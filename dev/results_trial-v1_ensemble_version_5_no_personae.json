[{"hyp": "A district of Kowloon, China.", "ref": "tgt", "src": "The City <define> Chiuchow </define> is Kowloon 's other top restaurant and is famous for its goose dishes and other specialties from the Chiuchow region ( you may also wish to try the beef satay done in a creamy sauce ) .", "tgt": "The Chaoshan region where the Teochew dialect is spoken.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Not Hallucination"], "predicted": "Hallucination", "predicted_p": 0.8, "timestamp": "2023-11-05T03:30:52Z", "rationale_0": "The output is a hallucination. While the output accurately identifies Chiuchow as a district of Kowloon, China, it fails to provide the important context that Chiuchow is a region where the Teochew dialect is spoken, as indicated in the target. The output also does not mention anything about the restaurant's specialty in goose dishes and other regional specialties, which is a key aspect of the definition given in the input.", "rationale_1": "The output is a hallucination. The term \"Chiuchow\" is defined incorrectly as a district of Kowloon, China. According to the target, \"Chiuchow\" refers to the Chaoshan region where the Teochew dialect is spoken, not a district in Kowloon. The output does not match the target and contains incorrect information not inferred from the input.", "rationale_2": "The output is a hallucination. While it correctly identifies Chiuchow as a district within Kowloon, China, it fails to provide the more precise definition outlined in the target. The target definition specifies that Chiuchow refers to the Chaoshan region where the Teochew dialect is spoken. The output does not contain this information, making it a hallucination.", "rationale_3": "The output is a hallucination. While the output correctly identifies Chiuchow as a district in China, it inaccurately specifies its location as Kowloon. The target definition clarifies that Chiuchow refers to the Chaoshan region where the Teochew dialect is spoken, not Kowloon.", "rationale_4": "The output is a hallucination. While it correctly identifies Chiuchow as a district of Kowloon, China, it fails to provide the specific information that Chiuchow is known for being the region where the Teochew dialect is spoken, which is specified in the target. Therefore, it's not fully accurate."}, {"hyp": "(Wicca) A witchdoctor.", "ref": "tgt", "src": "\u201c I went to see the witchdoctor , the <define> igqira </define> . And he spoke to the izinyanya , the spirits of the ancestors . \u201d", "tgt": "(South Africa) A traditional tribal diviner or spiritual healer.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Not Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T03:31:49Z", "rationale_0": "The output is a hallucination. The term \"igqira\" is correctly identified as a witchdoctor, however, the context provided by \"(Wicca)\" is incorrect. The term \"igqira\" is specific to South African traditional tribal culture, not Wicca. The target definition correctly identifies this cultural context. Thus, the output includes incorrect information not supported by the input.", "rationale_1": "The output is a hallucination. The target definition indicates that 'igqira' is a term used in South Africa to refer to a traditional tribal diviner or spiritual healer. However, the output incorrectly defines 'igqira' within the context of Wicca as a witchdoctor, which is not accurate based on the provided target. Thus, the output is not correct and is a hallucination.", "rationale_2": "The output is a hallucination. While it correctly identifies \"igqira\" as a type of spiritual healer or diviner, it incorrectly associates it with Wicca. The term \"igqira\" is actually from the Xhosa culture in South Africa, not Wicca. The output introduces extraneous information that isn't present or implied in the input.", "rationale_3": "The output is a hallucination. While the output does provide a definition for 'igqira', it inaccurately associates it with Wicca, a modern pagan, witchcraft religion. The correct association, as provided in the target, is with South African traditional tribal divination or spiritual healing. The output does not provide this accurate cultural context, making it a hallucination.", "rationale_4": "The output is a hallucination. The target definition provided specifies that \"igqira\" is a term from South Africa referring to a traditional tribal diviner or spiritual healer. However, the output incorrectly defines \"igqira\" in the context of Wicca as a witchdoctor. This is not accurate or inferred from the given input. Therefore, the output is a hallucination."}, {"hyp": "(nautical) A halyard.", "ref": "tgt", "src": "Haul away , keeping strain on both parts of the halyard so that the <define> pigstick </define> remains vertical as it goes up and does n't foul the spreaders .", "tgt": "(nautical) A staff that carries a flag or pennant above the mast of a sailboat.", "model": "", "task": "DM", "labels": ["Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T03:32:23Z", "rationale_0": "The output is a hallucination. The term to be defined was 'pigstick', but the language model incorrectly defined it as a 'halyard'. The target definition clearly states that a 'pigstick' is a staff that carries a flag or pennant above the mast of a sailboat, not a halyard.", "rationale_1": "The output is a hallucination. The term to be defined was 'pigstick', but the model incorrectly defined it as 'a halyard'. The correct definition, as given in the target, is a staff that carries a flag or pennant above the mast of a sailboat.", "rationale_2": "The output is a hallucination. The term to be defined was 'pigstick', but the output provides a definition for 'halyard', which is entirely different. The target confirms that a 'pigstick' is a staff that carries a flag or pennant above the mast of a sailboat, not a halyard.", "rationale_3": "The output is a hallucination. The term to be defined in the input is 'pigstick', but the output provides a definition for 'halyard', which is a different nautical term entirely. The correct definition is provided in the target, which describes a 'pigstick' as a staff that carries a flag or pennant above the mast of a sailboat.", "rationale_4": "The output is a hallucination because it does not accurately define the term \"pigstick\". While the output is related to sailing terminology, it incorrectly defines \"pigstick\" as a \"halyard\", which is a rope used for raising and lowering sails. The correct definition, as outlined in the target, is a staff that carries a flag or pennant above the mast of a sailboat. Therefore, the output is incorrect."}, {"hyp": "The quality of being rational.", "ref": "tgt", "src": "And what difference is there between the credibleness and <define> rationalness </define> of any of these wonders and the credibleness and rationalness of Papal infallibility ?", "tgt": "(archaic) The quality or state of being rational.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T03:32:49Z", "rationale_0": "The output is not a hallucination. It accurately provides the definition for the term \"rationalness\" as asked in the input. The definition in the output, \"The quality of being rational,\" aligns closely with the target definition, \"The quality or state of being rational.\" The slight variation in wording does not change the overall meaning.", "rationale_1": "The output is not a hallucination. The output correctly provides a definition for the term \"rationalness,\" which is in line with the target definition provided. It accurately captures the essence of the term, alluding to the quality of being rational.", "rationale_2": "The output is not a hallucination. The provided output accurately defines the term \"rationalness\" as the quality of being rational, which aligns with the target definition.", "rationale_3": "The output is not a hallucination. The output correctly defines the term \"rationalness\" as \"the quality of being rational,\" which aligns with the target definition of \"the quality or state of being rational.\"", "rationale_4": "The output is not a hallucination. The target and the output are almost identical in meaning, both defining \"rationalness\" as the quality or state of being rational. The output is correct and doesn't contain any extraneous or incorrect information."}, {"hyp": "(uncountable) The study of trees.", "ref": "tgt", "src": "It is now generally supposed that the forbidden fruit was a kind of citrus , but certain facts connected with <define> arborolatry </define> seem to me to disprove this opinion .", "tgt": "The worship of trees.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T03:33:20Z", "rationale_0": "The output is a hallucination. The term 'arborolatry' is defined as 'the worship of trees', which is accurately provided in the target. However, the output incorrectly defines 'arborolatry' as 'The study of trees', which is not accurate. Therefore, the output does contain incorrect information that is not inferred from the input.", "rationale_1": "The output is a hallucination. The term \"arborolatry\" is defined as the worship of trees, which is the correct definition provided in the target. However, the output incorrectly defines \"arborolatry\" as the study of trees, which is not accurate.", "rationale_2": "The output is a hallucination. The term \"arborolatry\" is defined as the worship of trees, not the study of trees. Thus, the output provided is incorrect and does not accurately define the term as required by the input.", "rationale_3": "The output is a hallucination. The term 'arborolatry' is defined as 'the worship of trees'. However, the output incorrectly defines it as 'the study of trees'. Therefore, the output contains incorrect information and is not aligned with the target.", "rationale_4": "The output is a hallucination. The term \"arborolatry\" is defined incorrectly in the output. The correct definition is given in the target as \"The worship of trees\", not \"The study of trees\"."}, {"hyp": "(zoology) A pseudostome.", "ref": "tgt", "src": "The pseudembryo moves rapidly in the water , rolling round and swinging from side to side ; as a rule , and especially when at rest , the surface bearing the pseudostome and <define> pseudoproct </define> is turned downwards .", "tgt": "(biology) The anal opening on the pseudembryo of an echinoderm.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T03:33:55Z", "rationale_0": "The output is a hallucination. The output incorrectly defines \"pseudoproct\" as a \"pseudostome\". The target definition indicates that \"pseudoproct\" is the anal opening on the pseudembryo of an echinoderm, not a pseudostome.", "rationale_1": "The output is a hallucination. The term 'pseudoproct' is inaccurately defined as a 'pseudostome' in the output. According to the target, 'pseudoproct' should be defined as the anal opening on the pseudembryo of an echinoderm. Therefore, the output is incorrect and does not match the target definition.", "rationale_2": "The output is a hallucination. The term \"pseudoproct\" is incorrectly defined as a \"pseudostome\" in the output. The target, which is the correct definition, identifies \"pseudoproct\" as the anal opening on the pseudembryo of an echinoderm, not a pseudostome.", "rationale_3": "The output is a hallucination. The term \"pseudoproct\" is incorrectly defined as a \"pseudostome\" in the output. According to the target, \"pseudoproct\" should be defined as the anal opening on the pseudembryo of an echinoderm, which is not mentioned in the output. Therefore, the output is incorrect.", "rationale_4": "The output is a hallucination. The term to be defined is \"pseudoproct\" but the output defines \"pseudostome.\" Furthermore, the output does not provide the correct definition for \"pseudoproct,\" which according to the target, is the anal opening on the pseudembryo of an echinoderm. The output is therefore incorrect and off point."}, {"hyp": "Resembling or characteristic of umber.", "ref": "tgt", "src": "<define> umbery </define> gold", "tgt": "Of or pertaining to umber; like umber.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T03:34:25Z", "rationale_0": "The output is not a hallucination. It accurately provides a definition for \"umbery\", indicating that it pertains to or is characteristic of umber. The output aligns with the target definition, therefore it is correct and not a hallucination. The word \"gold\" after the define tag in the input seems to be unrelated or extraneous and does not appear to influence the given output.", "rationale_1": "The output is not a hallucination. It correctly provides a definition for the term \"umbery,\" stating that it is something resembling or characteristic of umber. This aligns with the target definition, indicating that the output is accurate and on point.", "rationale_2": "The output is not a hallucination. The output \"Resembling or characteristic of umber\" is similar to the target \"Of or pertaining to umber; like umber.\" Both definitions correctly describe the term \"umbery\" as something that is like or characteristic of umber. Therefore, the output is accurate and not a hallucination.", "rationale_3": "The output is not a hallucination. It correctly and accurately provides a definition for the term \"umbery\" in a synonymous manner to the target. Both definitions indicate that \"umbery\" refers to something that is like or resembles umber. There is no extraneous or incorrect information provided in the output.", "rationale_4": "The output is not a hallucination. It correctly provides a definition for \"umbery\", stating that it is something resembling or characteristic of umber. This aligns with the target definition, which is \"of or pertaining to umber; like umber\". Thus, the output is accurate and on point with the input."}, {"hyp": "(music, transitive) To play (a note) at the same time.", "ref": "tgt", "src": "Now the two bounding notes of an enharmonic tetrachord of the relevant sort will indeed both be the lowest notes of pykna when the tetrachords are put together in conjunction ; but the higher of them can never <define> abut on </define> a pyknon in the case envisaged here , where the tone is introduced to disjoin the tetrachords .", "tgt": "(transitive) To border on.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T03:35:03Z", "rationale_0": "The output is a hallucination. The term to define is \"abut on\" and the target definition is \"(transitive) To border on.\" However, the output definition provided by the language model is \"(music, transitive) To play (a note) at the same time,\" which is not related to the term or its correct definition. It is incorrect and cannot be reasonably inferred from the input.", "rationale_1": "The output is a hallucination. The term \"abut on\" is defined in the target as \"to border on\", which can be interpreted in the musical context as to be adjacent to or to follow immediately. The output definition \"to play (a note) at the same time\" is not correct as it introduces the idea of simultaneousness, which is not implied in the original definition or context.", "rationale_2": "The output is a hallucination. The correct definition of \"abut on\" is to border on, as indicated by the target. The output inaccurately defines \"abut on\" as to play (a note) at the same time, which is not inferred from the input.", "rationale_3": "The output is a hallucination. The term to be defined is \"abut on\", which according to the target definition should mean \"to border on\". However, the output definition provided is related to playing a note at the same time, which is not accurate in the context of the given input and does not align with the target definition.", "rationale_4": "The output is a hallucination. The term \"abut on\" is defined in the target as to \"border on\", which means to be next to or have a common boundary with. However, the output defines the term as to play (a note) at the same time, which is not related to the target definition or the context provided in the input. Therefore, the output is incorrect and does not accurately define the term based on the input and target."}, {"hyp": "(Australia, New Zealand, colloquial) A hatfish.", "ref": "tgt", "src": "Noah did n't realize when he stayed on the job - he was then about 600 years old and built the ark and drove the animals in two by two , the <define> hatfish </define> and the kangaroo \u2014 \u2014 he did n't realize he was laying the foundation for an occupation for old men in New York , several years later .", "tgt": "(colloquial) Synonym of halibut", "model": "", "task": "DM", "labels": ["Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T03:35:40Z", "rationale_0": "The output is a hallucination. The term \"hatfish\" is defined as a colloquial synonym for halibut according to the target. However, the output generated by the model inaccurately defines \"hatfish\" as something specific to Australia and New Zealand, which is information not present or implied in the input.", "rationale_1": "The output is a hallucination. The target definition indicates that \"hatfish\" is a colloquial synonym for halibut. However, the generated output defines \"hatfish\" in a regional context (Australia, New Zealand) which cannot be inferred from the input, hence the output contains extraneous information. Furthermore, the output does not match the target definition, as it does not mention the term \"halibut\".", "rationale_2": "The output is a hallucination. The term \"hatfish\" is not defined accurately in the output. In the target, it is mentioned that hatfish is a synonym for halibut, a type of fish. However, in the output, it is defined as an Australian or New Zealand colloquialism without any further explanation. There is also no mention of it being a synonym for halibut. Thus, the generated definition does not align with the target.", "rationale_3": "The output is a hallucination. The provided definition in the output \"(Australia, New Zealand, colloquial) A hatfish\" is not in alignment with the target definition \"Synonym of halibut\". Furthermore, the output includes specific geographies (Australia, New Zealand) which cannot be inferred from the provided input.", "rationale_4": "The output is a hallucination. The output provides a definition for 'hatfish' that is specific to Australia and New Zealand, which cannot be inferred from the input. Furthermore, the output definition does not match the target definition, which defines 'hatfish' as a colloquial synonym for halibut."}, {"hyp": "Having a keen sense of humor.", "ref": "tgt", "src": "<define> keen </define> satire or sarcasm", "tgt": "Acrimonious, bitter, piercing.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T03:36:19Z", "rationale_0": "The output is a hallucination. The input asks for a definition of \"keen\" in the context of satire or sarcasm, which suggests a sharp, biting, or piercing quality. The output defines \"keen\" as having a sense of humor, which is not accurate in this context and doesn't match the target definition provided.", "rationale_1": "The output is a hallucination. The term to be defined 'keen' was interpreted as a characteristic of humor rather than a type of satire or sarcasm. The definition provided does not align with the context provided in the input. The target suggests that the correct definition should involve acrimony, bitterness, or piercing qualities, none of which are mentioned or implied in the output. Therefore, the output is incorrect and does not accurately define the term in the given context.", "rationale_2": "The output is a hallucination. While the term \"keen\" could be associated with having a sharp sense of humor, it does not specifically refer to satire or sarcasm, as suggested in the input. The output does not align with the target, which emphasizes a more negative and harsh interpretation of the term, such as acrimonious or bitter. Therefore, the output is incorrect and off point.", "rationale_3": "The output is a hallucination. The input term is \"keen satire or sarcasm\" which refers to sharp or biting humor. The target definition suggests a more negative or critical connotation with words like \"acrimonious,\" \"bitter,\" and \"piercing.\" However, the output offered, \"having a keen sense of humor,\" is not in alignment with either the input or target. It is too generic and misses the critical or sarcastic aspect of the humor implied in the original term.", "rationale_4": "The output is a hallucination. The term to define is \"keen satire or sarcasm\" but the output is defining a \"keen sense of humor.\" These are not the same concepts. A keen sense of humor doesn't necessarily involve satire or sarcasm, and it doesn't reflect the acrimonious, bitter, piercing quality that the target suggests. Therefore, the output is incorrect and off point."}, {"hyp": "A person who has a pass.", "ref": "tgt", "src": "<define> Passholders </define> can visit the theme park all year round .", "tgt": "One who holds a pass.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T03:36:45Z", "rationale_0": "The output is not a hallucination. It correctly defines \"Passholders\" as a person who has a pass, which is in line with the target definition.", "rationale_1": "The output is not a hallucination. The term \"Passholders\" is correctly defined as \"A person who has a pass.\" This definition matches the target \"One who holds a pass\", with no extraneous or incorrect information added.", "rationale_2": "The output is not a hallucination. The definition provided in the output accurately defines \"Passholders\" as a person who has a pass, which aligns with the target definition. The additional information in the input about visiting the theme park all year round is not included, but this is not a necessary part of the definition and does not make the output a hallucination.", "rationale_3": "The output is not a hallucination. It accurately defines the term \"Passholders\" as a person who has a pass, which aligns well with the target definition. It does not add extraneous or incorrect information.", "rationale_4": "The output is not a hallucination. The definition provided by the language model, \"A person who has a pass,\" accurately defines the term \"Passholders.\" It is synonymous with the target definition, \"One who holds a pass,\" and correctly derived from the input."}, {"hyp": "(colloquial) A term of endearment.", "ref": "tgt", "src": "Hey , <define> babe </define> , how 's about you and me getting together ?", "tgt": "(affectionate) Darling (term of endearment).", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T03:37:16Z", "rationale_0": "The output is not a hallucination. It accurately provides a definition for the term 'babe', describing it as a colloquial term of endearment. Although it doesn't use the same wording as the target, the meaning is essentially the same.", "rationale_1": "The output is not a hallucination. It accurately provides a definition for the term \"babe\" as used in the given context. It states that \"babe\" is a colloquial term of endearment, which is in line with the target definition.", "rationale_2": "The output is not a hallucination. It correctly defines the term \"babe\" as a term of endearment, which aligns with the target. However, it is slightly less specific than the target, as it doesn't include the descriptors \"affectionate\" or \"darling\". Nonetheless, it is not incorrect or off point.", "rationale_3": "The output is not a hallucination. It accurately defines \"babe\" as a term of endearment, which aligns with the target definition. Although it does not include the nuance of it being an affectionate term, it is not incorrect or off point.", "rationale_4": "The output is not a hallucination. It correctly identifies \"babe\" as a term of endearment, which aligns with the target definition. While the output might not be as specific as the target (which identifies \"babe\" as an affectionate term like \"darling\"), it is still accurate and within the correct context."}, {"hyp": "(intransitive) To speak in a slurred manner.", "ref": "tgt", "src": "Sometimes life takes hold of one , carries the body along , accomplishes one 's history , and yet is not real , but leaves oneself as it were <define> slurred over </define> .", "tgt": "(dated) To deal with something hurriedly; to treat in a perfunctory manner.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T03:37:51Z", "rationale_0": "The output is a hallucination. The term \"slurred over\" in the context of the input sentence doesn't refer to speaking in a slurred manner. Rather, it seems to be about handling something hastily or carelessly. The provided target definition conveys this meaning accurately, but the output definition does not. Therefore, the output is incorrect.", "rationale_1": "The output is a hallucination. The output defines \"slurred over\" as to speak in a slurred manner. However, the target definition suggests that \"slurred over\" refers to dealing with something hurriedly or treating something in a perfunctory manner. The output does not match the target, indicating it has provided an incorrect or unrelated definition.", "rationale_2": "The output is a hallucination. The output definition provided by the model, \"To speak in a slurred manner,\" is not accurate in the context of the given sentence. The target definition, \"To deal with something hurriedly; to treat in a perfunctory manner,\" better fits the context of the sentence and the term \"slurred over\". Therefore, the output has incorrectly defined the term.", "rationale_3": "The output is a hallucination. While the provided definition is accurate for the term \"slurred over\" in a different context, it does not correctly match the definition required in the given context. The target definition refers to the act of handling something in a hurried or careless manner, which is more in line with the context provided in the input sentence. Therefore, the output is not correct or accurate.", "rationale_4": "The output is a hallucination. The target definition talks about dealing with something in a hurried or perfunctory manner, whereas the output definition talks about speaking in a slurred manner. These two definitions are not the same, hence the output is incorrect."}, {"hyp": "A device that simulates walking.", "ref": "tgt", "src": "During the late 1960s and early 1970s , it was also the site of the lunar 1\u20446 gravity <define> walking simulator </define> rig .", "tgt": "Used other than figuratively or idiomatically: see walking,\u200e simulator.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T03:38:18Z", "rationale_0": "The output is not a hallucination. The term to be defined is 'walking simulator'. The output provides a concise and accurate definition of this term: \"a device that simulates walking.\" This definition can be reasonably inferred from the input and the output does not contain any extraneous information.", "rationale_1": "The output is not a hallucination. The term \"walking simulator\" is correctly interpreted and defined by the model as a \"device that simulates walking\". The output is accurate and correctly inferred from the input.", "rationale_2": "The output is not a hallucination. The term \"walking simulator\" is accurately defined as \"a device that simulates walking.\" The definition provided is concise, accurate, and does not contain any extraneous information that cannot be inferred from the input.", "rationale_3": "The output is not a hallucination. The term \"walking simulator\" is accurately defined as \"a device that simulates walking.\" This definition aligns with the context provided in the input, which refers to a \"lunar 1\u20446 gravity walking simulator rig.\"", "rationale_4": "The output is not a hallucination. The term \"walking simulator\" is accurately defined as \"a device that simulates walking\". The output definition is in line with the input context, which describes a simulator used to mimic the experience of walking in lunar gravity."}, {"hyp": "(intransitive, colloquial) To be very hot.", "ref": "tgt", "src": "Let 's face it , they 're there for a good stroll on a Sunday afternoon when it 's <define> pissing </define>   outside .", "tgt": "(ambitransitive, mildly, _, vulgar) To rain heavily.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T03:38:47Z", "rationale_0": "The output is a hallucination. The term 'pissing' in the given context is used to refer to heavy rain, as correctly defined in the target. However, the output incorrectly defines it as being very hot, which is not related or accurate to the input or target definition.", "rationale_1": "The output is a hallucination. The term 'pissing' in this context is colloquially used to refer to heavy rain, not to describe something as being very hot. Therefore, the output provided is incorrect and does not accurately define the term in the given context.", "rationale_2": "The output is a hallucination. The term to be defined, \"pissing\", in the given context refers to heavy rainfall. However, the generated definition inaccurately describes it as being very hot. Thus, the output does not align with the target and is incorrect.", "rationale_3": "The output is a hallucination. The term \"pissing\" in this context is used to describe heavy rain, as correctly defined in the target. The output incorrectly defines it as being very hot, which is not accurate or inferred from the input.", "rationale_4": "The output is a hallucination. The term \"pissing\" in the context provided is slang for heavy rain, as correctly defined in the target. However, the output incorrectly defines it as a term to describe very hot weather. This is not accurate according to the given input or target."}, {"hyp": "(geology) Synonym of synecdoche", "ref": "tgt", "src": "In the Ronne <define> syneclise </define> the thickness of sedimentary cover reaches 13.5 km and the folded basement has a complex relief owing to block movements along faults of different rank .", "tgt": "(geology) A large, shallow depression formed on a continental platform due to slow subsidence.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T03:39:26Z", "rationale_0": "The output is a hallucination. The term 'syneclise' is incorrectly defined as a synonym of 'synecdoche', which is a completely different term. The correct definition is provided in the target, which describes 'syneclise' as a large, shallow depression formed on a continental platform due to slow subsidence. This is relevant to the context provided in the input, which describes geological formations and processes.", "rationale_1": "The output is a hallucination. The term 'syneclise' is incorrectly defined as a synonym of 'synecdoche', which is a completely different term used in rhetoric. The correct definition, as given in the target, is a large, shallow depression formed on a continental platform due to slow subsidence. The output is therefore incorrect and does not accurately reflect the term's meaning in the context of the input sentence.", "rationale_2": "The output is a hallucination. The target term to be defined here is 'syneclise', which is a geological term referring to a large, shallow depression formed on a continental platform due to slow subsidence. However, the output incorrectly defines 'syneclise' as a synonym for 'synecdoche', which is a completely unrelated term from the field of rhetoric, not geology. Therefore, the output is incorrect and does not match the input context.", "rationale_3": "The output is a hallucination. The term 'synecdoche' provided in the output is incorrect and not related to the term 'syneclise' within the geological context. The correct definition is provided in the target, stating that a 'syneclise' is a large, shallow depression formed on a continental platform due to slow subsidence. Therefore, the output is not accurate.", "rationale_4": "The output is a hallucination. The given definition in the output, \"Synonym of synecdoche\", is incorrect. The target provides the correct definition of 'syneclise' as a large, shallow depression formed on a continental platform due to slow subsidence. This is a geological term and has no relation to 'synecdoche', which is a figure of speech in literature."}, {"hyp": "(informal) A person who is addicted to sport.", "ref": "tgt", "src": "I have spent much of my life a recovering <define> sportaholic </define> . If it bounced , rolled , slid , or flew , I chased it . Or watched it .", "tgt": "A sportsaholic.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T03:39:55Z", "rationale_0": "The output is not a hallucination. The definition provided by the model accurately and succinctly defines the term 'sportaholic' as a person who is addicted to sport, which aligns with the context provided in the input sentence.", "rationale_1": "The output is not a hallucination. The definition provided by the model correctly and accurately defines the term \"sportaholic\" as someone who is addicted to sports, which is consistent with the context given in the input.", "rationale_2": "The output is not a hallucination. The term \"sportaholic\" is defined correctly and accurately in the output as \"a person who is addicted to sport\", which matches the context given in the input. The term \"sportaholic\" is a play on the term \"alcoholic\", implying an addiction, but in this case, to sport. The output also correctly identifies that it is an informal term.", "rationale_3": "The output is not a hallucination. The defined term \"sportaholic\" is accurately described as a person who is addicted to sport, which aligns with the context given in the input. The term suggests an extreme involvement or obsession with sports, similar to how the term 'alcoholic' suggests an addiction to alcohol. Therefore, the definition provided by the language model is correct and accurate.", "rationale_4": "The output is not a hallucination. The term \"sportaholic\" is accurately defined as a person who is addicted to sports, which aligns with the context provided in the input. The additional term \"informal\" also correctly indicates that this term is not typically used in formal or official communication."}, {"hyp": "Resembling or characteristic of French surrealism.", "ref": "tgt", "src": "Quatermass also mediated Wellsian influence on the tone and preoccupations of the new hybrid SF \u2013 horror - film genre , with its monstrous <define> Gigeresque </define> fusions of machine and organism [ \u2026 ]", "tgt": "Reminiscent of H. R. Giger (born 1940), Swiss surrealist painter best known for nightmarish biomechanical imagery.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Not Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T03:40:31Z", "rationale_0": "The output is a hallucination. The output inaccurately defines \"Gigeresque\" as \"resembling or characteristic of French surrealism.\" The target definition correctly identifies \"Gigeresque\" as reminiscent of the works of H. R. Giger, a Swiss surrealist painter known for his \"nightmarish biomechanical imagery.\" The output not only incorrectly identifies the origin of the term as French rather than Swiss, but it also fails to capture the specific style of Giger's work.", "rationale_1": "The output is a hallucination. The output defines \"Gigeresque\" as \"resembling or characteristic of French surrealism,\" which is incorrect. The target definition indicates that \"Gigeresque\" refers to the style of H. R. Giger, a Swiss surrealist painter known for his biomechanical imagery, not French surrealism. Therefore, the output is incorrect and off point.", "rationale_2": "The output is a hallucination. The output incorrectly defines \"Gigeresque\" as \"resembling or characteristic of French surrealism.\" The target correctly identifies \"Gigeresque\" as being reminiscent of H. R. Giger, a Swiss surrealist painter known for his biomechanical imagery. The output not only incorrectly identifies the origin of the term (French vs Swiss), but also does not accurately describe the specific style of H. R. Giger's work.", "rationale_3": "The output is a hallucination. The term 'Gigeresque' is defined in the output as being related to French surrealism, which is incorrect. The term refers to the style of H. R. Giger, who is a Swiss surrealist painter known for his distinctive biomechanical art. The output does not correctly define the term in accordance with the target.", "rationale_4": "The output is a hallucination. The term 'Gigeresque' refers to the style of H. R. Giger, a Swiss surrealist painter known for his biomechanical artwork. The output incorrectly states it as \"resembling or characteristic of French surrealism.\" Although Giger's work falls under the umbrella of surrealism, the output does not accurately define 'Gigeresque' as it omits reference to Giger and his distinctive style."}, {"hyp": "The state or quality of being a princess.", "ref": "tgt", "src": "\u201c What are you doing ? \u201d Carly asked , looking around . \u201c You do n\u2019t want to be in here . You \u2019re way too much of a princess . \u201d / \u201c Remember how I grew up , Carly . I \u2019ve earned my <define> princessness </define> . \u201d", "tgt": "The quality of being a princess.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T03:40:56Z", "rationale_0": "The output is not a hallucination. It accurately defines the term \"princessness\" as the state or quality of being a princess, which aligns with the target definition. The output does not contain any incorrect or extraneous information that cannot be inferred from the input.", "rationale_1": "The output is not a hallucination. The output correctly and accurately defines \"princessness\" as the state or quality of being a princess, which aligns with the target definition. It doesn't contain any extraneous or incorrect information.", "rationale_2": "The output is not a hallucination. It correctly defines the term \"princessness\" as per the context given in the input. The definition \"The state or quality of being a princess\" aligns closely with the target definition and accurately reflects the information inferred from the input.", "rationale_3": "The output is not a hallucination. The output correctly and accurately defines the term \"princessness\" as described in the target. It does not contain any information that is incorrect or cannot be inferred from the input.", "rationale_4": "The output is not a hallucination. It accurately provides a definition for the term 'princessness', aligning with the target definition. The output definition (\"The state or quality of being a princess\") is synonymous and equivalent to the target definition (\"The quality of being a princess\")."}, {"hyp": "(Australia, New Zealand, colloquial) A tree.", "ref": "tgt", "src": "He climbed over the sedge and eely oarweeds and sat on a stool of rock , resting his ashplant in a <define> grike </define> .", "tgt": "(chiefly, British) A deep cleft formed in limestone surfaces due to water erosion; providing a unique habitat for plants.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T03:41:30Z", "rationale_0": "The output is a hallucination. The given definition in the output, that a 'grike' is a tree, is incorrect when compared with the target, which accurately defines a 'grike' as a deep cleft in limestone surfaces. The output does not match the target and is therefore incorrect and a hallucination.", "rationale_1": "The output is a hallucination. The term \"grike\" is defined incorrectly in the output. The target definition describes it as a deep cleft in limestone surfaces, typically found in Britain, whereas the output definition describes it as a tree, commonly used in Australia and New Zealand. This discrepancy indicates that the output definition is incorrect and thus, it is a hallucination.", "rationale_2": "The output is a hallucination. The output provides a definition for \"grike\" that is associated with trees and is commonly used in Australia and New Zealand. However, the target shows that \"grike\" is a term primarily used in Britain to refer to a deep cleft in limestone surfaces. Therefore, the output is not accurate.", "rationale_3": "The output is a hallucination. The output defines \"grike\" as a tree, which is incorrect. The target correctly defines \"grike\" as a deep cleft formed in limestone surfaces due to water erosion, a definition that is specific to geological formations, not trees.", "rationale_4": "The output is a hallucination. The term \"grike\" is defined in the target as a deep cleft in limestone surfaces formed due to water erosion, which is consistent with its usage in the input sentence. The output, however, incorrectly defines \"grike\" as a tree, which is not consistent with either the input sentence or the target definition."}, {"hyp": "(intransitive) To die.", "ref": "tgt", "src": "\" But why should I be in another room ? \" \" You <define> passed over </define> in the night . \" \" Passed over ? Do you mean I died ? \" \" Yes , lady , you died . \" There was a long silence .", "tgt": "(intransitive, euphemistic) To die and thus progress to the afterlife.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T03:42:03Z", "rationale_0": "The output is not a hallucination. The term \"passed over\" in this context is accurately defined as to die, which matches with the target definition. The omission of the phrase \"and thus progress to the afterlife\" in the output does not make it incorrect or a hallucination, as it is still a correct and reasonable interpretation of the term.", "rationale_1": "The output is not a hallucination. It correctly defines \"passed over\" as a euphemism for dying. However, it does not include the detail about progressing to the afterlife, which is mentioned in the target definition. Despite this omission, the output provides a correct, though less specific, definition of the term.", "rationale_2": "The output is not a hallucination. It accurately defines the term \"passed over\" as used in the context of the input, which refers to the euphemistic term for dying. While it doesn't include the additional detail about progressing to the afterlife as in the target, it is still a correct and relevant definition.", "rationale_3": "The output is not a hallucination. The term 'passed over' in the context provided is accurately defined as 'to die'. The target definition includes additional information about progressing to the afterlife, which the output does not include. However, the output is still correct as the basic meaning of 'passed over' in this context is indeed 'to die'.", "rationale_4": "The output is not a hallucination. It correctly defines the term \"passed over\" as used in the input context. The term is indeed a euphemism for dying, and the output accurately reflects this. Although the output's definition is slightly less detailed than the target, it is still correct and not off point."}, {"hyp": "Alternative form of scatter site", "ref": "tgt", "src": "It is designed for single - family use in subdivisions or <define> scatter sites </define> and available as a standardized product   [ \u2026 ]", "tgt": "An area of state-sponsored housing used as a shelter for homeless people; such housing is scattered across different parts of a city rather than concentrated in one place.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Not Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T03:42:33Z", "rationale_0": "The output is a hallucination because it does not provide a correct or accurate definition of \"scatter sites\". Instead of providing a definition, it simply refers to it as an \"alternative form of scatter site\", which is not informative or accurate according to the target definition.", "rationale_1": "The output is a hallucination. The output does not provide a correct definition of \"scatter sites\". Instead, it refers to an \"alternative form of scatter site\", which isn't coherent or accurate. The target provides a clear definition of scatter sites as housing scattered across different parts of a city, which is not captured in the output at all.", "rationale_2": "The output is a hallucination. The output, \"Alternative form of scatter site,\" doesn't provide a clear definition of the term \"scatter sites.\" It does not match the information or the level of detail provided in the target, which explains that scatter sites refer to an area of state-sponsored housing used as a shelter for homeless people, scattered across different parts of a city.", "rationale_3": "The output is a hallucination. The output provided does not give a definition of the term \"scatter sites\" as required by the task. Instead, it merely states that it is an alternative form of the term \"scatter site\", without providing any actual definition or meaning of the term. The target provides a clear and detailed definition of \"scatter sites\", which is not reflected in the output.", "rationale_4": "The output is a hallucination. While it refers to the term \"scatter sites\", it fails to accurately provide the detailed definition given in the target. The output suggests that \"scatter sites\" is an alternative form of \"scatter site\", which adds no valuable information or clear definition to the term. It does not mention the concept of state-sponsored housing scattered across different parts of a city, which is the core aspect of the definition."}, {"hyp": "The state or condition of being obsolescent.", "ref": "tgt", "src": "One way is to legislate extended warranties on products , so washing machines and refrigerators last for 30 years instead of 10 . Another is to ban planned <define> obsolescence </define> , so manufacturers ca n\u2019t create products that are designed to fail .", "tgt": "(uncountable) The state of being obsolete\u2014no longer in use; gone into disuse; disused or neglected.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Hallucination", "Not Hallucination", "Not Hallucination", "Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.4, "timestamp": "2023-11-05T03:44:49Z", "rationale_0": "The output is not a hallucination. Although the output definition doesn't exactly match the target definition, it captures the essence of the term 'obsolescence.' Both definitions point to the condition of becoming outdated or falling into disuse. The discrepancy between the output and target definitions can be attributed to the inherent subjectivity and variability in defining abstract concepts, rather than hallucination.", "rationale_1": "The output is a hallucination. While the output is a valid definition of obsolescence, it does not match the target definition provided. The target definition involves obsolescence as being no longer in use or neglected, but the output suggests a condition of becoming obsolete, not necessarily already being obsolete. Furthermore, the output doesn't capture the aspect of deliberate design for failure that is implied in the input text.", "rationale_2": "The output is not a hallucination. The term \"obsolescence\" is defined accurately in the output as \"The state or condition of being obsolescent\". This aligns with the target definition, which also refers to the state of being obsolete or no longer in use. The output does not contain any extraneous or incorrect information.", "rationale_3": "The output is not a hallucination. It is a correct and accurate definition of the term \"obsolescence\". Although the output definition is not identical to the target, it conveys the same concept: the state of being or becoming obsolete, which means no longer in use or out of date.", "rationale_4": "The output is a hallucination. The definition provided for 'obsolescence' in the output is not completely accurate. The output defines it as 'the state or condition of being obsolescent', which refers to the process of becoming obsolete, not the state of being obsolete itself. This does not align with the target definition of obsolescence being the state of no longer being in use, which is more accurate and relevant to the context provided in the input."}, {"hyp": "Alternative form of gartel (\u201cdance\u201d)", "ref": "tgt", "src": "The bride stands perfectly still at one end of the room and holds a long <define> gartel </define> while the male dancing before her holds the other end .", "tgt": "(Judaism) A belt or sash used in prayer.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T03:45:23Z", "rationale_0": "The output is a hallucination. The term \"gartel\" is inaccurately defined as an \"alternative form of gartel ('dance')\". The target definition describes it as a belt or sash used in prayer in Judaism, which is consistent with its actual usage. The output definition does not match the target or the real meaning of the term.", "rationale_1": "The output is a hallucination. The provided definition in the output, \"Alternative form of gartel (\u201cdance\u201d)\", is incorrect. The target definition clarifies that a 'gartel' is a belt or sash used in prayer in Judaism, not a form of dance. The output does not match the target and is thus incorrect and a hallucination.", "rationale_2": "The output is a hallucination. The correct definition of \"gartel\" is provided in the target: it is a belt or sash used in prayer in Judaism. The definition in the output, stating it as an alternative form of dance, is incorrect and not related to the information given in the input.", "rationale_3": "The output is a hallucination. The output suggests an alternative form of the term \"gartel\" relating to dance, which is incorrect. The term \"gartel\" in the context of Judaism is indeed a belt or sash used in prayer, as correctly stated in the target. The output does not match the target definition.", "rationale_4": "The output is a hallucination. The definition given in the output is incorrect as it refers to \"gartel\" as an alternative form of dance, which is not accurate. The correct definition, as provided in the target, is a belt or sash used in prayer in Judaism. The output does not match the target definition and cannot be inferred from the input."}, {"hyp": "Capable of being endured.", "ref": "tgt", "src": "Misery colored by the greens and blues in my mother 's voice took all of the grief out of the words and left me with a conviction that pain was not only <define> endurable </define> , it was sweet .", "tgt": "Able to be endured; tolerable; bearable.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T03:45:48Z", "rationale_0": "The output is not a hallucination. It accurately provides a definition for the term \"endurable\" that aligns with the target definition, indicating it is able to be endured, tolerable or bearable. Both definitions effectively communicate the same meaning.", "rationale_1": "The output is not a hallucination. The generated definition, \"Capable of being endured,\" accurately defines the term \"endurable\" as indicated in the target, \"Able to be endured; tolerable; bearable.\" There is no extraneous or incorrect information.", "rationale_2": "The output is not a hallucination. It accurately defines the term \"endurable\" as being capable of being endured, which is essentially the same as the target definition stating that it is able to be endured, tolerable, or bearable.", "rationale_3": "The output is not a hallucination. The generated definition \"Capable of being endured\" accurately and succinctly defines the term \"endurable\" as indicated in the target \"Able to be endured; tolerable; bearable.\" Therefore, the output is correct and not a hallucination.", "rationale_4": "The output is not a hallucination. The term \"endurable\" is defined accurately in the output as \"capable of being endured,\" which aligns closely with the target definition \"able to be endured; tolerable; bearable.\" Therefore, the output is correct and accurate."}, {"hyp": "(geology) Of or pertaining to the Alps.", "ref": "tgt", "src": "In 1884 O. Heer published a comprehensive account of the <define> nival </define> flora of   Switzerland , in which he listed 338 species of flowering plants found above 2600   m. ; of these , 6 were found above 3900 m.", "tgt": "(botany) Found or thriving in snowy conditions.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T03:46:22Z", "rationale_0": "The output is a hallucination. The term 'nival' is defined in the target as relating to snowy conditions, specifically in the context of botany. The output, however, inaccurately defines 'nival' as pertaining to the Alps, which is a geographical rather than botanical or climatic reference. Therefore, the output inaccurately defines the term in question.", "rationale_1": "The output is a hallucination. The term \"nival\" is correctly defined in the target as relating to snowy conditions, specifically in the context of botany. However, the output provided misidentifies \"nival\" as a term pertaining to the Alps in geology. The input text doesn't suggest anything related to geology or the Alps. Therefore, the output contains incorrect information that couldn't be inferred from the input.", "rationale_2": "The output is a hallucination. The term \"nival\" is supposed to be defined in relation to botany and snowy conditions, as per the target. However, the output gives a geological definition, relating the term to the Alps, which is incorrect and off point.", "rationale_3": "The output is a hallucination. The term 'nival' is supposed to be defined in relation to botany and it means 'found or thriving in snowy conditions'. However, the output provided is incorrect as it defines the term in a geological context, pertaining to the Alps, which is not inferred from the input.", "rationale_4": "The output is a hallucination. The term \"nival\" is defined in the target as \"found or thriving in snowy conditions,\" specifically in the field of botany. However, the output incorrectly defines it in the context of geology, referring to the Alps. It does not accurately reflect the definition provided in the target, making it a hallucination."}, {"hyp": "Capable of being parachuted.", "ref": "tgt", "src": "<define> parachutable </define> supplies", "tgt": "Capable of being deployed by parachute.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T03:46:45Z", "rationale_0": "The output is not a hallucination. It accurately defines \"parachutable\" as capable of being parachuted, which aligns closely with the target definition of being capable of being deployed by parachute.", "rationale_1": "The output is not a hallucination. It correctly defines \"parachutable\" as being capable of being parachuted, aligning closely with the provided target definition. Although the wording is slightly different, the meaning remains the same.", "rationale_2": "The output is not a hallucination. It accurately defines the term \"parachutable\" in a concise manner, even though it is not an exact match to the target. Both the output and the target imply that \"parachutable\" describes something that can be delivered or deployed via parachute.", "rationale_3": "The output is not a hallucination. It accurately and succinctly defines \"parachutable\" in the context of supplies, i.e., capable of being parachuted. This definition aligns with the target definition - \"Capable of being deployed by parachute.\"", "rationale_4": "The output is not a hallucination. It accurately defines the term \"parachutable\" as capable of being parachuted. The output matches the target definition in meaning, implying that the supplies can be deployed using a parachute."}, {"hyp": "In a muffled manner.", "ref": "tgt", "src": "A voice came <define> muffledly </define> from inside the closet .", "tgt": "In a muffled manner; indistinctly.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T03:47:17Z", "rationale_0": "The output is not a hallucination. It accurately provides a definition for the term \"muffledly\", which is to speak or sound in a muffled manner. Although it does not include the \"indistinctly\" part from the target, the given definition is still correct and accurate, and it does not provide any extraneous or off-point information.", "rationale_1": "The output is not a hallucination. It accurately provides a definition for the term \"muffledly\", which is to do something in a muffled manner. The output may not include the \"indistinctly\" part from the target, but it is not incorrect or off point.", "rationale_2": "The output is not a hallucination. It accurately defines \"muffledly\" as \"in a muffled manner\", which aligns with the target. Although it does not include the \"indistinctly\" part of the target definition, the provided definition is still accurate and relevant.", "rationale_3": "The output is not a hallucination. It accurately provides a definition for the term \"muffledly\" - indicating something done in a muffled manner. Although it does not include the \"indistinctly\" part of the target definition, it still accurately captures the essence of the term's meaning.", "rationale_4": "The output is not a hallucination. The term \"muffledly\" is defined correctly as \"in a muffled manner,\" which aligns with the target definition. The output does not include the \"indistinctly\" part of the target, but this does not make it inaccurate or a hallucination, as \"in a muffled manner\" is a complete and accurate definition on its own."}, {"hyp": "(transitive) To cook (something) in a frying pan.", "ref": "tgt", "src": "Innawong et al . ( 2006 ) conducted experiments to study the effect of using nitrogen gas on the quality of <define> fried </define> chicken nuggets during pressure frying in terms of moisture retention and reduction in fat   [ \u2026 ]", "tgt": "Cooked in a deep fryer or pressure fryer or the like after being coated (breaded) in batter; compare deep-fried.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Not Hallucination"], "predicted": "Hallucination", "predicted_p": 0.8, "timestamp": "2023-11-05T03:47:55Z", "rationale_0": "The output is a hallucination. While it is technically correct that frying involves cooking something in a frying pan, the target definition provided is more specific and accurate to the context given in the input. The output does not capture the specific method of cooking \"fried\" chicken nuggets in a deep fryer or pressure fryer after being coated in batter, which is the information provided in the target. Therefore, the output is too general and misses key details, making it a hallucination.", "rationale_1": "The output is a hallucination. While it is true that frying involves cooking something in a frying pan, the term \"fried\" in the context of the input refers specifically to chicken nuggets. The output does not capture this context, nor does it match the target definition of being cooked in a deep fryer or pressure fryer after being coated in batter. Therefore, the output is not accurate.", "rationale_2": "The output is a hallucination. While it does provide a correct definition for the general term 'fried,' it does not accurately define 'fried' in the specific context of the input. The input is talking about 'fried chicken nuggets' which are usually deep fried or pressure fried after being breaded, not simply cooked in a frying pan. Therefore, the output does not capture the specificity required by the input.", "rationale_3": "The output is a hallucination. While the output is a generally correct definition of \"fried\", it is not specifically accurate for the context provided in the input. The input is referring to \"fried chicken nuggets\" particularly in a pressure fryer using nitrogen gas, which is a more specific process and differs from simply cooking something in a frying pan. The target provides a more appropriate definition pertaining to the process of deep frying or pressure frying after being breaded. Therefore, the output can be considered as a hallucination in this context.", "rationale_4": "The output is not a hallucination. While it may not be as specific as the target definition, it is still a general and correct definition of the term \"fried\". It doesn't contain any incorrect or extraneous information. It accurately describes the basic process of frying, which involves cooking something in a frying pan. Nonetheless, the output could have been more specific to the context provided in the input, such as mentioning the use of a deep fryer or pressure fryer and the coating process."}, {"hyp": "A sleeveless garment worn at night.", "ref": "tgt", "src": "Winston wore a <define> nightcap </define> to stave off the cold .", "tgt": "A warm cloth cap worn while sleeping, often with pajamas, being common attire in northern Europe before effective home heating became widespread. [From 14th c.]", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Not Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T03:48:22Z", "rationale_0": "The output is a hallucination. The definition provided in the output inaccurately describes a nightcap as a \"sleeveless garment worn at night\" which is not correct. A nightcap, as per the target definition, is a warm cloth cap worn while sleeping.", "rationale_1": "The output is a hallucination. The definition provided in the output is incorrect. A nightcap, as per the target, is a warm cloth cap worn while sleeping to keep the head warm, not a 'sleeveless garment'. The output seems to be confusing a 'nightcap' with a different type of sleepwear.", "rationale_2": "The output is a hallucination. The definition provided in the output is incorrect. A nightcap is not a \"sleeveless garment worn at night\", it is a \"warm cloth cap worn while sleeping\". The output is off point and does not accurately define the term \"nightcap\" as per the given target.", "rationale_3": "The output is a hallucination. The term to be defined was 'nightcap', which refers to a warm cloth cap worn while sleeping. However, the output provided a definition for a sleeveless garment worn at night, which is incorrect and not related to the correct definition.", "rationale_4": "The output is a hallucination. The term to be defined is \"nightcap,\" but the definition provided (\"A sleeveless garment worn at night\") does not accurately describe a nightcap. The target definition accurately describes a nightcap as a \"warm cloth cap worn while sleeping.\" Therefore, the output is incorrect."}, {"hyp": "(obsolete) Old; old-fashioned.", "ref": "tgt", "src": "And thou , our Mother , twice two centuries <define> young </define> ,", "tgt": "(Not) advanced in age; (far towards or) at a specified stage of existence or age.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T03:48:59Z", "rationale_0": "The output is a hallucination. The term to be defined is \"young\", which according to the provided target should mean \"not advanced in age\" or \"at a specified stage of existence or age\". However, the output defines \"young\" as \"old; old-fashioned\", which is not only incorrect but also the opposite of the correct definition.", "rationale_1": "The output is a hallucination. The term to be defined was 'young', and the output definition provided an obsolete definition for 'young' as 'old; old-fashioned.' This is not accurate when compared to the target definition which focuses on being not advanced in age or at a specific stage of existence or age. The output is incorrect and does not match the target.", "rationale_2": "The output is a hallucination. The term to be defined is \"young\", and the target definition correctly describes this as not being advanced in age or being at a certain stage of existence. However, the output definition incorrectly defines \"young\" as \"old\" or \"old-fashioned\", which is the opposite of the term's actual meaning.", "rationale_3": "The output is a hallucination. The term to be defined is \"young,\" which according to the target definition means not advanced in age or at a specified stage of existence or age. However, the output provided defines \"young\" as old or old-fashioned, which is the opposite of the correct definition. Therefore, the output is incorrect.", "rationale_4": "The output is a hallucination. The term to be defined is 'young', and the target provides a correct definition, suggesting the term refers to being not advanced in age or at a specific stage of existence. However, the output inaccurately defines 'young' as old or old-fashioned, which is the opposite of the actual and target definitions. Therefore, the output is incorrect and is a hallucination."}, {"hyp": "A county of Hotan, Sichuan, China.", "ref": "tgt", "src": "The \u201c living fossil \u201d , metasequoia , for example , was once distributed over large areas of Europe , Asia and the Americas from the Cretaceous to the Tertiary periods . Destroyed by glaciers , its natural distribution in China is today limited to Sichuan \u2019s <define> Shizhu </define> county , Hubei \u2019s Lichuan county and Hunan \u2019s Longshan county .", "tgt": "A county of Chongqing, China.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T03:49:35Z", "rationale_0": "The output is a hallucination. The input specifies that Shizhu is a county in Sichuan, China, but the output incorrectly states that it is a county of Hotan, Sichuan, China. There is no mention of Hotan in the input, and it cannot be reasonably inferred from the provided information.", "rationale_1": "The output is a hallucination. The output incorrectly identifies Shizhu as a county of Hotan, Sichuan, China. The input text only states that Shizhu is a county in Sichuan, it does not specify that it is in Hotan. Additionally, the target definition correctly identifies Shizhu as a county of Chongqing, China, contradicting the output.", "rationale_2": "The output is a hallucination. While the output correctly identifies Shizhu as a county in China, it inaccurately places it in the Hotan, Sichuan province. The input text clearly states that Shizhu is a county in Chongqing, not Sichuan. Therefore, the output contains extraneous and incorrect information that does not align with the input.", "rationale_3": "The output is a hallucination. The output inaccurately defines Shizhu as a county of Hotan, Sichuan, China, while the target correctly identifies it as a county of Chongqing, China. The output also cannot be reasonably inferred from the input as the input does not provide any information to suggest that Shizhu is a county of Hotan, Sichuan.", "rationale_4": "The output is a hallucination. The input specifies that Shizhu is a county in Sichuan, China. However, the output incorrectly defines Shizhu as a county of Hotan, Sichuan, China. The target confirms that Shizhu is indeed a county of Chongqing, China. Therefore, the output is incorrect and does not align with the information provided in the input or the target."}, {"hyp": "A small flag.", "ref": "tgt", "src": "Given the present crisis and empty coffers , working meetings geared toward results are more appropriate for politicians than a program of touristy forays , throngs waving <define> flaglets </define> and bulletproof glass , the whole culminating in a neo - feudal state banquet .", "tgt": "A small flag.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T03:49:59Z", "rationale_0": "The output is not a hallucination. The term \"flaglets\" is correctly defined as \"a small flag\" in the output, which matches the target. There is no extraneous or incorrect information given.", "rationale_1": "The output is not a hallucination. The term \"flaglets\" is correctly defined as \"a small flag\" in the output which matches the target. Hence, the output is correct and accurate.", "rationale_2": "The output is not a hallucination. The term \"flaglets\" is correctly defined as \"a small flag\" in the output, which matches the target definition. Therefore, the output is accurate and not a hallucination.", "rationale_3": "The output is not a hallucination. The term \"flaglets\" is correctly defined as \"a small flag\" in the output, which matches the target. This definition is accurate and there is no extraneous information added.", "rationale_4": "The output is not a hallucination. The term \"flaglets\" is correctly and accurately defined as \"a small flag\" in the output, which matches the provided target."}, {"hyp": "(zoology) Of or pertaining to a minotaur.", "ref": "tgt", "src": "Elytra <define> miniatous </define> , with a large somewhat triangular black spot on their disk ,   [ \u2026 ]", "tgt": "(formal) Orange-red, the colour of red lead.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T03:50:32Z", "rationale_0": "The output is a hallucination. The term to be defined is \"miniatous\", not \"minotaur\". The provided definition in the output is irrelevant and unrelated to the term in the input. The target suggests that \"miniatous\" is related to a specific color, not a creature from Greek mythology. Thus, the output is incorrect and inaccurate.", "rationale_1": "The output is a hallucination. The term to define is 'miniatous', however the definition provided in the output pertains to the term 'minotaur'. The correct definition according to the target is related to a color description, not to a mythical creature. Therefore, the output is incorrect and off point.", "rationale_2": "The output is a hallucination. The term to be defined was \"miniatous\", but the output provides a definition related to \"minotaur\", a term from Greek mythology. The target definition indicates that \"miniatous\" refers to a specific color, which is not reflected in the output. Therefore, the output is incorrect and not related to the given input.", "rationale_3": "The output is a hallucination. The term to be defined is \"miniatous\", but the language model provides a definition for a term that is not present in the input, \"minotaur\". This is not related to the given term and is therefore incorrect. The target definition, which describes \"miniatous\" as a specific color, is also not reflected in the output.", "rationale_4": "The output is a hallucination. The term to be defined is \"miniatous\", but the model incorrectly defines it as pertaining to a minotaur, which is a creature from Greek mythology. The target definition indicates that \"miniatous\" should be defined as a color, specifically orange-red. Therefore, the output does not accurately define the term based on the provided target."}, {"hyp": "(chemistry) The degree to which a substance is hydrated.", "ref": "tgt", "src": "DuBois and coworkers carried out extensive studies of the thermodynamic <define> hydricity </define> of metal hydrides ( 3.2 ) ; in many cases the metal product resulting following hydride transfer will bind a CH3CN ligand ( not shown in 3.2 ) , so comparisons of hydricity will be solvent - dependent .", "tgt": "(chemistry) The tendency in a transition metal hydride for an H- ion to transfer to a substrate", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T03:51:10Z", "rationale_0": "The output is a hallucination. The provided definition in the output is incorrect as it talks about the degree to which a substance is hydrated. However, the term 'hydricity' in the context of the input and the target definition refers to the tendency in a transition metal hydride for an H- ion to transfer to a substrate. Thus, the output does not accurately reflect the meaning of the term as given in the input and target.", "rationale_1": "The output is a hallucination. The output defines hydricity as the degree to which a substance is hydrated, which is incorrect. The target definition indicates that hydricity refers to the tendency in a transition metal hydride for an H- ion to transfer to a substrate. The output does not align with the correct definition and is, therefore, a hallucination.", "rationale_2": "The output is a hallucination. The output has incorrectly defined \"hydricity\" as the degree to which a substance is hydrated. However, the target definition indicates that hydricity in chemistry refers to the tendency in a transition metal hydride for an H- ion to transfer to a substrate. The output does not match with the target and is therefore incorrect.", "rationale_3": "The output is a hallucination. The definition given in the output is incorrect. Hydricity in chemistry is not about the degree of hydration of a substance, but about the tendency of an H- ion in a transition metal hydride to transfer to a substrate, as stated in the target. Therefore, the output provided by the language model is not accurate.", "rationale_4": "The output is a hallucination. The term 'hydricity' in the context of the provided scientific text refers to the tendency of a transition metal hydride to transfer an H- ion to a substrate. However, the output defines it as the degree to which a substance is hydrated, which is not the accurate definition in this context."}, {"hyp": "(video games) The state or condition of being bisexual in a video game.", "ref": "tgt", "src": "It can be argued that explicit representations of bisexuality , pansexuality , and other multiple - gender - attracted people are erased from games that use ' <define> playersexuality </define> ' as a mechanic .", "tgt": "(video games) The state of an NPC being attracted to the player character, especially without regard to gender, race, etc.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T03:51:49Z", "rationale_0": "The output is a hallucination. The term 'playersexuality' is inaccurately defined as \"the state or condition of being bisexual in a video game.\" The target definition explains that 'playersexuality' refers to a non-player character (NPC) being attracted to the player character, irrespective of factors like gender or race. This is not the same as bisexuality, which refers to attraction to both male and female genders. The output definition does not accurately reflect the concept of 'playersexuality'.", "rationale_1": "The output is a hallucination. The definition provided in the output is inaccurate. The term 'playersexuality' in the context of video games does not refer to the state of being bisexual. Instead, it refers to an NPC being attracted to the player character, irrespective of the character's gender, race, etc. Therefore, the output definition is incorrect.", "rationale_2": "The output is a hallucination. The term \"playersexuality\" in the context of video games does not specifically refer to bisexuality. Instead, it refers to non-player characters (NPCs) showing attraction to the player character regardless of the player character's gender, race, etc. The output incorrectly defines \"playersexuality\" as the state or condition of being bisexual in a video game, which is not accurate.", "rationale_3": "The output is a hallucination. The term \"playersexuality\" in the context of video games does not specifically refer to bisexuality. Instead, it refers to the ability of a non-player character (NPC) to be attracted to the player character regardless of their gender, race, etc. Thus, the output inaccurately defines the term by narrowing it down to bisexuality.", "rationale_4": "The output is a hallucination. The term 'playersexuality' in video games does not specifically refer to the state or condition of being bisexual. Instead, it refers to a game mechanic where non-player characters (NPCs) are attracted to the player character irrespective of their gender, race, etc. The output inaccurately defined 'playersexuality' as bisexuality in a game, which is not correct."}, {"hyp": "That\u2019s not happening at the moment.", "ref": "either", "src": "That\u2019s not happening.", "tgt": "That isn\u2019t gonna happen.", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T03:52:20Z", "rationale_0": "The output is a hallucination. The original input states \"That's not happening\" and the target paraphrase is \"That isn't gonna happen.\" Both these sentences imply a definite and absolute condition, whereas the output \"That's not happening at the moment\" introduces a temporal element, suggesting the situation could change in the future. This is an additional information that was not present or implied in the input, hence it can be considered a hallucination.", "rationale_1": "The output is a hallucination. The input states \"That\u2019s not happening,\" which has a definitive, absolute tone, indicating something is not going to occur. The target paraphrase maintains this absolute tone. However, the output \"That\u2019s not happening at the moment,\" suggests a temporary situation implying that it's not happening now, but it might happen later. This temporal element is not present or implied in the input, making it extraneous information and thus a hallucination.", "rationale_2": "The output is a hallucination. The original input statement was absolute, asserting that something is not happening. The output, however, adds extra information, implying that the event might happen later, which is not present or inferred from the original input. Therefore, the output is incorrect and contains extraneous information.", "rationale_3": "The output is a hallucination. The input statement is absolute, stating that something is not happening. The output, however, adds an unnecessary time constraint (\"at the moment\"), which is not included or inferred from the input. Therefore, it introduces new information that wasn't in the original statement.", "rationale_4": "The output is a hallucination. While it is a paraphrase of the input, it adds extra information (\"at the moment\") that was not present or implied in the input, making it inaccurate."}, {"hyp": "I have a permit to carry it.", "ref": "either", "src": "I have a permit.", "tgt": "Uh, I\u2019m validated.", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T03:52:49Z", "rationale_0": "The output is a hallucination. The input states \"I have a permit\" without specifying what the permit is for. The output, however, adds extraneous information, specifying that the permit is \"to carry it\", which cannot be inferred from the input.", "rationale_1": "The output is a hallucination. The input states \"I have a permit\" but doesn't specify what the permit is for. The output, however, specifies that the permit is for carrying something, which is an addition that can't be inferred from the input. This makes the output a hallucination as it contains extraneous information.", "rationale_2": "The output is a hallucination. The input sentence \"I have a permit\" is generalized and doesn't specify what the permit is for. However, the output \"I have a permit to carry it\" adds information that was not present or implied in the input, specifically mentioning \"carry it\". This is an assumption made by the model, thus it is a hallucination.", "rationale_3": "The output is a hallucination. The input statement \"I have a permit\" is broad and doesn't specify what the permit is for. The output \"I have a permit to carry it\" assumes that the permit is for carrying something, which is an addition that isn't mentioned or inferred in the input. Therefore, the output contains extraneous information and is considered a hallucination.", "rationale_4": "The output is a hallucination. The input \"I have a permit\" does not specify what the permit is for, while the output assumes and specifies that it is a permit to carry something, which is an addition of information not present or implied in the input. Thus, it is a hallucination."}, {"hyp": "The process is easy.", "ref": "either", "src": "Easy, easy.", "tgt": "Watch it now.", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Hallucination", "Hallucination", "Not Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T03:53:25Z", "rationale_0": "The output is a hallucination. The input phrase \"Easy, easy\" could be interpreted as someone trying to calm another down or indicating that something is simple. However, the output \"The process is easy\" introduces a new concept (\"the process\") that wasn't present or implied in the original phrase, making it a hallucination.", "rationale_1": "The output is a hallucination. The output phrase \"The process is easy\" introduces a new concept (\"process\") that was not present or implied in the input phrase \"Easy, easy\". It is an incorrect interpretation and contains extraneous information that cannot be reasonably inferred from the input.", "rationale_2": "The output is a hallucination. The input simply repeats the word \"easy\" twice, which does not necessarily indicate that a process is easy. The output is adding information that could not be reasonably inferred from the input. Furthermore, the output does not align with the target (\"Watch it now.\"), suggesting that the output is incorrect.", "rationale_3": "The output is a hallucination. The original input \"Easy, easy\" is a phrase commonly used to tell someone to slow down or be careful, as indicated by the target \"Watch it now.\" However, the output \"The process is easy\" is an entirely different context, inferring that a process or task is straightforward or simple to perform. There is no direct correlation or accurate paraphrase between the input and the output.", "rationale_4": "The output is a hallucination. The input \"Easy, easy.\" is more likely a call for caution or to slow down, as indicated by the target \"Watch it now.\" The output \"The process is easy.\" suggests a different context and meaning, interpreting \"easy\" as a descriptor for a process, which is not implied in the input."}, {"hyp": "A number between five and eight.", "ref": "either", "src": "A five, six, seven, eight.", "tgt": "And 5, 6, 7, 8.", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Hallucination", "Hallucination", "Not Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T03:53:57Z", "rationale_0": "The output is a hallucination. The input simply lists a sequence of numbers, while the output introduces a new concept of a \"number between five and eight\", which is not present in the input. Therefore, the output is not a correct or accurate paraphrase of the input.", "rationale_1": "The output is a hallucination. The input suggests a list of consecutive numbers - five, six, seven, eight. However, the output interprets this as a range \u2013 'a number between five and eight'. This interpretation is not accurate as it adds extraneous information not present or reasonably inferred from the input.", "rationale_2": "The output is a hallucination. The input is a list of sequential numbers (five, six, seven, eight) and the target paraphrase maintains this list accurately. However, the output changes the meaning entirely to suggest a number between five and eight, which is not an accurate paraphrase of the input.", "rationale_3": "The output is a hallucination. The input is simply listing four sequential numbers (five, six, seven, eight), but the output incorrectly interprets it as a range (\"a number between five and eight\"). The output should have maintained the list of numbers as separate entities, like in the target (\"And 5, 6, 7, 8\").", "rationale_4": "The output is a hallucination. The input lists four distinct numbers in word form: five, six, seven, and eight. The output, however, incorrectly summarizes this as \"a number between five and eight.\" This changes the meaning of the original sentence, as it implies that only one number is being referred to, rather than four. Therefore, the output is not a correct or accurate paraphrase of the input."}, {"hyp": "That is a safer way to travel.", "ref": "either", "src": "A lot safer that way.", "tgt": "Because it\u2019s safer.", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T03:54:32Z", "rationale_0": "The output is not a hallucination. The output is a paraphrase of the input and maintains the same meaning, which is that a certain way or method is safer. The output does not introduce any new or extraneous information that is not present or suggested in the input.", "rationale_1": "The output is not a hallucination. It accurately paraphrases the input statement \"A lot safer that way\" by interpreting it as referring to a safer way to travel. Even though the concept of \"travel\" is not explicitly mentioned in the input, it is a reasonable inference given the common use of phrases like \"safer that way\" to refer to methods of travel or transportation. Therefore, the output is correct and not a hallucination.", "rationale_2": "The output is not a hallucination. It accurately paraphrases the original input, albeit with the addition of the inferred context of \"travel\". While the input did not specifically mention travel, this context can be reasonably inferred and does not constitute extraneous information. The output maintains the core message of the input and the target, which is the emphasis on safety.", "rationale_3": "The output is not a hallucination. It correctly paraphrases the input by conveying the same meaning in a different way. The input \"A lot safer that way\" implies that a certain method or strategy is safer, and the output \"That is a safer way to travel\" conveys the same implication, albeit in a slightly more specific context of travel. Even though the output specifies \"travel\", it does not add any extraneous information or deviate from the intended meaning of the input.", "rationale_4": "The output is not a hallucination. It accurately paraphrases the input by conveying the same message. The output phrase \"That is a safer way to travel\" implies that the way referred to is safer, which is the same message conveyed in the input \"A lot safer that way\"."}, {"hyp": "You\u2019re not a good scam artist.", "ref": "either", "src": "You\u2019re a scam artist.", "tgt": "You are an imposter.", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T03:55:06Z", "rationale_0": "The output is a hallucination. While the input and target both assert that the individual is a scam artist or an imposter, the output introduces new information by qualifying the type of scam artist the person is, suggesting they are \"not good\". This value judgment is not suggested or implied in either the input or target, thus making the output a hallucination.", "rationale_1": "The output is a hallucination. The target paraphrase suggests that the person is being accused of being an imposter, which aligns with the input. However, the output generated by the language model changes the meaning by suggesting that the person is not a good scam artist, rather than simply being a scam artist or imposter. This includes the evaluation of their skills as a scam artist, which is extraneous information not present or implied in the input.", "rationale_2": "The output is a hallucination. The target paraphrase is \"You are an imposter\", which maintains the negative connotation of the original input \"You\u2019re a scam artist.\" However, the generated output \"You\u2019re not a good scam artist\" changes the sentiment and meaning of the original phrase by implying that the person is a scam artist, but not a capable one. Therefore, the output includes extraneous information not present or inferred from the input.", "rationale_3": "The output is a hallucination. The original input sentence and the target both convey the accusation that the person being spoken to is a scam artist or imposter. However, the output alters the meaning by suggesting that the person is not good at being a scam artist, which is an addition of information not found in the original input or target.", "rationale_4": "The output is a hallucination. The input statement is accusing someone of being a scam artist, while the output is not only failing to paraphrase the input accurately, but it is also adding extraneous information - the quality of the person's scamming skills. The output should have been something along the lines of the target, \"You are an imposter,\" to accurately paraphrase the input."}, {"hyp": "When did you see him?", "ref": "either", "src": "When\u2019d you last see him?", "tgt": "When was the last time you saw him?", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T03:55:30Z", "rationale_0": "The output is not a hallucination. Although it is not an exact match of the target, it maintains the original meaning of the input. The output is essentially asking the same question as the input, only with slightly different wording.", "rationale_1": "The output is not a hallucination. It is a correct and straightforward paraphrase of the input, even though it slightly lacks the specificity of the target. The target phrasing emphasizes the \"last time\" one saw the person, while the output simply asks when the person was seen, which could theoretically refer to any time they were seen. However, the output does not add or infer any extraneous information that isn't present in the input.", "rationale_2": "The output is not a hallucination. It correctly paraphrases the input, maintaining its essential meaning. However, it does not precisely match the target, as it omits the \"last time\" aspect. Nonetheless, it is not incorrect or off point, and does not include any extraneous information.", "rationale_3": "The output is not a hallucination. It accurately paraphrases the input, although it doesn't exactly match the target. The meaning conveyed by the output is similar to the input, even though it omits the \"last time\" part. Therefore, the output is correct and not a hallucination.", "rationale_4": "The output is not a hallucination. Although it does not perfectly match the target, it still conveys the same general meaning as the input. The output is a simpler version, but it does not introduce any new or incorrect information."}, {"hyp": "Let me leave.", "ref": "either", "src": "Let me out of here.", "tgt": "Someone let me out.", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T03:55:55Z", "rationale_0": "The output is not a hallucination. It correctly paraphrases the input, \"Let me out of here,\" without introducing any extraneous or incorrect information. Both the target and the output convey the same meaning as the input, which is a request to be allowed to leave a certain place.", "rationale_1": "The output is not a hallucination. It accurately captures the essence of the input and target, which is a demand or plea to be allowed to leave or be released from a certain place. There is no extraneous or incorrect information added in the output.", "rationale_2": "The output is not a hallucination. It accurately paraphrases the input, \"Let me out of here,\" by changing the wording to \"Let me leave.\" Both sentences convey the same meaning of the speaker wanting to exit a location.", "rationale_3": "The output is not a hallucination. It accurately conveys the same meaning as the input. Both phrases express a desire to leave or be released from a location or situation, therefore it is a correct paraphrase.", "rationale_4": "The output is not a hallucination. The input \"Let me out of here\" has been correctly paraphrased as \"Let me leave\" in the output. The meaning has been preserved and there is no addition of extraneous or off-point information."}, {"hyp": "It is not impossible.", "ref": "either", "src": "Nothing is impossible.", "tgt": "There\u2019s nothing that can\u2019t be done.", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T03:56:18Z", "rationale_0": "The output is not a hallucination. It accurately paraphrases the input, \"Nothing is impossible,\" by stating, \"It is not impossible.\" Both sentences convey the same meaning of possibility.", "rationale_1": "The output is not a hallucination. It accurately paraphrases the original input \"Nothing is impossible\" to \"It is not impossible.\" Both phrases convey the same meaning, thus making the output accurate and not a hallucination.", "rationale_2": "The output is not a hallucination. It accurately paraphrases the input \"Nothing is impossible\" without adding or inferring any extraneous information. However, it doesn't exactly match the target, but that doesn't make it a hallucination.", "rationale_3": "The output is not a hallucination. It correctly conveys the same meaning as the input sentence, albeit in a slightly different wording. It does not include any extraneous or incorrect information.", "rationale_4": "The output is not a hallucination. While it does not exactly match the target, it is still a valid paraphrase of the given input. Both the input and the output convey the same message, that there is no such thing as impossible."}, {"hyp": "Tom decided to leave the company.", "ref": "either", "src": "Tom d\u00e9cida de quitter la soci\u00e9t\u00e9.", "tgt": "Tom has decided to leave the company.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T03:56:48Z", "rationale_0": "The output is not a hallucination. The language model correctly translated the French sentence into English. The only difference between the target and output is the use of present perfect tense (\"has decided\") in the target versus past simple tense (\"decided\") in the output. However, both tenses are correct in this context and accurately represent the meaning of the original French sentence.", "rationale_1": "The output is not a hallucination. It accurately translates the French sentence into English. The only difference between the target and output is that the target uses \"has decided\" while the output uses \"decided\", but both are correct translations and convey the same meaning.", "rationale_2": "The output is not a hallucination. The translation from French to English is accurate. The only difference between the output and the target is the tense of the verb \"decide\". In the target, it's \"has decided\" (present perfect tense) while in the output, it's \"decided\" (past tense). However, both are correct translations for the French past tense \"d\u00e9cida\".", "rationale_3": "The output is not a hallucination. The output accurately translates the French input to English. Although the output uses the simple past tense (\"decided\") instead of the present perfect tense (\"has decided\") used in the target, both tenses are acceptable translations of the French past tense (\"d\u00e9cida\"). Therefore, there is no error or extraneous information in the translation.", "rationale_4": "The output is not a hallucination. It accurately translates the input from French to English. The only difference between the output and the target is the tense - the target uses present perfect (\"has decided\") while the output uses simple past (\"decided\"). But both tenses work correctly in this context in English and accurately represent the meaning of the original French sentence, which is in the past tense."}, {"hyp": "Do you love her?", "ref": "either", "src": "Est-ce que tu l'aimes ?", "tgt": "Do you love him?", "model": "", "task": "MT", "labels": ["Not Hallucination", "Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T03:57:15Z", "rationale_0": "The output is a hallucination. The input in French is asking if \"you love him\", not \"her\". Therefore, the translation should be \"Do you love him?\" not \"Do you love her?\" The model has incorrectly translated the gender.", "rationale_1": "The output is a hallucination. In the French language, the object pronoun \"le\" is masculine and translates to \"him\" in English. However, the output incorrectly translates \"le\" to \"her\". Therefore, the output is not accurate.", "rationale_2": "The output is a hallucination. While the translation is almost correct, it inaccurately translates \"l'aimes\" as \"love her\" instead of the correct \"love him\". Thus, the gender of the person being referred to is incorrectly inferred in the output.", "rationale_3": "The output is a hallucination. The French pronoun \"le\" in \"tu l'aimes\" translates to \"him\" in English, not \"her\". Therefore, the correct translation should be \"Do you love him?\" not \"Do you love her?\" The model incorrectly inferred the gender of the object in the sentence.", "rationale_4": "The output is a hallucination. The French pronoun \"le\" translates to \"him\" in English, not \"her\". Therefore, the correct translation is \"Do you love him?\" as indicated in the target. The language model inaccurately translated \"le\" as \"her\", making the output incorrect."}, {"hyp": "I got the company.", "ref": "either", "src": "J'ai de la compagnie.", "tgt": "I've got company.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T03:57:51Z", "rationale_0": "The output is not a hallucination, but it is not entirely accurate. The translation is not incorrect but it is not as precise as the target. The phrase \"I got the company\" could imply ownership of a business, while the target translation \"I've got company\" implies that there are other people present. Thus, the output could lead to some confusion due to its ambiguity.", "rationale_1": "The output is not a hallucination. However, it is not entirely correct or accurate. The translation \"I got the company\" is not the best translation for \"J'ai de la compagnie\". The more accurate translation is indeed the target \"I've got company\". The output does not contain extraneous or off point information, but it is slightly incorrect.", "rationale_2": "The output is not a hallucination. However, it is not perfectly accurate. The correct translation of the French phrase \"J'ai de la compagnie\" is \"I've got company\". The provided output \"I got the company\" is incorrect because it changes the meaning of the sentence. Instead of referring to having company or guests, it suggests ownership of a company. So, the output is inaccurate but not a hallucination as it doesn't add any extraneous information.", "rationale_3": "The output is not a hallucination, but it's not entirely correct. The output, \"I got the company\", could imply that the person acquired or obtained a business, which is not what the original French sentence is saying. The target translation, \"I've got company\", is more accurate as it means someone is with the speaker. So, while the output is not a hallucination, it is not an accurate translation.", "rationale_4": "The output is not a hallucination. However, it is not entirely correct and accurate either. The translation provided, \"I got the company,\" could imply that the speaker has acquired a business, which is not the meaning conveyed in the original French sentence. The correct translation is provided in the target: \"I've got company,\" which means that the speaker is not alone. The output does not add any extraneous information, but it does misinterpret the meaning of the original phrase."}, {"hyp": "He's got several friends.", "ref": "either", "src": "Ann a plusieurs amis.", "tgt": "Ann has many friends.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T03:58:18Z", "rationale_0": "The output is a hallucination. The input sentence is about \"Ann\" but the output wrongly refers to a male subject \"He\". Thus, the translation is not accurate.", "rationale_1": "The output is a hallucination. The main issue here is the wrong translation of the subject \"Ann\" to \"He\". Instead of accurately translating the sentence as \"Ann has several friends\", the model incorrectly translates it as \"He's got several friends.\" The gender of Ann is not inferred correctly and there's an incorrect use of pronoun instead of the proper noun. Hence, the output is not accurate.", "rationale_2": "The output is a hallucination. The input text mentions \"Ann,\" a female name, but in the output, the pronoun used is \"He\". The correct translation should use \"She\" to correctly represent \"Ann\". So, the output inaccurately represents the gender of the subject mentioned in the input.", "rationale_3": "The output is a hallucination. While the output is a correct translation of the sentence, it incorrectly identifies the subject of the sentence. The input sentence is about \"Ann,\" but the output sentence refers to an unidentified \"He.\" This indicates that the language model has inaccurately translated the subject of the sentence.", "rationale_4": "The output is a hallucination. The input sentence is about \"Ann\" but the output sentence refers to a \"He\". The gender and identity of the subject have been incorrectly translated."}, {"hyp": "The captain orders the ship on board.", "ref": "either", "src": "Le capitaine donne l'ordre d'embarquer sur le navire.", "tgt": "The skipper is giving the order to board the ship.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T03:58:47Z", "rationale_0": "The output is incorrect and therefore can be considered as a hallucination. The main error lies in the incorrect translation of the phrase \"d'embarquer sur le navire\" which should be \"to board the ship\" but has been incorrectly translated as \"the ship on board.\" Thus, the intended meaning of the sentence has been distorted in the output.", "rationale_1": "The output is a hallucination. While it does translate some elements of the sentence correctly, it incorrectly suggests that the captain is ordering the ship on board, which is nonsensical. The accurate translation, as provided in the target, is that the captain is giving the order to board (or embark on) the ship.", "rationale_2": "The output is a hallucination. The output mistranslates the sentence by saying \"The captain orders the ship on board\" which does not make sense. The correct translation should be \"The captain gives the order to board the ship\" as indicated in the target. Therefore, the output is not accurate.", "rationale_3": "The output is a hallucination. The output, \"The captain orders the ship on board,\" is not a correct translation of the input. The phrase 'orders the ship on board' does not make sense in English. The correct translation is provided in the target: \"The skipper is giving the order to board the ship.\" The output therefore is incorrect and off point.", "rationale_4": "The output is a hallucination. While it does translate some parts of the sentence correctly, it changes the overall meaning of the sentence. The correct translation should be \"The captain gives the order to board the ship\", as seen in the target. Instead, the output suggests that the captain is ordering the ship on board, which does not make sense, as ships don't board. Therefore, the output is not an accurate translation of the input."}, {"hyp": "Sami called 911.", "ref": "either", "src": "Sami a appel\u00e9 le 911.", "tgt": "Sami made a call to 911.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T03:59:17Z", "rationale_0": "The output is not a hallucination. It accurately translates the French sentence \"Sami a appel\u00e9 le 911\" into English as \"Sami called 911\". Although the translation is not verbatim with the target (\"Sami made a call to 911\"), it still accurately conveys the same meaning.", "rationale_1": "The output is not a hallucination. It accurately translates the input from French to English. While the output does not use the exact phrase \"made a call to,\" the word \"called\" in this context has the same meaning, making this an accurate translation.", "rationale_2": "The output is not a hallucination. It accurately translates the French sentence \"Sami a appel\u00e9 le 911\" into English. While it is not a word-for-word translation of the target (\"Sami made a call to 911\"), it still correctly conveys the same meaning.", "rationale_3": "The output is not a hallucination. It accurately translates the French sentence \"Sami a appel\u00e9 le 911\" into English. Both the output \"Sami called 911\" and the target \"Sami made a call to 911\" convey the same meaning, even though the wording is slightly different. Therefore, the output is correct and not a hallucination.", "rationale_4": "The output is not a hallucination. It accurately translates the French sentence \"Sami a appel\u00e9 le 911\" to English. Although the output is not a verbatim translation of the target (\"Sami made a call to 911\"), it still correctly conveys the same meaning."}, {"hyp": "We love our school.", "ref": "either", "src": "Nous aimons notre \u00e9cole.", "tgt": "We like our school.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Hallucination", "Not Hallucination", "Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.4, "timestamp": "2023-11-05T03:59:44Z", "rationale_0": "The output is not a hallucination, but it is not fully accurate. The French verb \"aimons\" translates to \"like\" in English, not \"love\". Therefore, while the overall meaning is similar, the degree of affection expressed in the output is slightly stronger than in the input.", "rationale_1": "The output is not a hallucination. However, it is not entirely accurate either. The French verb \"aimons\" translates to \"like\" in English, not \"love\". While \"love\" is not completely off point, it is a stronger emotion than \"like\". Therefore, the output translation is not completely correct.", "rationale_2": "The output is a hallucination. The French verb \"aimons\" translates to \"like\" in English, not \"love\". Thus, the translation is not accurate.", "rationale_3": "The output is a hallucination. The original French sentence, \"Nous aimons notre \u00e9cole,\" translates directly to \"We love our school,\" not \"We like our school\" as given in the target. The output correctly translates the French sentence, therefore it is not a hallucination.", "rationale_4": "The output is a hallucination. The French verb \"aimons\" is translated as \"like\" in English, but the model incorrectly translated it as \"love\". Although \"like\" and \"love\" have similar meanings, they do not have the same intensity of feeling or preference. Therefore, the output is not an accurate translation of the input."}, {"hyp": "How'd you get \"pretty\"?", "ref": "either", "src": "Comment \u00e9pelles-tu \"pretty\" ?", "tgt": "How do you spell \"pretty\"?", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T04:00:17Z", "rationale_0": "The output is a hallucination. The input is asking for a spelling of the word \"pretty\", but the output is not providing the spelling. Instead, it's asking an unrelated question \"How'd you get \"pretty\"?\", which is not inferred from the input.", "rationale_1": "The output is a hallucination. The correct translation of the given input is provided in the target, \"How do you spell 'pretty'?\" However, the output \"How'd you get 'pretty'?\" does not accurately reflect this. The output seems to ask how the term 'pretty' was arrived at or chosen, which is not what the original French input is asking.", "rationale_2": "The output is a hallucination. The correct translation of the input from French to English is \"How do you spell 'pretty'?\", as indicated in the target. However, the output \"How'd you get 'pretty'?\" does not accurately represent this, but instead introduces a completely different question. Therefore, the output is not correct.", "rationale_3": "The output is a hallucination. The input asks for a translation of a question about how to spell a word. However, the output produced by the model changes the meaning entirely, asking instead how the word was obtained. Thus, the output is not accurate or correct.", "rationale_4": "The output is a hallucination. The correct translation from French to English of the input \"Comment \u00e9pelles-tu \"pretty\" ?\" is \"How do you spell \"pretty\"?\" However, the output \"How'd you get \"pretty\"?\" doesn't match the target and is thus incorrect. This seems to be a misunderstanding or incorrect translation of the question being asked."}, {"hyp": "The old days will never come back.", "ref": "either", "src": "Les jours anciens ne reviendront jamais.", "tgt": "The old days have gone never to return.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T04:00:50Z", "rationale_0": "The output is not a hallucination. Although the output doesn't match the target exactly, it correctly and accurately translates the meaning of the original French sentence, \"Les jours anciens ne reviendront jamais.\" Both \"The old days will never come back\" and \"The old days have gone never to return\" convey the same sentiment and meaning, the former is just slightly more direct and literal.", "rationale_1": "The output is not a hallucination. It accurately translates the French sentence into English. Although the output isn't a literal translation of the input, it conveys the same meaning as the target sentence.", "rationale_2": "The output is not a hallucination. Although the output is not an exact translation of the target, it correctly and accurately conveys the same meaning as the input sentence. The phrase \"The old days will never come back\" is essentially equivalent to \"The old days have gone never to return\" in meaning.", "rationale_3": "The output is not a hallucination. Although the output doesn't match exactly with the target, it still correctly and accurately translates the original input from French to English. Both the output and target convey the same overall meaning that the old days will not return.", "rationale_4": "The output is not a hallucination. Although the output is not a literal translation of the input, the meaning remains the same. Both the target and output translations suggest that the old days are not going to return. There might be slight variations in how it's expressed, but the core message is maintained. Therefore, the output is correct and accurate."}, {"hyp": "I bought three different varieties of flowers.", "ref": "either", "src": "J\u2019ai achet\u00e9 trois diff\u00e9rentes sortes de fleurs.", "tgt": "I bought three different kinds of flowers.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T04:01:17Z", "rationale_0": "The output is not a hallucination. Although the translation uses the term \"varieties\" instead of \"kinds\", both words have very similar meanings and can be used interchangeably in this context. Hence, the output accurately conveys the meaning of the original French sentence.", "rationale_1": "The output is not a hallucination. Although the exact wording is slightly different (\"kinds\" in the target vs \"varieties\" in the output), the meaning remains the same. The output is a correct and accurate translation of the input.", "rationale_2": "The output is not a hallucination. While the exact wording differs from the target, both \"kinds\" and \"varieties\" convey the same meaning in this context. The output accurately translates the key information from the input.", "rationale_3": "The output is not a hallucination. The translation from French to English is correct and accurate. While the target translation uses \"kinds\" and the output uses \"varieties,\" both words have similar meanings and accurately convey the information from the original French sentence.", "rationale_4": "The output is not a hallucination. While the specific words used in the translation differ slightly from the target (\"varieties\" instead of \"kinds\"), the overall meaning of the sentence remains the same. The output accurately and correctly translates the original French sentence."}, {"hyp": "It's my duty.", "ref": "either", "src": "C'est mon m\u00e9tier.", "tgt": "It's my job.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T04:01:48Z", "rationale_0": "The output is not a hallucination. Although it doesn't match the target exactly, the output is a reasonable interpretation of the input. In French, \"C'est mon m\u00e9tier\" can be translated as \"It's my job\" or \"It's my duty\". Both translations capture the essence of the original statement.", "rationale_1": "The output is not a hallucination. While it does not match the target exactly, it still correctly translates the meaning of the input. \"M\u00e9tier\" in French can be translated as both \"job\" and \"duty\" in English, depending on the context. Therefore, both \"It's my job\" and \"It's my duty\" are correct translations of \"C'est mon m\u00e9tier.\"", "rationale_2": "The output is not a hallucination. While the translation is not exact, the output \"It's my duty\" still conveys a similar meaning to the target \"It's my job\". The words \"job\" and \"duty\" can be interchangeable in some contexts. Therefore, it's not entirely incorrect or off point, it's just a less precise translation.", "rationale_3": "The output is not a hallucination. While the output is not a direct translation of the target, the term \"duty\" can be seen as a synonym for \"job\" in this context. Therefore, it is not incorrect or off point. However, it's worth noting that the translation could be more accurate to the original French phrase by using the word \"job\" instead of \"duty\".", "rationale_4": "The output is not a hallucination. Although it is not a direct translation of the input, as the target suggests, it still conveys a very similar meaning. The words \"job\" and \"duty\" can often be used interchangeably in English. Therefore, while it may not be the most accurate translation, it does not introduce any extraneous or incorrect information."}, {"hyp": "I have nothing to do with it.", "ref": "either", "src": "J'en ai rien \u00e0 secouer.", "tgt": "I don't give a shit about it.", "model": "", "task": "MT", "labels": ["Hallucination", "Not Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "predictions": ["Hallucination", "Not Hallucination", "Not Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 0.6000000000000001, "timestamp": "2023-11-05T04:02:31Z", "rationale_0": "The output is a hallucination. Although the output is a possible translation of the input, it is not accurately capturing the original sentiment or intensity. The French phrase \"J'en ai rien \u00e0 secouer\" is a colloquialism that translates more accurately to the target, \"I don't give a shit about it\", indicating strong indifference or disdain. The output, \"I have nothing to do with it\", while grammatically correct, lacks this emotional intensity and changes the original meaning.", "rationale_1": "The output is not a hallucination. However, it is not entirely accurate. The phrase \"J'en ai rien \u00e0 secouer\" is a colloquial and somewhat vulgar way to say \"I don't care\" in French, similar to the English phrase \"I don't give a shit.\" The output, \"I have nothing to do with it,\" is not an accurate translation because it loses the original phrase's tone and intensity. While it is true that the speaker does not care about the subject in both sentences, the output fails to capture the dismissive and indifferent attitude expressed in the input.", "rationale_2": "The output is not a hallucination. It is a correct translation, but it's not as accurate or idiomatic as the target. The literal translation of \"J'en ai rien \u00e0 secouer\" is indeed \"I have nothing to shake off\". However, in the idiomatic and contextual sense, it equates to \"I don't give a shit about it\". The output fails to capture this idiomatic meaning fully, but it does not add or infer any extraneous information from the input. Thus, it's not a hallucination, just a less accurate translation.", "rationale_3": "The output is a hallucination. While the output may be a literal translation of the input, it does not accurately capture the intended meaning. The French phrase \"J'en ai rien \u00e0 secouer\" is an informal and somewhat vulgar way to say \"I don't care\" or \"I don't give a shit\", as indicated in the target. The output \"I have nothing to do with it\" does not convey the same level of indifference or dismissiveness.", "rationale_4": "The output is a hallucination. While it accurately translates the words from the input, it fails to capture the colloquial and dismissive tone of the phrase. The French phrase \"J'en ai rien \u00e0 secouer\" is a vulgar way of expressing indifference, more similar in tone to \"I don't give a shit about it,\" rather than the more neutral \"I have nothing to do with it.\""}, {"hyp": "I've been confiscated.", "ref": "either", "src": "On m'a confisqu\u00e9 mon permis.", "tgt": "I've had my driving license confiscated.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T04:03:04Z", "rationale_0": "The output is a hallucination. The correct translation of \"On m'a confisqu\u00e9 mon permis\" is \"I've had my driving license confiscated.\" However, the model only outputs \"I've been confiscated,\" which is both grammatically incorrect and fails to include key information from the input, such as the fact that it is the driving license that has been confiscated.", "rationale_1": "The output is a hallucination. The output does not accurately translate the input. The original French sentence, \"On m'a confisqu\u00e9 mon permis,\" translates to \"I've had my driving license confiscated.\" However, the output, \"I've been confiscated,\" is incorrect and missing important information about the driver's license being confiscated.", "rationale_2": "The output is a hallucination. The translation provided is not only incorrect but also incomplete. The original French sentence indicates that the speaker's driving license has been confiscated. However, the output merely states, \"I've been confiscated,\" which not only misses the subject (the driving license) but is also nonsensical as it suggests the speaker themselves has been confiscated.", "rationale_3": "The output is a hallucination. The translation provided in the output is not only incorrect, but it also doesn't convey the complete information from the input. The original French sentence discusses the confiscation of a driving license, but the output simply states \"I've been confiscated,\" which is not only grammatically incorrect but also fails to mention the driving license.", "rationale_4": "The output is a hallucination. The output \"I've been confiscated\" is not a correct translation of the input \"On m'a confisqu\u00e9 mon permis.\" The correct translation is \"I've had my driving license confiscated,\" as indicated in the target. The output misses the crucial information about the driving license being confiscated."}, {"hyp": "Stop turning.", "ref": "either", "src": "Arr\u00eate de tourner.", "tgt": "Stop spinning.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T04:03:37Z", "rationale_0": "The output is not a hallucination. Although the output does not exactly match the target, \"Stop turning\" is a reasonable and correct translation of \"Arr\u00eate de tourner.\" Both \"spinning\" and \"turning\" can be appropriate translations for \"tourner,\" depending on the context. Therefore, the output is accurate and not a hallucination.", "rationale_1": "The output is not a hallucination. Although the output translation is \"Stop turning\" instead of the target \"Stop spinning\", both convey the same meaning. The verb \"tourner\" in French can be translated as either \"turning\" or \"spinning\" in English, depending on the context. Therefore, this output is accurate and not a hallucination.", "rationale_2": "The output is not a hallucination. While the output \"Stop turning\" is not an exact match for the target \"Stop spinning\", it is a correct and accurate translation of the French sentence \"Arr\u00eate de tourner\". Both \"turning\" and \"spinning\" can be used to translate \"tourner\" depending on the context.", "rationale_3": "The output is not a hallucination. While the output is not an exact match to the target, both convey the same meaning. In French, \"tourner\" can be translated as both \"turn\" and \"spin\" in English. Therefore, the translation provided is still correct and accurately represents the original input, even if it is not a word-for-word match to the target.", "rationale_4": "The output is not a hallucination. While the exact word used in the translation (\"turning\" instead of \"spinning\") differs from the target, both words convey a similar meaning in the given context. Therefore, the output is still a correct and coherent translation of the input."}, {"hyp": "What kind of bread are you eating in general?", "ref": "either", "src": "Quel genre de pain est-ce que tu manges en g\u00e9n\u00e9ral ?", "tgt": "What kind of bread do you usually eat?", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T04:04:05Z", "rationale_0": "The output is not a hallucination. While it is not an exact match to the target, it does accurately and correctly translate the meaning of the input. Both the target and output are asking about the respondent's usual or general bread-eating habits.", "rationale_1": "The output is not a hallucination. It accurately translates the meaning of the input from French to English, though the phrasing is slightly different from the target. Both versions convey the same general idea of the speaker asking about the listener's typical bread consumption.", "rationale_2": "The output is not a hallucination. It is a correct translation of the input, although it's phrased slightly differently than the target. Both sentences in English mean essentially the same thing. Thus, the output is accurate and on point, even if it's not an exact match for the target.", "rationale_3": "The output is not a hallucination. It accurately translates the input from French to English. However, the choice of phrase \"are you eating in general?\" is less common than the target \"do you usually eat?\". Despite this slight variation, the meaning is still correctly conveyed, hence it is not a hallucination.", "rationale_4": "The output is not a hallucination. Although the output translation differs slightly from the target, it still accurately conveys the meaning of the original input. The use of \"in general\" instead of \"usually\" is a reasonable semantic equivalent in translating the original French sentence."}, {"hyp": "The eagles are friends.", "ref": "either", "src": "Les araign\u00e9es sont mignonnes.", "tgt": "Spiders are cute.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T04:04:38Z", "rationale_0": "The output is a hallucination. The input sentence in French translates to \"Spiders are cute\" in English. However, the output provided is \"The eagles are friends,\" which is not a correct translation. The output introduces new entities ('eagles' and 'friends') that are not mentioned or implied in the input, hence it is a hallucination.", "rationale_1": "The output is a hallucination. The input sentence in French translates to \"Spiders are cute\" in English. However, the output provided incorrectly translates it to \"The eagles are friends\", which is not only incorrect, but also introduces a completely different subject (eagles instead of spiders) and adjective (friends instead of cute).", "rationale_2": "The output is a hallucination. The input sentence is about spiders being cute in French, but the generated output is about eagles being friends which is not an accurate translation of the input. The output is completely unrelated to the original input, making it a hallucination.", "rationale_3": "The output is a hallucination. The input sentence in French translates to \"Spiders are cute\" in English. However, the output provided, \"The eagles are friends,\" is not an accurate translation as it does not maintain the same meaning or subject matter. It is clear that the output is incorrect and not related to the input.", "rationale_4": "The output is a hallucination. The input sentence in French is \"Les araign\u00e9es sont mignonnes,\" which translates to \"Spiders are cute\" in English. The output, \"The eagles are friends,\" is not only a completely different sentence, but it also introduces a new subject (\"eagles\") and predicate (\"are friends\") that were not present or implied in the original French sentence. Therefore, the output is incorrect and can be classified as a hallucination."}, {"hyp": "Farhat Mehenni's separatist group concluded a compromise with the radical Islamist group Rachad for the destabilization of Algeria. This led Algeria to officially consider the two groups as terrorist organizations.", "ref": "either", "src": "Le groupe s\u00e9paratiste de Ferhat Mehenni a conclu un compromis avec le groupe islamiste radical Rachad pour la d\u00e9stabilisation de l'Alg\u00e9rie. C'est ce qui a conduit l'Alg\u00e9rie \u00e0 officiellement consid\u00e9rer les deux groupes comme des organisations terroristes.", "tgt": "Ferhat Mehenni's separatist group cut a deal with the radical Islamist group Rachad to destabilize Algeria. That's what led Algeria to officially consider both groups as terrorist organizations.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T04:05:07Z", "rationale_0": "The output is not a hallucination. It accurately translates the input from French to English. The slight difference in word choice \"concluded a compromise\" instead of \"cut a deal\" does not change the overall meaning of the sentence. Therefore, the output is correct and accurate.", "rationale_1": "The output is not a hallucination. It accurately translates the input from French to English. Although the phrase \"cut a deal\" in the target is translated as \"concluded a compromise\" in the output, both phrases essentially mean the same thing in this context. Therefore, the output accurately and correctly conveys the same information as the input.", "rationale_2": "The output is not a hallucination. It accurately and correctly translates the input from French to English without adding any extraneous or incorrect information. The minor difference in word choice (\"concluded a compromise\" instead of \"cut a deal\") does not change the overall meaning.", "rationale_3": "The output is not a hallucination. It accurately translates the information given in the input from French to English. The only slight difference is the use of \"concluded a compromise\" instead of \"cut a deal\", but both phrases have similar meanings and do not alter the overall message.", "rationale_4": "The output is not a hallucination. It accurately translates the input from French to English, maintaining the original meaning without introducing extraneous information. The only small difference is the use of the word \"compromise\" instead of \"deal,\" but these words are synonyms in this context and do not change the overall meaning."}, {"hyp": "You certainly don't have your mother's good nature.", "ref": "either", "src": "Tu n'as certainement pas la bonne nature de ta m\u00e8re.", "tgt": "You definitely don't have the good nature of your mother.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T04:05:30Z", "rationale_0": "The output is not a hallucination. It accurately translates the sentiment and content of the original French sentence into English. The slight variation in word order does not change the meaning or add any extraneous information.", "rationale_1": "The output is not a hallucination. Although the wording differs slightly, the output accurately translates the meaning of the original French sentence into English. Both the target and output convey the same message that the individual does not possess their mother's good nature.", "rationale_2": "The output is not a hallucination. It accurately translates the meaning of the input from French to English. Although the wording is slightly different than the target, the overall meaning remains the same.", "rationale_3": "The output is not a hallucination. It accurately translates the content and sentiment of the original French sentence into English, although the word order is slightly different, which is common in translation due to differences in sentence structure between languages.", "rationale_4": "The output is not a hallucination. The translation provided in the output accurately conveys the meaning of the original French sentence into English, even if it isn't a word-for-word translation. The essence of the sentence, which is about someone not having the good nature of their mother, is correctly and clearly expressed."}, {"hyp": "Tom didn't hurry.", "ref": "either", "src": "Tom n'a pas hurl\u00e9.", "tgt": "Tom didn't scream.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T04:05:59Z", "rationale_0": "The output is a hallucination. The correct translation of \"Tom n'a pas hurl\u00e9\" from French to English is \"Tom didn't scream.\" However, the provided output is \"Tom didn't hurry,\" which is not an accurate translation of the original sentence. Therefore, the output can be considered a hallucination as it does not correctly reflect the input.", "rationale_1": "The output is a hallucination. The French sentence \"Tom n'a pas hurl\u00e9\" translates to \"Tom didn't scream\" in English. However, the output provided is \"Tom didn't hurry,\" which is incorrect as \"hurl\u00e9\" does not mean \"hurry\", but \"scream\". Therefore, the output is not an accurate translation of the input.", "rationale_2": "The output is a hallucination. The correct translation of the French phrase \"Tom n'a pas hurl\u00e9\" is \"Tom didn't scream.\" However, the provided output translates it as \"Tom didn't hurry,\" which is incorrect and does not match the target or the original input.", "rationale_3": "The output is a hallucination. The French sentence translates to \"Tom didn't scream.\" However, the output provided by the model is \"Tom didn't hurry,\" which is inaccurate. The model incorrectly translated \"hurl\u00e9\" (screamed) as \"hurry\".", "rationale_4": "The output is a hallucination. The correct translation of \"Tom n'a pas hurl\u00e9\" from French to English is \"Tom didn't scream\", as indicated in the target. However, the output provided is \"Tom didn't hurry\", which is a mistranslation of the original sentence. Therefore, the output is incorrect and off point."}, {"hyp": "Do you like tomatoes?", "ref": "either", "src": "Tom aime-t-il les tomates ?", "tgt": "Tom likes tomatoes?", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T04:06:24Z", "rationale_0": "The output is a hallucination. The input sentence in French is asking if \"Tom likes tomatoes\", but the output incorrectly translates it to \"Do you like tomatoes?\" The translation should have been about 'Tom', not 'you'.", "rationale_1": "The output is a hallucination. The original French sentence is asking if Tom likes tomatoes, while the output is asking if 'you' like tomatoes. Therefore, the output is not correctly translating the input.", "rationale_2": "The output is a hallucination. The original French sentence is asking if Tom likes tomatoes, however, the translated output is asking if \"you\" like tomatoes. Therefore, the output does not correctly translate the subject of the sentence from \"Tom\" to \"you\".", "rationale_3": "The output is a hallucination. The input sentence in French is asking if Tom likes tomatoes, but the output is incorrectly translated to a general question, \"Do you like tomatoes?\" The correct translation should be, \"Does Tom like tomatoes?\" as indicated in the target. Therefore, the output is not correct or accurate.", "rationale_4": "The output is a hallucination. The correct translation of the French sentence \"Tom aime-t-il les tomates?\" is \"Does Tom like tomatoes?\" However, the output provided is \"Do you like tomatoes?\", which changes the subject of the sentence from \"Tom\" to \"you\". This is inaccurate and cannot be inferred from the original input."}, {"hyp": "In this case we see the results all the time.", "ref": "either", "src": "Dans ce m\u00e9tier on voit tout de suite les r\u00e9sultats.", "tgt": "In this activity one immediately sees the result.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Not Hallucination", "Not Hallucination", "Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.2, "timestamp": "2023-11-05T04:07:00Z", "rationale_0": "The output is not a hallucination. While it is not a direct translation of the input, it still conveys the same overall meaning that in this profession, the results are immediately visible. However, it's not as accurate as the target translation.", "rationale_1": "The output is not a hallucination. It is a valid translation, but not as accurate as the target. The phrase \"all the time\" is not a direct translation of \"tout de suite\", which means \"immediately\". However, the overall meaning is not significantly altered.", "rationale_2": "The output is a hallucination. The input sentence in French states \"In this job, we immediately see the results\", but the output translates it as \"In this case we see the results all the time\". The main issue lies in the incorrect translation of \"m\u00e9tier\" (job or profession) as \"case\". Moreover, \"tout de suite\" is translated as \"all the time\" instead of \"immediately\". Therefore, the output introduces information that wasn't in the original input.", "rationale_3": "The output is not a hallucination. While it's not a direct translation, it does capture the overall meaning of the input text. However, it's not as accurate as the target translation. The phrase \"all the time\" in the output might be seen as adding some extraneous information, but it can also be interpreted as a less literal translation of \"tout de suite\" which means \"right away\" or \"immediately\". So, while it's not entirely accurate, it's not a complete deviation from the input.", "rationale_4": "The output is not a hallucination. Although it doesn't match the target exactly, it still accurately conveys the core meaning of the original French sentence. The phrase \"tout de suite\" is translated as \"all the time\" instead of \"immediately\", but both phrases convey the idea of immediacy. Therefore, the output is not a hallucination, but rather a slightly different interpretation of the original text."}, {"hyp": "I really think you should leave.", "ref": "either", "src": "Je pense vraiment que vous devriez partir.", "tgt": "I really think you should leave.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T04:07:18Z", "rationale_0": "The output is not a hallucination. It correctly and accurately translates the French input to English, matching the target translation exactly. There is no extraneous or incorrect information.", "rationale_1": "The output is not a hallucination. The output accurately and correctly translates the French input to English without adding any extraneous information.", "rationale_2": "The output is not a hallucination. The English translation provided by the language model accurately translates the meaning of the original French sentence, \"Je pense vraiment que vous devriez partir.\" There is no extra or incorrect information added.", "rationale_3": "The output is not a hallucination. It accurately and correctly translates the French input to English.", "rationale_4": "The output is not a hallucination. The translation from French to English is accurate and it correctly conveys the meaning of the original sentence without adding any extraneous information."}, {"hyp": "Make him a horse!", "ref": "either", "src": "Fais-lui un c\u00e2lin !", "tgt": "Give her a hug.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T04:07:45Z", "rationale_0": "The output is a hallucination. The original French sentence \"Fais-lui un c\u00e2lin !\" translates to \"Give her a hug!\" in English. However, the output \"Make him a horse!\" is completely unrelated and incorrect, therefore it is a hallucination.", "rationale_1": "The output is a hallucination. The French phrase \"Fais-lui un c\u00e2lin !\" translates directly to \"Give him/her a hug!\" in English. However, the output, \"Make him a horse!\" is completely unrelated to the input and includes information not present or implied in the original French sentence. Therefore, it is inaccurate and incorrect.", "rationale_2": "The output is a hallucination. The correct translation of \"Fais-lui un c\u00e2lin !\" from French to English is \"Give her a hug!\" as given in the target. However, the output \"Make him a horse!\" is completely unrelated and incorrect. It doesn't match the input context at all and can be considered as a hallucination.", "rationale_3": "The output is a hallucination. The correct translation of the French sentence \"Fais-lui un c\u00e2lin !\" is \"Give her a hug!\". However, the output \"Make him a horse!\" is not only incorrect but also irrelevant to the input, making it a clear case of hallucination.", "rationale_4": "The output is a hallucination. The correct translation of \"Fais-lui un c\u00e2lin !\" from French to English is \"Give him/her a hug!\" However, the output provided is \"Make him a horse!\" which is not only a mistranslation but also includes extraneous information that cannot be inferred from the original input."}, {"hyp": "Don't lend anyone else the book you borrowed.", "ref": "either", "src": "Ne pr\u00eate pas \u00e0 un autre le livre que tu as emprunt\u00e9.", "tgt": "Don't lend a borrowed book to another.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T04:08:05Z", "rationale_0": "The output is not a hallucination. It correctly and accurately translates the given French sentence into English. While the wording is slightly different from the target, the meaning remains the same.", "rationale_1": "The output is not a hallucination. It accurately and correctly translates the input from French to English. The meaning of the sentence is preserved and there is no extraneous information added.", "rationale_2": "The output is not a hallucination. It accurately translates the input from French to English, conveying the same meaning as the original sentence and the target translation. The slight variations in wording do not change the overall message of the sentence.", "rationale_3": "The output is not a hallucination. It accurately translates the input from French to English, maintaining the same meaning and context. The slight difference in phrasing does not change the overall meaning of the sentence.", "rationale_4": "The output is not a hallucination. It accurately and correctly translates the meaning of the original French sentence into English. While the wording is slightly different from the target, the overall meaning is preserved."}, {"hyp": "I want to drink something free.", "ref": "either", "src": "Je veux boire quelque chose de frais.", "tgt": "I want something cold to drink.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T04:08:34Z", "rationale_0": "The output is a hallucination. The correct translation from French to English of \"Je veux boire quelque chose de frais\" is \"I want something cold to drink.\" However, the model incorrectly translated \"frais\" as \"free\" instead of \"cold,\" which changes the meaning of the sentence. Therefore, the output is not accurate.", "rationale_1": "The output is a hallucination. The correct translation of \"Je veux boire quelque chose de frais\" is \"I want something cold to drink.\" However, the output translates \"frais\" as \"free\" instead of \"cold\". Therefore, the output is not an accurate translation of the input.", "rationale_2": "The output is a hallucination. The correct translation of the French sentence \"Je veux boire quelque chose de frais\" is \"I want something cold to drink.\" However, the model incorrectly translates \"frais\" as \"free\" instead of \"cold\". This results in a sentence that deviates significantly from the correct translation.", "rationale_3": "The output is a hallucination. The correct translation of \"Je veux boire quelque chose de frais\" is \"I want something cold to drink.\" However, the model incorrectly translated \"frais\" as \"free\" instead of \"cold,\" resulting in an output that does not accurately reflect the original input.", "rationale_4": "The output is a hallucination. The correct translation of the French sentence \"Je veux boire quelque chose de frais\" is \"I want something cold to drink.\" However, the output provided by the machine translation is \"I want to drink something free,\" which is not accurate. Therefore, the output is a hallucination as it inaccurately translates \"frais\" (cold) as \"free\"."}, {"hyp": "Do you have a cryon?", "ref": "either", "src": "As-tu un crayon ?", "tgt": "Have you got a pencil?", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T04:10:48Z", "rationale_0": "The output is not a hallucination. It is a correct translation from French to English with the exception of a spelling error. The word \"cryon\" should be \"pencil\". Aside from this error, the output does not contain extraneous or incorrect information.", "rationale_1": "The output is not a hallucination. It is a correct translation, but there is a minor spelling error. The word \"crayon\" has been incorrectly translated as \"cryon\". Other than this, the meaning of the sentence has been accurately captured.", "rationale_2": "The output is not a hallucination. Although there is a spelling mistake in the translation (the word \"cryon\" instead of \"pencil\"), the output is still on point with the input. The phrase in question is still asking if the person has a pencil, as indicated in the target. Therefore, the translation is accurate in terms of meaning, despite the spelling error.", "rationale_3": "The output is not a hallucination. It is a correct translation of the input, albeit with a minor typographical error. The word \"cryon\" should be \"pencil\". Other than this typo, the output accurately translates the given input.", "rationale_4": "The output is not a hallucination. While there is a misspelling in the translation ('cryon' instead of 'pencil'), the general meaning of the sentence is preserved. The output accurately translates the question of whether or not someone possesses a pencil. However, it should be noted that the output includes a spelling error."}, {"hyp": "I talked to other people in the same situation.", "ref": "either", "src": "J'ai discut\u00e9 avec d'autres personnes dans la m\u00eame situation.", "tgt": "I have talked with others in the same situation.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T04:11:15Z", "rationale_0": "The output is not a hallucination. It accurately translates the input from French to English, conveying the same meaning even though the wording is slightly different (\"I have talked\" vs \"I talked\").", "rationale_1": "The output is not a hallucination. It accurately translates the meaning of the input from French to English, even though it does not match the target translation word-for-word. Both the output and target convey the same core message, that the speaker has communicated with other individuals experiencing the same circumstances.", "rationale_2": "The output is not a hallucination. It accurately translates the meaning of the French input into English. The slight variance in verbs (\"I have talked\" vs \"I talked\") does not change the overall meaning of the sentence.", "rationale_3": "The output is not a hallucination. Although the output does not match the target translation word for word, it conveys the same meaning as the input sentence in a grammatically correct and coherent manner. The differences in wording do not alter the semantics of the sentence.", "rationale_4": "The output is not a hallucination. It accurately translates the meaning of the French sentence into English, even though it uses slightly different phrasing (\"I talked to\" vs. \"I have talked with\"). Both variations are grammatically correct and convey the same information."}, {"hyp": "The nurse will check your arm within 2 days to see if there's any reaction.", "ref": "either", "src": "L'infirmier v\u00e9rifiera ton bras dans les 2 jours pour voir s'il y a une r\u00e9action.", "tgt": "The nurse will check your arm within 2 days to see if there is a reaction.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T04:11:41Z", "rationale_0": "The output is not a hallucination. It accurately translates the original French sentence into English, capturing the main ideas without adding extraneous information. The slight difference in wording (\"if there is a reaction\" vs \"if there's any reaction\") does not change the overall meaning of the sentence.", "rationale_1": "The output is not a hallucination. It accurately translates the input from French to English, conveying the same meaning as the target. The slight variation in wording (\"if there's any reaction\" instead of \"if there is a reaction\") does not change the overall meaning.", "rationale_2": "The output is not a hallucination. It accurately translates the input from French to English. Although the word \"any\" is added in the output, it does not change the meaning of the sentence and can be reasonably inferred from the context.", "rationale_3": "The output is not a hallucination. It accurately and correctly translates the information given in the input. The slight difference in wording (\"there's any reaction\" instead of \"there is a reaction\") does not change the meaning of the sentence.", "rationale_4": "The output is not a hallucination. Although the wording differs slightly from the target, the output accurately and correctly translates the input from French to English, retaining all essential information and meaning. The difference between \"if there is a reaction\" and \"if there's any reaction\" is negligible and does not alter the main intended message."}, {"hyp": "You're not missing anyone.", "ref": "either", "src": "Tu ne manques \u00e0 personne.", "tgt": "No one misses you.", "model": "", "task": "MT", "labels": ["Hallucination", "Not Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T04:12:12Z", "rationale_0": "The output is a hallucination. The correct translation of the French sentence \"Tu ne manques \u00e0 personne\" is \"No one misses you\", as stated in the target. However, the output \"You're not missing anyone\" is an incorrect translation, changing the meaning of the original sentence.", "rationale_1": "The output is a hallucination. The correct translation of the French sentence \"Tu ne manques \u00e0 personne\" is \"No one misses you\", which is given in the target. However, the model output \"You're not missing anyone\" is not an accurate translation as it changes the meaning completely. Thus, the output is incorrect.", "rationale_2": "The output is a hallucination. The input is in French and translates to \"No one misses you\" in English. However, the output provided, \"You're not missing anyone,\" is incorrect and does not accurately capture the meaning of the original French sentence. Instead, it introduces a completely different meaning. Therefore, the output can be considered a hallucination.", "rationale_3": "The output is a hallucination. The correct translation of the French sentence \"Tu ne manques \u00e0 personne\" is \"No one misses you,\" which is the target provided. However, the output provided, \"You're not missing anyone,\" is an incorrect translation as it changes the meaning of the sentence entirely.", "rationale_4": "The output is a hallucination. The correct translation of the French sentence \"Tu ne manques \u00e0 personne\" is \"No one misses you\", which is given in the target. However, the output provided, \"You're not missing anyone\", conveys a different meaning entirely. The output inaccurately translates the sentence as though the subject of the sentence (you) is the one not missing anyone else, rather than the other way around."}, {"hyp": "I've got the floor and the furniture.", "ref": "either", "src": "J'ai poli le plancher et les meubles.", "tgt": "I polished up the floor and furniture.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T04:12:41Z", "rationale_0": "The output is a hallucination. The output sentence \"I've got the floor and the furniture\" does not accurately translate the original French sentence. The French sentence speaks about the action of polishing the floor and furniture, whereas the English output implies possession or responsibility for the floor and furniture, not an action performed on them.", "rationale_1": "The output is a hallucination. The output, \"I've got the floor and the furniture,\" does not accurately translate the original French sentence. The correct translation is \"I polished up the floor and furniture,\" as indicated in the target. The output does not convey the same meaning or action described in the original sentence.", "rationale_2": "The output is a hallucination. The original French sentence translates to \"I polished the floor and the furniture\", while the output \"I've got the floor and the furniture\" holds a completely different meaning and does not correctly translate the action of polishing from the input sentence.", "rationale_3": "The output is a hallucination. The original French sentence translates to \"I polished the floor and the furniture\", but the output provided \"I've got the floor and the furniture\" does not convey the same meaning. The action of \"polishing\" is completely lost in the translation, making the output incorrect and off point.", "rationale_4": "The output is a hallucination. The original French sentence is about the speaker having polished the floor and furniture. However, the output in English does not accurately convey this action. Instead, it merely mentions the floor and furniture without referring to any action performed on them. Therefore, the output is not a correct translation of the input."}, {"hyp": "I can't do it alone.", "ref": "either", "src": "Je ne peux le faire seule. Il vous faut m'aider.", "tgt": "I can't do it alone. You have to help me.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T04:13:11Z", "rationale_0": "The output is a hallucination. While the first sentence of the output accurately translates the first sentence of the input, it completely omits the second sentence. The input \"Il vous faut m'aider\" should be translated to \"You have to help me\", but this is not present in the output. Therefore, the output is incomplete and not entirely accurate.", "rationale_1": "The output is a partial hallucination. While the first sentence of the translation is accurate (\"I can't do it alone\"), the second sentence of the input (\"Il vous faut m'aider\") is not translated at all in the output. Therefore, important information from the input is missing in the output.", "rationale_2": "The output is a hallucination. While the first part of the translation is correct (\"I can't do it alone\"), the second part of the original French sentence (\"Il vous faut m'aider\") is not translated in the output. The output should also include \"You have to help me\" to fully and accurately translate the source text.", "rationale_3": "The output is a hallucination because it only translates the first sentence of the input but leaves out the second sentence entirely. The second sentence, \"Il vous faut m'aider,\" translates to \"You have to help me,\" which is not mentioned in the output. Therefore, the output is incomplete and not a full translation of the input.", "rationale_4": "The output is a hallucination because it only translates part of the input sentence. The second sentence \"Il vous faut m'aider\" which translates to \"You have to help me\" is completely missing from the output. Therefore, the output is incomplete and not entirely accurate."}, {"hyp": "He lost what he received from his father.", "ref": "either", "src": "Il a perdu ce qu'il a re\u00e7u de son p\u00e8re.", "tgt": "He wasted that which he had received from his father.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T04:13:46Z", "rationale_0": "The output is not a hallucination. It is a correct and accurate translation of the input. The only minor discrepancy is the choice of verb \u2013 the French verb \"perdu\" is translated as \"lost\" in the output, while the target uses \"wasted\". Both translations convey the same overall meaning, and \"lost\" is a standard translation for \"perdu\", making the output acceptable.", "rationale_1": "The output is not a hallucination. The output correctly translates the given French sentence into English. Although the word \"wasted\" in the target is replaced by \"lost\" in the output, both words convey a similar meaning in this context. The output does not contain any incorrect, off point, or extraneous information.", "rationale_2": "The output is not a hallucination. It is a correct and accurate translation of the French input. However, it should be noted that the output is slightly different from the target phrase. The target phrase uses \"wasted\" instead of \"lost\", which could imply a more intentional action of misusing the inheritance. But in terms of direct translation, \"perdu\" in French translates to \"lost\" in English. Thus, the output is correct based on the input, even though it might not fully capture the nuanced meaning suggested by the target phrase.", "rationale_3": "The output is not a hallucination. The output accurately translates the input from French to English, maintaining the meaning of the original sentence. However, the target translation uses the word \"wasted\" instead of \"lost\", which could imply a slightly different connotation, suggesting not just the loss but the misuse of what was received. Nevertheless, the output translation is not incorrect or off point.", "rationale_4": "The output is not a hallucination. The output accurately translates the French sentence into English. However, it's worth noting that the verb \"perdu\" can be translated both as \"lost\" and \"wasted\". Therefore, while the output is correct, it might not perfectly match the target translation, which uses \"wasted\" instead of \"lost\"."}, {"hyp": "We've discovered a lot of news.", "ref": "either", "src": "Nous avons d\u00e9couvert une grande nouveaut\u00e9.", "tgt": "We have discovered a great novelty.", "model": "", "task": "MT", "labels": ["Hallucination", "Not Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T04:14:23Z", "rationale_0": "The output is a hallucination. The original French sentence translates to \"We have discovered a great novelty\" but the machine translation incorrectly translates it as \"We've discovered a lot of news.\" The output is incorrect and doesn't accurately represent the original input.", "rationale_1": "The output is a hallucination. The original French sentence, \"Nous avons d\u00e9couvert une grande nouveaut\u00e9,\" translates directly to \"We have discovered a great novelty.\" The output, \"We've discovered a lot of news,\" is not an accurate translation as it changes the meaning of the original sentence. The word \"nouveaut\u00e9\" has been inaccurately translated to \"news\" instead of \"novelty,\" and the quantity \"a lot of\" is added information that is not present in the original sentence. Therefore, the output can be considered a hallucination.", "rationale_2": "The output can be considered a hallucination. The original French sentence translates directly to \"We have discovered a great novelty\". However, the output \"We've discovered a lot of news\" does not accurately reflect this. The output incorrectly translates \"une grande nouveaut\u00e9\" (a great novelty) as \"a lot of news\", adding extraneous information that isn't present in the original input.", "rationale_3": "The output is a hallucination. The original French sentence translates to \"We have discovered a great novelty.\" However, the output translation says \"We've discovered a lot of news,\" which is not an accurate translation. The output introduces the idea of \"a lot of news\" which wasn't suggested in the input. Therefore, the output contains extraneous information, making it a hallucination.", "rationale_4": "The output is a hallucination. The original French sentence talks about discovering a \"grande nouveaut\u00e9\" which translates to \"a great novelty\". However, the output translates it to \"a lot of news\" which is not the same. The output is not accurately reflecting the content of the input, hence it is a hallucination."}, {"hyp": "Why is everyone okay?", "ref": "either", "src": "Pourquoi est-ce que tout le monde rigole ?", "tgt": "Why is everyone laughing?", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T04:14:50Z", "rationale_0": "The output is a hallucination. The input in French is asking why everyone is laughing. However, the output in English incorrectly translates this as asking if everyone is okay. The output does not accurately reflect the content of the input.", "rationale_1": "The output is a hallucination. The input sentence in French translates to \"Why is everyone laughing?\" in English. However, the model's output is \"Why is everyone okay?\" which does not correctly translate the original input. Therefore, it is providing inaccurate information.", "rationale_2": "The output is a hallucination. The original French sentence translates to \"Why is everyone laughing?\" However, the output provided by the model is \"Why is everyone okay?\" which doesn't correctly translate the original sentence. Thus, the output is incorrect.", "rationale_3": "The output is a hallucination. The input in French is asking why everyone is laughing, but the output in English incorrectly translates this to asking if everyone is okay. The output does not accurately reflect the original meaning of the input.", "rationale_4": "The output is a hallucination. The input in French is asking \"Why is everyone laughing?\" but the output in English incorrectly translates it to \"Why is everyone okay?\" The output is not an accurate translation of the input."}, {"hyp": "No matter what you do to your guide.", "ref": "either", "src": "Chacun fait \u00e0 sa guise.", "tgt": "Each one does as he likes.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T04:15:19Z", "rationale_0": "The output is a hallucination. The correct translation from French to English of \"Chacun fait \u00e0 sa guise\" is \"Each one does as he likes\", as indicated in the target. The output \"No matter what you do to your guide\" is not a correct translation and does not convey the same meaning as the original French sentence.", "rationale_1": "The output is a hallucination. The correct translation of the French sentence \"Chacun fait \u00e0 sa guise\" is \"Each one does as he likes,\" as given in the target. The output \"No matter what you do to your guide\" is not an accurate translation of the input and includes extraneous information not present in the original text.", "rationale_2": "The output is a hallucination. The correct translation of the French sentence \"Chacun fait \u00e0 sa guise\" is \"Each one does as he likes\". The output \"No matter what you do to your guide\" is not a correct translation and does not convey the same meaning as the original sentence. Therefore, it's an incorrect and inaccurate translation.", "rationale_3": "The output is a hallucination. The correct translation of \"Chacun fait \u00e0 sa guise\" from French to English is \"Each one does as he likes.\" The provided output, \"No matter what you do to your guide,\" does not accurately translate the input and adds extraneous information not present in the original sentence.", "rationale_4": "The output is a hallucination. The correct translation of the French sentence \"Chacun fait \u00e0 sa guise\" is \"Each one does as he likes\". The provided output, \"No matter what you do to your guide\", does not accurately translate the original input and introduces an entirely new concept (\"your guide\") that is not present in the input."}]