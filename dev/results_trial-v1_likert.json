[{"hyp": "A district of Kowloon, China.", "ref": "tgt", "src": "The City <define> Chiuchow </define> is Kowloon 's other top restaurant and is famous for its goose dishes and other specialties from the Chiuchow region ( you may also wish to try the beef satay done in a creamy sauce ) .", "tgt": "The Chaoshan region where the Teochew dialect is spoken.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The term to be defined is \"Chiuchow\", and the target definition indicates that it refers to the Chaoshan region where the Teochew dialect is spoken. However, the output generated by the model incorrectly defines \"Chiuchow\" as a district of Kowloon, China. The input text does mention Kowloon, but it is in reference to a restaurant located there, not the term to be defined. Therefore, the output is incorrect and not based on the information provided in the input.", "predicted": "Strongly Agree"}, {"hyp": "(Wicca) A witchdoctor.", "ref": "tgt", "src": "\u201c I went to see the witchdoctor , the <define> igqira </define> . And he spoke to the izinyanya , the spirits of the ancestors . \u201d", "tgt": "(South Africa) A traditional tribal diviner or spiritual healer.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Not Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "rationale": "The output is a hallucination. The term \"igqira\" is defined correctly in the target as a traditional tribal diviner or spiritual healer in South Africa. However, the language model incorrectly defines it as a witchdoctor in Wicca. The output does not match the target and also includes information (Wicca) that is not mentioned or inferred from the input. Therefore, the output is incorrect and off point.", "predicted": "Strongly Agree"}, {"hyp": "(nautical) A halyard.", "ref": "tgt", "src": "Haul away , keeping strain on both parts of the halyard so that the <define> pigstick </define> remains vertical as it goes up and does n't foul the spreaders .", "tgt": "(nautical) A staff that carries a flag or pennant above the mast of a sailboat.", "model": "", "task": "DM", "labels": ["Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "rationale": "The output is a hallucination. The term to be defined in the input is 'pigstick', but the output provides a definition for 'halyard'. The target definition confirms that a 'pigstick' is a staff that carries a flag or pennant above the mast of a sailboat, not a halyard. Therefore, the output is incorrect and off point.", "predicted": "Strongly Agree"}, {"hyp": "The quality of being rational.", "ref": "tgt", "src": "And what difference is there between the credibleness and <define> rationalness </define> of any of these wonders and the credibleness and rationalness of Papal infallibility ?", "tgt": "(archaic) The quality or state of being rational.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. The term to be defined in the input is 'rationalness', and the output provided by the language model is 'The quality of being rational.' This is a correct and accurate definition, as it aligns closely with the target definition 'The quality or state of being rational.' Therefore, the output is not a hallucination as it correctly and accurately defines the term from the input.", "predicted": "Strongly Disagree"}, {"hyp": "(uncountable) The study of trees.", "ref": "tgt", "src": "It is now generally supposed that the forbidden fruit was a kind of citrus , but certain facts connected with <define> arborolatry </define> seem to me to disprove this opinion .", "tgt": "The worship of trees.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The term \"arborolatry\" is defined in the target as \"The worship of trees.\" However, the language model incorrectly defines it as \"(uncountable) The study of trees.\" This is not accurate as the term refers to the religious practice of worshipping trees, not studying them. Therefore, the output is incorrect and does not match the target definition.", "predicted": "Strongly Agree"}, {"hyp": "(zoology) A pseudostome.", "ref": "tgt", "src": "The pseudembryo moves rapidly in the water , rolling round and swinging from side to side ; as a rule , and especially when at rest , the surface bearing the pseudostome and <define> pseudoproct </define> is turned downwards .", "tgt": "(biology) The anal opening on the pseudembryo of an echinoderm.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The term to be defined is 'pseudoproct', but the model incorrectly defines it as 'pseudostome'. The target definition indicates that 'pseudoproct' is the anal opening on the pseudembryo of an echinoderm, which is not reflected in the output. Therefore, the output is incorrect and off point.", "predicted": "Strongly Agree"}, {"hyp": "Resembling or characteristic of umber.", "ref": "tgt", "src": "<define> umbery </define> gold", "tgt": "Of or pertaining to umber; like umber.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. The term \"umbery\" is correctly defined as resembling or characteristic of umber, which aligns with the target definition of being of or pertaining to umber. The language model has accurately inferred the meaning from the input.", "predicted": "Strongly Disagree"}, {"hyp": "(music, transitive) To play (a note) at the same time.", "ref": "tgt", "src": "Now the two bounding notes of an enharmonic tetrachord of the relevant sort will indeed both be the lowest notes of pykna when the tetrachords are put together in conjunction ; but the higher of them can never <define> abut on </define> a pyknon in the case envisaged here , where the tone is introduced to disjoin the tetrachords .", "tgt": "(transitive) To border on.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The term to be defined is \"abut on\", and the target definition is \"to border on\". However, the output provided by the language model is \"to play (a note) at the same time\", which is not accurate or relevant to the term in question. The output seems to be influenced by the musical context of the input, but it does not correctly define the term \"abut on\".", "predicted": "Strongly Agree"}, {"hyp": "(Australia, New Zealand, colloquial) A hatfish.", "ref": "tgt", "src": "Noah did n't realize when he stayed on the job - he was then about 600 years old and built the ark and drove the animals in two by two , the <define> hatfish </define> and the kangaroo \u2014 \u2014 he did n't realize he was laying the foundation for an occupation for old men in New York , several years later .", "tgt": "(colloquial) Synonym of halibut", "model": "", "task": "DM", "labels": ["Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "rationale": "The output is a hallucination. The language model was supposed to generate a definition for the term \"hatfish\", and the target definition provided is \"Synonym of halibut\". However, the output generated by the model is \"(Australia, New Zealand, colloquial) A hatfish\", which does not provide a definition for the term. Instead, it simply repeats the term and adds a geographical context, which is not present in the input. Therefore, the output is incorrect and does not match the target.", "predicted": "Strongly Agree"}, {"hyp": "Having a keen sense of humor.", "ref": "tgt", "src": "<define> keen </define> satire or sarcasm", "tgt": "Acrimonious, bitter, piercing.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The input asks for a definition of \"keen\" in the context of satire or sarcasm, which should involve concepts like sharpness, intensity, or biting wit. The target words \"acrimonious,\" \"bitter,\" and \"piercing\" align with this interpretation. However, the output provided by the model, \"having a keen sense of humor,\" does not accurately reflect the input. It is a general statement about humor, not specifically about satire or sarcasm, and it does not incorporate the intensity or sharpness implied by the term \"keen\" in this context. Therefore, the output is incorrect and off point.", "predicted": "Strongly Agree"}, {"hyp": "A person who has a pass.", "ref": "tgt", "src": "<define> Passholders </define> can visit the theme park all year round .", "tgt": "One who holds a pass.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. The term to be defined from the input is \"Passholders\", and the language model correctly defines it as \"A person who has a pass.\" This definition aligns with the target definition, \"One who holds a pass.\" Therefore, the output is correct and accurate.", "predicted": "Strongly Disagree"}, {"hyp": "(colloquial) A term of endearment.", "ref": "tgt", "src": "Hey , <define> babe </define> , how 's about you and me getting together ?", "tgt": "(affectionate) Darling (term of endearment).", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. The term \"babe\" is indeed often used as a term of endearment in colloquial language. While the output does not match the target exactly, it still provides a correct and accurate definition of the term in question.", "predicted": "Strongly Disagree"}, {"hyp": "(intransitive) To speak in a slurred manner.", "ref": "tgt", "src": "Sometimes life takes hold of one , carries the body along , accomplishes one 's history , and yet is not real , but leaves oneself as it were <define> slurred over </define> .", "tgt": "(dated) To deal with something hurriedly; to treat in a perfunctory manner.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The term \"slurred over\" in the context of the input sentence refers to dealing with something hurriedly or treating it in a perfunctory manner. However, the language model incorrectly defines it as speaking in a slurred manner, which is not accurate in this context. Therefore, the output is incorrect and off point.", "predicted": "Strongly Agree"}, {"hyp": "A device that simulates walking.", "ref": "tgt", "src": "During the late 1960s and early 1970s , it was also the site of the lunar 1\u20446 gravity <define> walking simulator </define> rig .", "tgt": "Used other than figuratively or idiomatically: see walking,\u200e simulator.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "rationale": "The output is not a hallucination. The term to be defined is 'walking simulator' and the model's output, \"A device that simulates walking,\" is a correct and straightforward definition of the term. The output does not contain any incorrect or off-point information and it can be reasonably inferred from the input. However, it could be argued that the output is a bit too general, as it doesn't capture the specific context of the term in the input, which refers to a walking simulator used in lunar gravity simulations.", "predicted": "Strongly Disagree"}, {"hyp": "(intransitive, colloquial) To be very hot.", "ref": "tgt", "src": "Let 's face it , they 're there for a good stroll on a Sunday afternoon when it 's <define> pissing </define>   outside .", "tgt": "(ambitransitive, mildly, _, vulgar) To rain heavily.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The term to be defined is 'pissing', used in the context of describing weather conditions. The target definition correctly identifies it as a vulgar term for heavy rain. However, the output provided by the language model incorrectly defines it as a colloquial term for very hot weather. This is not accurate or correct based on the given input.", "predicted": "Strongly Agree"}, {"hyp": "(geology) Synonym of synecdoche", "ref": "tgt", "src": "In the Ronne <define> syneclise </define> the thickness of sedimentary cover reaches 13.5 km and the folded basement has a complex relief owing to block movements along faults of different rank .", "tgt": "(geology) A large, shallow depression formed on a continental platform due to slow subsidence.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The term 'syneclise' is incorrectly defined as a synonym of 'synecdoche', which is a figure of speech in literature. The correct definition, as given in the target, is a large, shallow depression formed on a continental platform due to slow subsidence in the field of geology. The output does not match the target and is not accurate based on the context provided in the input.", "predicted": "Strongly Agree"}, {"hyp": "(informal) A person who is addicted to sport.", "ref": "tgt", "src": "I have spent much of my life a recovering <define> sportaholic </define> . If it bounced , rolled , slid , or flew , I chased it . Or watched it .", "tgt": "A sportsaholic.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. The term \"sportaholic\" is defined accurately by the language model as \"a person who is addicted to sport\". This definition aligns with the context provided in the input, where the speaker mentions chasing or watching anything that \"bounced, rolled, slid, or flew\", implying a strong obsession or addiction to sports. Therefore, the output is correct and accurate.", "predicted": "Strongly Disagree"}, {"hyp": "Resembling or characteristic of French surrealism.", "ref": "tgt", "src": "Quatermass also mediated Wellsian influence on the tone and preoccupations of the new hybrid SF \u2013 horror - film genre , with its monstrous <define> Gigeresque </define> fusions of machine and organism [ \u2026 ]", "tgt": "Reminiscent of H. R. Giger (born 1940), Swiss surrealist painter best known for nightmarish biomechanical imagery.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Not Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "rationale": "The output is a hallucination. The term \"Gigeresque\" is defined in the target as being reminiscent of H. R. Giger, a Swiss surrealist painter known for his biomechanical imagery. However, the output incorrectly defines \"Gigeresque\" as being characteristic of French surrealism. This is incorrect as H. R. Giger is Swiss, not French, and his work is specifically known for its biomechanical themes, not just general surrealism. Therefore, the output is not accurate or correct.", "predicted": "Strongly Agree"}, {"hyp": "The state or quality of being a princess.", "ref": "tgt", "src": "\u201c What are you doing ? \u201d Carly asked , looking around . \u201c You do n\u2019t want to be in here . You \u2019re way too much of a princess . \u201d / \u201c Remember how I grew up , Carly . I \u2019ve earned my <define> princessness </define> . \u201d", "tgt": "The quality of being a princess.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. The target definition is \"The quality of being a princess,\" and the language model's output is \"The state or quality of being a princess.\" Both definitions essentially convey the same meaning, indicating that the language model correctly understood and defined the term 'princessness' from the given input.", "predicted": "Strongly Disagree"}, {"hyp": "(Australia, New Zealand, colloquial) A tree.", "ref": "tgt", "src": "He climbed over the sedge and eely oarweeds and sat on a stool of rock , resting his ashplant in a <define> grike </define> .", "tgt": "(chiefly, British) A deep cleft formed in limestone surfaces due to water erosion; providing a unique habitat for plants.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The term 'grike' is defined in the target as a deep cleft formed in limestone surfaces due to water erosion, which is a geological feature. However, the language model incorrectly defines 'grike' as a tree in Australia and New Zealand. This is not accurate or related to the correct definition, indicating that the model has generated a hallucination.", "predicted": "Strongly Agree"}, {"hyp": "(intransitive) To die.", "ref": "tgt", "src": "\" But why should I be in another room ? \" \" You <define> passed over </define> in the night . \" \" Passed over ? Do you mean I died ? \" \" Yes , lady , you died . \" There was a long silence .", "tgt": "(intransitive, euphemistic) To die and thus progress to the afterlife.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. The term to be defined in the input is \"passed over,\" and the context makes it clear that this term is being used as a euphemism for dying. The output generated by the language model, \"To die,\" accurately captures this meaning. While the output is slightly less detailed than the target, it is still correct and can be reasonably inferred from the input.", "predicted": "Strongly Disagree"}, {"hyp": "Alternative form of scatter site", "ref": "tgt", "src": "It is designed for single - family use in subdivisions or <define> scatter sites </define> and available as a standardized product   [ \u2026 ]", "tgt": "An area of state-sponsored housing used as a shelter for homeless people; such housing is scattered across different parts of a city rather than concentrated in one place.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Not Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "rationale": "The output is a hallucination. The language model's output, \"Alternative form of scatter site,\" does not provide a clear definition of the term \"scatter sites\" as required by the task. It does not match the target definition, which explains that scatter sites are areas of state-sponsored housing scattered across different parts of a city. The model's output does not provide this information, making it incorrect and off point.", "predicted": "Strongly Agree"}, {"hyp": "The state or condition of being obsolescent.", "ref": "tgt", "src": "One way is to legislate extended warranties on products , so washing machines and refrigerators last for 30 years instead of 10 . Another is to ban planned <define> obsolescence </define> , so manufacturers ca n\u2019t create products that are designed to fail .", "tgt": "(uncountable) The state of being obsolete\u2014no longer in use; gone into disuse; disused or neglected.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. The term \"obsolescence\" is correctly defined as the state or condition of being obsolescent, which aligns with the target definition of being no longer in use or neglected. The output accurately captures the essence of the term as it is used in the input context, where products are designed to become obsolete or fail after a certain period.", "predicted": "Strongly Disagree"}, {"hyp": "Alternative form of gartel (\u201cdance\u201d)", "ref": "tgt", "src": "The bride stands perfectly still at one end of the room and holds a long <define> gartel </define> while the male dancing before her holds the other end .", "tgt": "(Judaism) A belt or sash used in prayer.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The term 'gartel' is defined in the target as a belt or sash used in prayer in Judaism. However, the output generated by the language model incorrectly defines 'gartel' as an alternative form of a dance. This definition is not accurate or correct based on the provided target, and it cannot be reasonably inferred from the input. Therefore, the output is a hallucination.", "predicted": "Strongly Agree"}, {"hyp": "Capable of being endured.", "ref": "tgt", "src": "Misery colored by the greens and blues in my mother 's voice took all of the grief out of the words and left me with a conviction that pain was not only <define> endurable </define> , it was sweet .", "tgt": "Able to be endured; tolerable; bearable.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. The term to be defined from the input is 'endurable', and the language model correctly generates a definition that aligns with the target. Both the target and output definitions convey the idea that 'endurable' means something that can be endured, tolerated, or borne. Therefore, the output is correct and accurate.", "predicted": "Strongly Disagree"}, {"hyp": "(geology) Of or pertaining to the Alps.", "ref": "tgt", "src": "In 1884 O. Heer published a comprehensive account of the <define> nival </define> flora of   Switzerland , in which he listed 338 species of flowering plants found above 2600   m. ; of these , 6 were found above 3900 m.", "tgt": "(botany) Found or thriving in snowy conditions.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The term to be defined is 'nival', and the target definition is \"(botany) Found or thriving in snowy conditions.\" However, the output provided by the language model is \"(geology) Of or pertaining to the Alps.\" This is incorrect as it does not match the target definition and it is not accurate in the context of the input. The term 'nival' is related to snowy conditions, not specifically to the Alps. Therefore, the output is a hallucination.", "predicted": "Strongly Agree"}, {"hyp": "Capable of being parachuted.", "ref": "tgt", "src": "<define> parachutable </define> supplies", "tgt": "Capable of being deployed by parachute.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. The term \"parachutable\" indeed refers to something that is capable of being parachuted or deployed by parachute. Therefore, the language model's output is correct and accurate.", "predicted": "Strongly Disagree"}, {"hyp": "In a muffled manner.", "ref": "tgt", "src": "A voice came <define> muffledly </define> from inside the closet .", "tgt": "In a muffled manner; indistinctly.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. The term \"muffledly\" is correctly defined by the language model as \"in a muffled manner\". Although the output is slightly less detailed than the target, it still accurately captures the essence of the term's definition.", "predicted": "Strongly Disagree"}, {"hyp": "(transitive) To cook (something) in a frying pan.", "ref": "tgt", "src": "Innawong et al . ( 2006 ) conducted experiments to study the effect of using nitrogen gas on the quality of <define> fried </define> chicken nuggets during pressure frying in terms of moisture retention and reduction in fat   [ \u2026 ]", "tgt": "Cooked in a deep fryer or pressure fryer or the like after being coated (breaded) in batter; compare deep-fried.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is a hallucination. The term to be defined is 'fried' and while the output does provide a definition for 'fried', it is not specific to the context provided in the input. The input is specifically about 'fried chicken nuggets' and the target definition accurately describes the process of frying in this context, including the coating or breading of the chicken nuggets before frying. The output definition, however, is a more general definition of frying and does not include these specific details. Therefore, the output is not accurate in the context of the input.", "predicted": "Agree"}, {"hyp": "A sleeveless garment worn at night.", "ref": "tgt", "src": "Winston wore a <define> nightcap </define> to stave off the cold .", "tgt": "A warm cloth cap worn while sleeping, often with pajamas, being common attire in northern Europe before effective home heating became widespread. [From 14th c.]", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Not Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "rationale": "The output is a hallucination. The term to be defined is 'nightcap', and the target definition correctly describes it as a warm cloth cap worn while sleeping. However, the output from the language model incorrectly defines 'nightcap' as a sleeveless garment worn at night, which is not accurate. Therefore, the output is incorrect and off point.", "predicted": "Strongly Agree"}, {"hyp": "(obsolete) Old; old-fashioned.", "ref": "tgt", "src": "And thou , our Mother , twice two centuries <define> young </define> ,", "tgt": "(Not) advanced in age; (far towards or) at a specified stage of existence or age.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The term to be defined in the input is \"young\", and the target definition accurately describes it as not being advanced in age or at a specified stage of existence or age. However, the output provided by the language model incorrectly defines \"young\" as \"old\" or \"old-fashioned\", which is the opposite of the actual meaning of the term. Therefore, the output is incorrect and off point.", "predicted": "Strongly Agree"}, {"hyp": "A county of Hotan, Sichuan, China.", "ref": "tgt", "src": "The \u201c living fossil \u201d , metasequoia , for example , was once distributed over large areas of Europe , Asia and the Americas from the Cretaceous to the Tertiary periods . Destroyed by glaciers , its natural distribution in China is today limited to Sichuan \u2019s <define> Shizhu </define> county , Hubei \u2019s Lichuan county and Hunan \u2019s Longshan county .", "tgt": "A county of Chongqing, China.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The input text specifies that Shizhu is a county in Sichuan, China. However, the output incorrectly defines Shizhu as a county of Hotan, Sichuan, China. Hotan is actually a prefecture-level city in Xinjiang, not Sichuan. Therefore, the output is incorrect and does not accurately reflect the information provided in the input.", "predicted": "Strongly Agree"}, {"hyp": "A small flag.", "ref": "tgt", "src": "Given the present crisis and empty coffers , working meetings geared toward results are more appropriate for politicians than a program of touristy forays , throngs waving <define> flaglets </define> and bulletproof glass , the whole culminating in a neo - feudal state banquet .", "tgt": "A small flag.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. The term \"flaglets\" is correctly defined as \"a small flag\" in the output, which matches the target definition. The language model has accurately inferred the definition from the term itself.", "predicted": "Strongly Disagree"}, {"hyp": "(zoology) Of or pertaining to a minotaur.", "ref": "tgt", "src": "Elytra <define> miniatous </define> , with a large somewhat triangular black spot on their disk ,   [ \u2026 ]", "tgt": "(formal) Orange-red, the colour of red lead.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The term to be defined is \"miniatous\", and the target definition indicates that it refers to an orange-red color. However, the output provided by the language model incorrectly defines \"miniatous\" as pertaining to a minotaur, which is a creature from Greek mythology. This definition is not related to the color orange-red, nor can it be inferred from the input. Therefore, the output is incorrect and off point.", "predicted": "Strongly Agree"}, {"hyp": "(chemistry) The degree to which a substance is hydrated.", "ref": "tgt", "src": "DuBois and coworkers carried out extensive studies of the thermodynamic <define> hydricity </define> of metal hydrides ( 3.2 ) ; in many cases the metal product resulting following hydride transfer will bind a CH3CN ligand ( not shown in 3.2 ) , so comparisons of hydricity will be solvent - dependent .", "tgt": "(chemistry) The tendency in a transition metal hydride for an H- ion to transfer to a substrate", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The term 'hydricity' in the context of the input is related to the tendency of a transition metal hydride for an H- ion to transfer to a substrate. However, the output provided by the language model incorrectly defines 'hydricity' as the degree to which a substance is hydrated. This definition is not accurate or relevant to the context provided in the input.", "predicted": "Strongly Agree"}, {"hyp": "(video games) The state or condition of being bisexual in a video game.", "ref": "tgt", "src": "It can be argued that explicit representations of bisexuality , pansexuality , and other multiple - gender - attracted people are erased from games that use ' <define> playersexuality </define> ' as a mechanic .", "tgt": "(video games) The state of an NPC being attracted to the player character, especially without regard to gender, race, etc.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The term 'playersexuality' in the context of video games does not specifically refer to bisexuality. Instead, it refers to the state of a non-player character (NPC) being attracted to the player character, regardless of the player character's gender, race, etc. The output incorrectly defines 'playersexuality' as the state or condition of being bisexual in a video game, which is not accurate based on the target definition.", "predicted": "Strongly Agree"}, {"hyp": "That\u2019s not happening at the moment.", "ref": "either", "src": "That\u2019s not happening.", "tgt": "That isn\u2019t gonna happen.", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "rationale": "The output is a hallucination. The input statement is \"That\u2019s not happening,\" and the model's output is \"That\u2019s not happening at the moment.\" The addition of \"at the moment\" changes the meaning of the sentence. The input statement is absolute, indicating that something will not happen at all. However, the output suggests that the event could happen in the future, just not right now. This additional information cannot be inferred from the input, making the output a hallucination.", "predicted": "Strongly Agree"}, {"hyp": "I have a permit to carry it.", "ref": "either", "src": "I have a permit.", "tgt": "Uh, I\u2019m validated.", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The input statement \"I have a permit\" is vague and doesn't specify what the permit is for. The model's output \"I have a permit to carry it\" adds specific information that was not present or implied in the input. The model is making an assumption about what the permit is for, which is a form of hallucination. The target paraphrase \"Uh, I\u2019m validated\" maintains the vagueness of the original statement, which is the correct approach for this task.", "predicted": "Strongly Agree"}, {"hyp": "The process is easy.", "ref": "either", "src": "Easy, easy.", "tgt": "Watch it now.", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Hallucination", "Hallucination", "Not Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "rationale": "The output can be considered a hallucination. The input \"Easy, easy\" is a common phrase often used to tell someone to slow down or be careful. The target \"Watch it now\" carries a similar connotation, suggesting caution or attention. However, the output \"The process is easy\" does not convey the same meaning. It seems to interpret \"Easy, easy\" as a description of a process, which is not a reasonable inference from the input. Therefore, the output is not a correct paraphrase of the input.", "predicted": "Strongly Agree"}, {"hyp": "A number between five and eight.", "ref": "either", "src": "A five, six, seven, eight.", "tgt": "And 5, 6, 7, 8.", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Hallucination", "Hallucination", "Not Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "rationale": "The output can be considered a hallucination. The task is to generate a paraphrase of the input, but the output does not accurately reflect the input. The input is a simple list of numbers from five to eight, but the output suggests a range between five and eight, which is not the same thing. The output introduces new information that was not present or implied in the input, thus it can be classified as a hallucination.", "predicted": "Strongly Agree"}, {"hyp": "That is a safer way to travel.", "ref": "either", "src": "A lot safer that way.", "tgt": "Because it\u2019s safer.", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is not a hallucination. It accurately paraphrases the input, maintaining the same meaning and context. The input \"A lot safer that way\" is rephrased in the output as \"That is a safer way to travel.\" The output does add the context of travel, but it can be reasonably inferred from the input, which discusses safety in a certain 'way' or method, often associated with a form of action or movement. Therefore, the output is correct and accurate.", "predicted": "Strongly Disagree"}, {"hyp": "You\u2019re not a good scam artist.", "ref": "either", "src": "You\u2019re a scam artist.", "tgt": "You are an imposter.", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output can be considered a hallucination. The input statement is \"You're a scam artist,\" and the target paraphrase is \"You are an imposter.\" However, the output generated by the language model is \"You're not a good scam artist.\" This output introduces a negative evaluation (\"not good\") that is not present in the original input or the target. Therefore, it can be said that the model is hallucinating, as it is adding information that cannot be reasonably inferred from the input.", "predicted": "Strongly Agree"}, {"hyp": "When did you see him?", "ref": "either", "src": "When\u2019d you last see him?", "tgt": "When was the last time you saw him?", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. It accurately paraphrases the input, maintaining the same meaning. However, it does not match the target exactly. The target includes the phrase \"the last time,\" which is not present in the output. Despite this, the output is still a valid paraphrase of the input.", "predicted": "Strongly Disagree"}, {"hyp": "Let me leave.", "ref": "either", "src": "Let me out of here.", "tgt": "Someone let me out.", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. The original input \"Let me out of here\" has been accurately paraphrased by the language model as \"Let me leave\". Both sentences convey the same meaning of the speaker wanting to exit or be released from a certain place or situation. Therefore, the output is correct and accurate.", "predicted": "Strongly Disagree"}, {"hyp": "It is not impossible.", "ref": "either", "src": "Nothing is impossible.", "tgt": "There\u2019s nothing that can\u2019t be done.", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "rationale": "The output is not a hallucination. It accurately paraphrases the input \"Nothing is impossible\" by stating \"It is not impossible.\" Both sentences convey the same meaning, that there is no such thing as an impossible task or situation. However, it should be noted that the output does not match the target \"There\u2019s nothing that can\u2019t be done,\" but this does not make it a hallucination as it still accurately reflects the input.", "predicted": "Strongly Disagree"}, {"hyp": "Tom decided to leave the company.", "ref": "either", "src": "Tom d\u00e9cida de quitter la soci\u00e9t\u00e9.", "tgt": "Tom has decided to leave the company.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. The input sentence in French is correctly translated into English. The only difference between the target and the output is the tense of the verb \"decide\". In the target, it's \"has decided\" (present perfect tense), while in the output, it's \"decided\" (simple past tense). However, both tenses can be used to translate the French past tense \"d\u00e9cida\", so the output is still accurate.", "predicted": "Strongly Disagree"}, {"hyp": "Do you love her?", "ref": "either", "src": "Est-ce que tu l'aimes ?", "tgt": "Do you love him?", "model": "", "task": "MT", "labels": ["Not Hallucination", "Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "rationale": "The output is a hallucination. The input is in French and it translates to \"Do you love him?\" in English. However, the model incorrectly translated it to \"Do you love her?\" The gender of the person being referred to in the sentence has been changed, which is not accurate or correct. Therefore, the output is a hallucination as it contains information that cannot be reasonably inferred from the input.", "predicted": "Strongly Agree"}, {"hyp": "I got the company.", "ref": "either", "src": "J'ai de la compagnie.", "tgt": "I've got company.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "rationale": "The output is not a hallucination. Although the translation is not exactly the same as the target, it still conveys the same general meaning as the input. The phrase \"I got the company\" can be interpreted as \"I have company\" in English. Therefore, while it's not a perfect translation, it's not a hallucination because it doesn't introduce any new information or distort the original meaning.", "predicted": "Strongly Disagree"}, {"hyp": "He's got several friends.", "ref": "either", "src": "Ann a plusieurs amis.", "tgt": "Ann has many friends.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The input sentence is about \"Ann\", a female, but the output sentence refers to a male subject \"He\". The translation is incorrect because it changes the gender of the subject. The correct translation should be \"Ann has several friends.\"", "predicted": "Strongly Agree"}, {"hyp": "The captain orders the ship on board.", "ref": "either", "src": "Le capitaine donne l'ordre d'embarquer sur le navire.", "tgt": "The skipper is giving the order to board the ship.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "rationale": "The output is a hallucination. The correct translation of the input \"Le capitaine donne l'ordre d'embarquer sur le navire\" is \"The captain gives the order to board the ship.\" The output \"The captain orders the ship on board\" is incorrect and does not accurately convey the meaning of the original French sentence. The output suggests that the captain is ordering the ship itself to come on board, which is nonsensical. Therefore, the output is a hallucination.", "predicted": "Strongly Agree"}, {"hyp": "Sami called 911.", "ref": "either", "src": "Sami a appel\u00e9 le 911.", "tgt": "Sami made a call to 911.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. The input sentence in French, \"Sami a appel\u00e9 le 911,\" directly translates to \"Sami called 911,\" which is exactly what the output is. Although the output does not match the target exactly, it still accurately and correctly translates the input. The difference between the output and the target is a matter of stylistic choice rather than accuracy.", "predicted": "Strongly Disagree"}, {"hyp": "We love our school.", "ref": "either", "src": "Nous aimons notre \u00e9cole.", "tgt": "We like our school.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. The input \"Nous aimons notre \u00e9cole\" is correctly translated to English as \"We love our school\". Although the target translation provided is \"We like our school\", the verb \"aimons\" in French can be translated as both \"like\" and \"love\" in English. Therefore, the output is correct and accurate, even though it does not match the target exactly.", "predicted": "Strongly Disagree"}, {"hyp": "How'd you get \"pretty\"?", "ref": "either", "src": "Comment \u00e9pelles-tu \"pretty\" ?", "tgt": "How do you spell \"pretty\"?", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The input is asking how to spell the word \"pretty\" in French, but the output is asking how the word \"pretty\" was obtained. The output does not accurately translate the input, thus it is incorrect and off point.", "predicted": "Strongly Agree"}, {"hyp": "The old days will never come back.", "ref": "either", "src": "Les jours anciens ne reviendront jamais.", "tgt": "The old days have gone never to return.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. Although the output does not match the target exactly, it still accurately translates the meaning of the original French sentence. Both the target and output convey the same idea that the old days will not return. Therefore, the output is correct and accurate.", "predicted": "Strongly Disagree"}, {"hyp": "I bought three different varieties of flowers.", "ref": "either", "src": "J\u2019ai achet\u00e9 trois diff\u00e9rentes sortes de fleurs.", "tgt": "I bought three different kinds of flowers.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. The translation from French to English is accurate and maintains the original meaning of the sentence. The words \"sortes\" and \"varieties\" are synonymous in this context, so using either one does not change the overall meaning. Therefore, the output is correct and not a hallucination.", "predicted": "Strongly Disagree"}, {"hyp": "It's my duty.", "ref": "either", "src": "C'est mon m\u00e9tier.", "tgt": "It's my job.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "rationale": "The output is not a hallucination. While the output does not match the target exactly, it is still a correct and reasonable translation of the input. In French, \"C'est mon m\u00e9tier\" can be translated to \"It's my job\" or \"It's my duty\". Both translations are accurate and convey the same general meaning. Therefore, the output is not a hallucination, but rather an alternative correct translation.", "predicted": "Strongly Disagree"}, {"hyp": "I have nothing to do with it.", "ref": "either", "src": "J'en ai rien \u00e0 secouer.", "tgt": "I don't give a shit about it.", "model": "", "task": "MT", "labels": ["Hallucination", "Not Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "rationale": "The output is not a hallucination. However, it is not entirely accurate. The French phrase \"J'en ai rien \u00e0 secouer\" is a colloquial expression that translates more closely to \"I don't give a damn\" or \"I don't give a shit,\" as indicated in the target. The output \"I have nothing to do with it\" is not a direct translation and misses the dismissive and indifferent tone of the original phrase. Therefore, while the output is not a hallucination, it is not an accurate translation.", "predicted": "Strongly Disagree"}, {"hyp": "I've been confiscated.", "ref": "either", "src": "On m'a confisqu\u00e9 mon permis.", "tgt": "I've had my driving license confiscated.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The correct translation of the input \"On m'a confisqu\u00e9 mon permis\" is \"I've had my driving license confiscated.\" However, the model's output \"I've been confiscated\" is incorrect and does not accurately convey the meaning of the original sentence. The model has omitted the crucial information about the \"driving license\" being confiscated, which is a key aspect of the input. Therefore, the output can be considered a hallucination as it contains information that cannot be reasonably inferred from the input.", "predicted": "Strongly Agree"}, {"hyp": "Stop turning.", "ref": "either", "src": "Arr\u00eate de tourner.", "tgt": "Stop spinning.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. The input \"Arr\u00eate de tourner\" is correctly translated to \"Stop turning\" in English. Although the target translation is \"Stop spinning\", both \"turning\" and \"spinning\" can be used interchangeably in this context, and thus the output is still a correct and accurate translation of the input.", "predicted": "Strongly Disagree"}, {"hyp": "What kind of bread are you eating in general?", "ref": "either", "src": "Quel genre de pain est-ce que tu manges en g\u00e9n\u00e9ral ?", "tgt": "What kind of bread do you usually eat?", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. The translation provided by the language model is accurate and conveys the same meaning as the target. The slight difference in phrasing (\"usually eat\" vs \"are you eating in general\") does not change the overall meaning of the sentence. Therefore, the output is correct and not a hallucination.", "predicted": "Strongly Disagree"}, {"hyp": "The eagles are friends.", "ref": "either", "src": "Les araign\u00e9es sont mignonnes.", "tgt": "Spiders are cute.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The input sentence in French translates to \"Spiders are cute\" in English, which is accurately reflected in the target. However, the output \"The eagles are friends\" is not a correct translation of the input. It introduces new information (eagles and friends) that is not present or inferred from the input, thus it is a hallucination.", "predicted": "Strongly Agree"}, {"hyp": "Farhat Mehenni's separatist group concluded a compromise with the radical Islamist group Rachad for the destabilization of Algeria. This led Algeria to officially consider the two groups as terrorist organizations.", "ref": "either", "src": "Le groupe s\u00e9paratiste de Ferhat Mehenni a conclu un compromis avec le groupe islamiste radical Rachad pour la d\u00e9stabilisation de l'Alg\u00e9rie. C'est ce qui a conduit l'Alg\u00e9rie \u00e0 officiellement consid\u00e9rer les deux groupes comme des organisations terroristes.", "tgt": "Ferhat Mehenni's separatist group cut a deal with the radical Islamist group Rachad to destabilize Algeria. That's what led Algeria to officially consider both groups as terrorist organizations.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. It accurately translates the input from French to English. The only minor difference is the use of \"concluded a compromise\" instead of \"cut a deal\", but both phrases essentially mean the same thing. Therefore, the output is correct and accurate.", "predicted": "Strongly Disagree"}, {"hyp": "You certainly don't have your mother's good nature.", "ref": "either", "src": "Tu n'as certainement pas la bonne nature de ta m\u00e8re.", "tgt": "You definitely don't have the good nature of your mother.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. Although the output does not match the target verbatim, it conveys the same meaning as the input. The translation is accurate and maintains the sentiment and information of the original French sentence. Therefore, it is not a hallucination.", "predicted": "Strongly Disagree"}, {"hyp": "Tom didn't hurry.", "ref": "either", "src": "Tom n'a pas hurl\u00e9.", "tgt": "Tom didn't scream.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The French sentence \"Tom n'a pas hurl\u00e9\" translates to \"Tom didn't scream\" in English. However, the model incorrectly translated it as \"Tom didn't hurry\". The model's output is not accurate and does not correctly reflect the meaning of the input.", "predicted": "Strongly Agree"}, {"hyp": "Do you like tomatoes?", "ref": "either", "src": "Tom aime-t-il les tomates ?", "tgt": "Tom likes tomatoes?", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The input is in French and it translates to \"Does Tom like tomatoes?\" However, the output generated by the model is \"Do you like tomatoes?\" which is incorrect. The model has incorrectly replaced \"Tom\" with \"you\", thus changing the subject of the sentence. Therefore, the output is not accurate.", "predicted": "Strongly Agree"}, {"hyp": "In this case we see the results all the time.", "ref": "either", "src": "Dans ce m\u00e9tier on voit tout de suite les r\u00e9sultats.", "tgt": "In this activity one immediately sees the result.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is not a hallucination. Although it does not match the target translation exactly, it still accurately conveys the main idea of the input. The input sentence in French translates to \"In this job, we immediately see the results.\" The output, \"In this case we see the results all the time,\" is a slightly different interpretation but still maintains the core meaning of seeing results quickly or immediately in a certain situation or job. Therefore, it is not a hallucination as it does not introduce new information or misinterpret the input.", "predicted": "Strongly Disagree"}, {"hyp": "I really think you should leave.", "ref": "either", "src": "Je pense vraiment que vous devriez partir.", "tgt": "I really think you should leave.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. The input sentence is in French and translates to \"I really think you should leave\" in English. The language model has accurately translated the input to the target language, maintaining the same meaning and context. Therefore, the output is correct and accurate.", "predicted": "Strongly Disagree"}, {"hyp": "Make him a horse!", "ref": "either", "src": "Fais-lui un c\u00e2lin !", "tgt": "Give her a hug.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The input is in French and translates to \"Give her a hug!\" in English. However, the output provided by the language model is \"Make him a horse!\" which is not only a mistranslation but also includes information (\"horse\") that is not present or inferred from the original input. Therefore, the output is incorrect and off point.", "predicted": "Strongly Agree"}, {"hyp": "Don't lend anyone else the book you borrowed.", "ref": "either", "src": "Ne pr\u00eate pas \u00e0 un autre le livre que tu as emprunt\u00e9.", "tgt": "Don't lend a borrowed book to another.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. The translation provided by the language model accurately conveys the meaning of the original French sentence. While the wording is slightly different from the target, the overall meaning remains the same. Both the target and output instruct not to lend a book that one has borrowed to someone else. Therefore, the output is correct and accurate.", "predicted": "Strongly Disagree"}, {"hyp": "I want to drink something free.", "ref": "either", "src": "Je veux boire quelque chose de frais.", "tgt": "I want something cold to drink.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The French sentence \"Je veux boire quelque chose de frais\" translates to \"I want something cold to drink\" in English. However, the model incorrectly translated \"frais\" as \"free\" instead of \"cold\". Therefore, the output is incorrect and does not accurately reflect the input.", "predicted": "Strongly Agree"}, {"hyp": "Do you have a cryon?", "ref": "either", "src": "As-tu un crayon ?", "tgt": "Have you got a pencil?", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is not a hallucination. The output is a correct translation of the input, except for a minor spelling error. The word \"cryon\" should be \"pencil\". Despite this error, the output still conveys the same meaning as the input and the target. Therefore, it is not a hallucination, which would involve the output being incorrect, off point, or containing information not present in the input.", "predicted": "Strongly Disagree"}, {"hyp": "I talked to other people in the same situation.", "ref": "either", "src": "J'ai discut\u00e9 avec d'autres personnes dans la m\u00eame situation.", "tgt": "I have talked with others in the same situation.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. The translation provided by the language model is accurate and conveys the same meaning as the original French sentence. The slight difference in verb tense (\"I have talked\" vs \"I talked\") does not significantly alter the meaning of the sentence. Therefore, the output is correct and not a hallucination.", "predicted": "Strongly Disagree"}, {"hyp": "The nurse will check your arm within 2 days to see if there's any reaction.", "ref": "either", "src": "L'infirmier v\u00e9rifiera ton bras dans les 2 jours pour voir s'il y a une r\u00e9action.", "tgt": "The nurse will check your arm within 2 days to see if there is a reaction.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. The translation provided by the language model is accurate and conveys the same meaning as the target translation. The only difference is the use of \"any reaction\" instead of \"a reaction\", but this does not change the overall meaning of the sentence. Therefore, the output is correct and not a hallucination.", "predicted": "Strongly Disagree"}, {"hyp": "You're not missing anyone.", "ref": "either", "src": "Tu ne manques \u00e0 personne.", "tgt": "No one misses you.", "model": "", "task": "MT", "labels": ["Hallucination", "Not Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "rationale": "The output is a hallucination. The input sentence in French, \"Tu ne manques \u00e0 personne,\" translates to \"No one misses you\" in English. However, the model's output, \"You're not missing anyone,\" is a completely different meaning. Therefore, the output is incorrect and does not accurately reflect the input.", "predicted": "Strongly Agree"}, {"hyp": "I've got the floor and the furniture.", "ref": "either", "src": "J'ai poli le plancher et les meubles.", "tgt": "I polished up the floor and furniture.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The input sentence in French is \"J'ai poli le plancher et les meubles,\" which translates to \"I polished the floor and the furniture.\" However, the output provided by the language model is \"I've got the floor and the furniture,\" which is not an accurate translation of the input. The model has incorrectly translated \"poli\" (polished) to \"got,\" thus changing the meaning of the sentence.", "predicted": "Strongly Agree"}, {"hyp": "I can't do it alone.", "ref": "either", "src": "Je ne peux le faire seule. Il vous faut m'aider.", "tgt": "I can't do it alone. You have to help me.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "rationale": "The output is not a hallucination, but it is incomplete. The language model correctly translated the first sentence from French to English. However, it failed to translate the second sentence, \"Il vous faut m'aider,\" which means \"You have to help me.\" Therefore, while the output is not a hallucination, it is not fully correct or accurate because it does not include the entire translation.", "predicted": "Strongly Disagree"}, {"hyp": "He lost what he received from his father.", "ref": "either", "src": "Il a perdu ce qu'il a re\u00e7u de son p\u00e8re.", "tgt": "He wasted that which he had received from his father.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. The output accurately translates the input from French to English. However, it should be noted that the verb \"perdu\" can be translated as both \"lost\" and \"wasted\". In this context, \"lost\" is a more literal translation, while \"wasted\" might convey a more figurative meaning, implying that the person did not use what they received wisely. Both translations are correct, but they may convey slightly different nuances.", "predicted": "Strongly Disagree"}, {"hyp": "We've discovered a lot of news.", "ref": "either", "src": "Nous avons d\u00e9couvert une grande nouveaut\u00e9.", "tgt": "We have discovered a great novelty.", "model": "", "task": "MT", "labels": ["Hallucination", "Not Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "rationale": "The output can be considered a hallucination. The original French sentence translates to \"We have discovered a great novelty.\" However, the model's translation, \"We've discovered a lot of news,\" is not accurate. The model incorrectly translated \"une grande nouveaut\u00e9\" (a great novelty) as \"a lot of news,\" which adds information that was not present in the original input. Therefore, the output is a hallucination.", "predicted": "Strongly Agree"}, {"hyp": "Why is everyone okay?", "ref": "either", "src": "Pourquoi est-ce que tout le monde rigole ?", "tgt": "Why is everyone laughing?", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The input in French is asking \"Why is everyone laughing?\" but the model incorrectly translates it to \"Why is everyone okay?\" The output is not an accurate translation of the input and introduces information (\"okay\") that is not present or inferred from the original sentence. Therefore, it is a hallucination.", "predicted": "Strongly Agree"}, {"hyp": "No matter what you do to your guide.", "ref": "either", "src": "Chacun fait \u00e0 sa guise.", "tgt": "Each one does as he likes.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The correct translation of the French sentence \"Chacun fait \u00e0 sa guise\" is \"Each one does as he likes,\" as indicated in the target. The output \"No matter what you do to your guide\" is not an accurate translation of the input and introduces new information that is not present or inferred from the original sentence. Therefore, it is incorrect and off point.", "predicted": "Strongly Agree"}]