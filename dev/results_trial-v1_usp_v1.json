[{"hyp": "A district of Kowloon, China.", "ref": "tgt", "src": "The City <define> Chiuchow </define> is Kowloon 's other top restaurant and is famous for its goose dishes and other specialties from the Chiuchow region ( you may also wish to try the beef satay done in a creamy sauce ) .", "tgt": "The Chaoshan region where the Teochew dialect is spoken.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:10:07Z", "rationale_0": "The output is a hallucination. While the input does mention that Chiuchow is a restaurant in Kowloon, it does not suggest that Chiuchow is a district of Kowloon. Instead, it refers to Chiuchow as a region, which is consistent with the target definition.", "rationale_1": "The output is a hallucination. While the input mentions that Chiuchow is a restaurant in Kowloon, the output incorrectly defines Chiuchow as a district of Kowloon. The target definition correctly identifies Chiuchow as a region in China where Teochew dialect is spoken.", "rationale_2": "The output is a hallucination. While the input does mention the city of Chiuchow in relation to Kowloon, the output incorrectly defines Chiuchow as a district of Kowloon, China. The target correctly identifies Chiuchow as the Chaoshan region where the Teochew dialect is spoken. Therefore, the output is incorrect.", "rationale_3": "The output is a hallucination. The output defines Chiuchow as a district of Kowloon, China, which contradicts the target that defines it as a region where the Teochew dialect is spoken in the Chaoshan region. The output does not accurately represent the information provided in the input.", "rationale_4": "The output is a hallucination. The target suggests that Chiuchow refers to the Chaoshan region where the Teochew dialect is spoken, but the output incorrectly defines it as a district of Kowloon, China. The input does mention Kowloon but it is referring to a restaurant named Chiuchow in Kowloon, not a district."}, {"hyp": "(Wicca) A witchdoctor.", "ref": "tgt", "src": "\u201c I went to see the witchdoctor , the <define> igqira </define> . And he spoke to the izinyanya , the spirits of the ancestors . \u201d", "tgt": "(South Africa) A traditional tribal diviner or spiritual healer.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Not Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:10:31Z", "rationale_0": "The output is a hallucination. The target indicates that \"igqira\" refers to a traditional tribal diviner or spiritual healer in South Africa. The output, on the other hand, defines \"igqira\" as a witchdoctor in Wicca, which is a misinterpretation of the input.", "rationale_1": "The output is a hallucination. While it correctly identifies 'igqira' as a type of witchdoctor, it incorrectly associates it with Wicca. The target definition makes it clear that 'igqira' refers to a traditional tribal diviner or spiritual healer in South Africa, not a practitioner of Wicca. Therefore, the output contains extraneous and incorrect information.", "rationale_2": "The output is a hallucination. While it correctly identifies 'igqira' as some form of witchdoctor, it incorrectly associates it with Wicca, a modern Pagan religious movement, rather than with South African traditional tribal spiritual practices as specified in the target.", "rationale_3": "The output is a hallucination. While the term \"igqira\" does generally refer to a spiritual healer, the output is incorrect in specifying \"Wicca\" as the context. The input sentence clearly states the context as South Africa, and \"Wicca\" is not a term specific or unique to South Africa. Thus, the output is not accurate.", "rationale_4": "The output is a hallucination. The term 'igqira' is specifically defined as a traditional tribal diviner or spiritual healer in South Africa, not a witchdoctor in Wicca. The output does not accurately reflect the target definition."}, {"hyp": "(nautical) A halyard.", "ref": "tgt", "src": "Haul away , keeping strain on both parts of the halyard so that the <define> pigstick </define> remains vertical as it goes up and does n't foul the spreaders .", "tgt": "(nautical) A staff that carries a flag or pennant above the mast of a sailboat.", "model": "", "task": "DM", "labels": ["Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:10:49Z", "rationale_0": "The output is a hallucination. The target definition indicates that a pigstick is a staff that carries a flag or pennant above the mast of a sailboat, not a halyard as the output suggests.", "rationale_1": "The output is a hallucination. The term to be defined is \"pigstick\", but the output provides a definition for \"halyard\", which is a different nautical term. The definition provided in the output does not match the target definition for \"pigstick\".", "rationale_2": "The output is a hallucination. The term \"pigstick\" is defined incorrectly as a \"halyard\", when it should have been defined as a \"staff that carries a flag or pennant above the mast of a sailboat.\"", "rationale_3": "The output is a hallucination. The target defines \"pigstick\" as a staff that carries a flag or pennant above the mast of a sailboat, but the output incorrectly defines it as a halyard. This is not accurate as a pigstick and a halyard serve different functions on a sailboat.", "rationale_4": "The output is a hallucination. The term \"pigstick\" is incorrectly defined as a \"halyard\" in the output, while the target correctly defines it as a staff that carries a flag or pennant above the mast of a sailboat."}, {"hyp": "The quality of being rational.", "ref": "tgt", "src": "And what difference is there between the credibleness and <define> rationalness </define> of any of these wonders and the credibleness and rationalness of Papal infallibility ?", "tgt": "(archaic) The quality or state of being rational.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T18:11:07Z", "rationale_0": "The output is not a hallucination. It correctly defines the term 'rationalness' as being the quality of being rational, which aligns with the target definition. The output is concise and accurate, it does not include any extraneous or incorrect information.", "rationale_1": "The output is not a hallucination. The output is correct and accurate as it matches with the target definition of the term \"rationalness\". It simply rephrases the target by excluding the words \"quality or state of\", which doesn't change the meaning.", "rationale_2": "The output is correct and accurate. It aligns perfectly with the target definition, defining \"rationalness\" as the quality of being rational.", "rationale_3": "The output is correct and accurate. It correctly defines the term \"rationalness\" as the quality of being rational, which matches the target definition.", "rationale_4": "The output is correct and accurate as it matches the target definition. The term \"rationalness\" is defined as the quality or state of being rational, which is accurately reflected in the output."}, {"hyp": "(uncountable) The study of trees.", "ref": "tgt", "src": "It is now generally supposed that the forbidden fruit was a kind of citrus , but certain facts connected with <define> arborolatry </define> seem to me to disprove this opinion .", "tgt": "The worship of trees.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:13:09Z", "rationale_0": "The output is a hallucination. The target defines 'arborolatry' as 'the worship of trees,' but the output incorrectly defines it as 'the study of trees.' This indicates that the model has provided incorrect information.", "rationale_1": "The output is a hallucination. The target defines \"arborolatry\" as \"The worship of trees,\" whereas the output incorrectly defines it as \"The study of trees.\"", "rationale_2": "The output is a hallucination. The target defines \"arborolatry\" as the worship of trees, but the output incorrectly defines it as the study of trees.", "rationale_3": "The output is a hallucination. The target indicates that \"arborolatry\" is the worship of trees, while the output incorrectly defines it as the study of trees.", "rationale_4": "The output is a hallucination. The target defines \"arborolatry\" as \"The worship of trees\", but the output inaccurately defines it as \"The study of trees.\""}, {"hyp": "(zoology) A pseudostome.", "ref": "tgt", "src": "The pseudembryo moves rapidly in the water , rolling round and swinging from side to side ; as a rule , and especially when at rest , the surface bearing the pseudostome and <define> pseudoproct </define> is turned downwards .", "tgt": "(biology) The anal opening on the pseudembryo of an echinoderm.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:13:34Z", "rationale_0": "The output is a hallucination. The term \"pseudoproct\" is inaccurately defined as a \"pseudostome\" in the output, which is not in alignment with the target definition that identifies it as the anal opening on a pseudembryo of an echinoderm.", "rationale_1": "The output is a hallucination. The output incorrectly defines 'pseudoproct' as a 'pseudostome', which is not accurate according to the target definition. The target definition specifies that a 'pseudoproct' is the anal opening on the pseudembryo of an echinoderm, not a pseudostome.", "rationale_2": "The output is a hallucination. The target definition refers to the pseudoproct as the anal opening on the pseudembryo of an echinoderm, but the output incorrectly defines it as a pseudostome.", "rationale_3": "The output is a hallucination. The target definition refers to the pseudoproct as the anal opening on the pseudembryo of an echinoderm, but the output incorrectly defines it as a pseudostome, which is a different biological term.", "rationale_4": "The output is a hallucination. The target defines 'pseudoproct' as the anal opening on the pseudembryo of an echinoderm, whereas the output incorrectly defines it as a pseudostome."}, {"hyp": "Resembling or characteristic of umber.", "ref": "tgt", "src": "<define> umbery </define> gold", "tgt": "Of or pertaining to umber; like umber.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T18:13:56Z", "rationale_0": "The output is correct and accurate. The definition provided in the output aligns well with the target definition, even though the specific words used are a little different. Both definitions essentially convey that 'umbery' means 'resembling or characteristic of umber'. There are no hallucinations as the output does not include any incorrect or extraneous information.", "rationale_1": "The output is not a hallucination. It correctly provides a definition of \"umbery\" that aligns with the target, even though the exact words used are not the same. Both definitions convey the message that \"umbery\" refers to something that is like or resembles umber.", "rationale_2": "The output is correct and accurate. It is providing a synonym for the term \"umbery\", which means resembling or characteristic of umber, essentially matching the target definition. Therefore, it is not a hallucination.", "rationale_3": "The output is not a hallucination. While the phrasing is slightly different from the target, the definition provided is essentially the same. Both describe something as resembling or being characteristic of umber.", "rationale_4": "The output is not a hallucination. The output correctly defines \"umbery\" as something resembling or characteristic of umber, which aligns with the target definition. The term \"gold\" in the input seems to be irrelevant or misaligned."}, {"hyp": "(music, transitive) To play (a note) at the same time.", "ref": "tgt", "src": "Now the two bounding notes of an enharmonic tetrachord of the relevant sort will indeed both be the lowest notes of pykna when the tetrachords are put together in conjunction ; but the higher of them can never <define> abut on </define> a pyknon in the case envisaged here , where the tone is introduced to disjoin the tetrachords .", "tgt": "(transitive) To border on.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:14:23Z", "rationale_0": "The output is a hallucination. The definition provided in the output does not match the target definition. The term 'abut on' is defined as to border on, not to play a note at the same time as suggested in the output.", "rationale_1": "The output is a hallucination. The target definition is about bordering on something, which in the context of the input would mean one musical note being next to or up against another. However, the output definition is about playing a note at the same time as something else, which is not the same concept.", "rationale_2": "The output is a hallucination. The target defines \"abut on\" as \"to border on,\" which is consistent with the context provided in the input. However, the output defines it as \"to play (a note) at the same time,\" which does not align with the target definition or the context provided in the input.", "rationale_3": "The output is a hallucination. The target defines \"abut on\" as to border on, whereas the output incorrectly defines it as to play a note at the same time. This is not accurate and does not align with the correct definition of the term.", "rationale_4": "The output is a hallucination. The correct definition of 'abut on' is to border on, as stated in the target. The output's definition is incorrect and not relevant to the term in context."}, {"hyp": "(Australia, New Zealand, colloquial) A hatfish.", "ref": "tgt", "src": "Noah did n't realize when he stayed on the job - he was then about 600 years old and built the ark and drove the animals in two by two , the <define> hatfish </define> and the kangaroo \u2014 \u2014 he did n't realize he was laying the foundation for an occupation for old men in New York , several years later .", "tgt": "(colloquial) Synonym of halibut", "model": "", "task": "DM", "labels": ["Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:14:47Z", "rationale_0": "The output is a hallucination. It incorrectly defines \"hatfish\" as an Australian and New Zealand colloquial term, which is not supported by the target. The target suggests that \"hatfish\" is a synonym for halibut. There is no mention or implication of Australia or New Zealand in the input or target.", "rationale_1": "The output is a hallucination. The term \"hatfish\" is supposed to be a synonym for halibut as per the target, but the output incorrectly defines it as an Australian or New Zealand colloquial term without providing any further details. Furthermore, there's no mention of Australia, New Zealand, or any colloquialisms in the input.", "rationale_2": "The output is a hallucination. It provides a regional and colloquial definition for the term \"hatfish,\" but it does not match the target, which states that \"hatfish\" is a synonym for \"halibut.\" The output also does not accurately reflect the context provided in the input.", "rationale_3": "The output is a hallucination. The output defines 'hatfish' as an Australian and New Zealand colloquial term, but the input does not provide any context or information that supports this. The target definition, which states that 'hatfish' is a synonym for halibut, is also not reflected in the output.", "rationale_4": "The output is a hallucination. The definition provided for 'hatfish' in the output is not in alignment with the target which states that 'hatfish' is a synonym of halibut. The output instead defines 'hatfish' as a term used in Australia and New Zealand, which is not mentioned or inferred in the target or input."}, {"hyp": "Having a keen sense of humor.", "ref": "tgt", "src": "<define> keen </define> satire or sarcasm", "tgt": "Acrimonious, bitter, piercing.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:15:15Z", "rationale_0": "The output is a hallucination. The target definition indicates that \"keen\" in this context refers to acrimonious, bitter, or piercing satire or sarcasm. The output, however, defines \"keen\" as having a sense of humor, which is not accurate in this context.", "rationale_1": "The output is a hallucination. While the term \"keen\" can refer to having a sharp or acute quality, in the context of satire or sarcasm, it does not necessarily equate to having a keen sense of humor. The output does not align with the target definition which describes \"keen\" as acrimonious, bitter, or piercing.", "rationale_2": "The output is a hallucination. While having a \"keen sense of humor\" could potentially involve satire or sarcasm, the output definition does not directly address or define the term as expected. The target suggests the term should be defined in terms of acrimony, bitterness, or being piercing, none of which are covered in the output.", "rationale_3": "The output is a hallucination. The term 'keen' was supposed to be defined in the context of 'satire or sarcasm', but the output provides a definition that is not related to this context. It instead defines 'keen' in the context of humor. The output is not accurate or consistent with the target.", "rationale_4": "The output is a hallucination. While it does correctly associate the term 'keen' with a sharp or intense quality, it inaccurately applies it to a sense of humor, which was not mentioned in the input. The input mentions satire or sarcasm, so the definition should relate to these. The target correctly defines 'keen' in this context as acrimonious, bitter, or piercing."}, {"hyp": "A person who has a pass.", "ref": "tgt", "src": "<define> Passholders </define> can visit the theme park all year round .", "tgt": "One who holds a pass.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T18:15:31Z", "rationale_0": "The output is not a hallucination. It accurately defines 'Passholders' as a person who has a pass, which is synonymous with the target definition of one who holds a pass.", "rationale_1": "The output is not a hallucination. It accurately provides a definition for \"Passholders\" as someone who has a pass, which is in line with the target definition.", "rationale_2": "The output is not a hallucination. It accurately defines the term \"Passholders\" as a person who has a pass, which is in line with the target definition.", "rationale_3": "The output is not a hallucination. It accurately provides a definition for \"Passholders\" which matches closely with the target definition.", "rationale_4": "The output is correct and accurate. It matches with the target definition that a passholder is a person who holds a pass. There is no hallucination as the output stays on point and does not add any extraneous information."}, {"hyp": "(colloquial) A term of endearment.", "ref": "tgt", "src": "Hey , <define> babe </define> , how 's about you and me getting together ?", "tgt": "(affectionate) Darling (term of endearment).", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T18:15:54Z", "rationale_0": "The output is not a hallucination. Although it doesn't specifically mention \"darling\" as the target does, it correctly defines \"babe\" as a term of endearment used in colloquial language.", "rationale_1": "The output is not a hallucination. It provides a correct definition of the term 'babe' in the given context. However, it is not as specific as the target definition, which includes the attribute of 'affectionate' and the synonym 'darling'.", "rationale_2": "The output is not a hallucination. Although the output differs slightly from the target, it is still correct and accurate. The term \"babe\" is indeed a colloquial term of endearment. The output does not include the \"affectionate\" or \"darling\" aspects of the target, but its absence doesn't make the output incorrect or off point.", "rationale_3": "The output is not a hallucination. It correctly defines the term \"babe\" as a term of endearment, although it does not specify that it's an affectionate term like the target does. It also includes the additional information that it's a colloquial term, which is accurate and relevant.", "rationale_4": "The output is not a hallucination. While the output doesn't include the descriptor \"affectionate\" or the specific term \"Darling,\" it is still correct in that \"babe\" is indeed a colloquial term of endearment."}, {"hyp": "(intransitive) To speak in a slurred manner.", "ref": "tgt", "src": "Sometimes life takes hold of one , carries the body along , accomplishes one 's history , and yet is not real , but leaves oneself as it were <define> slurred over </define> .", "tgt": "(dated) To deal with something hurriedly; to treat in a perfunctory manner.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:18:02Z", "rationale_0": "The output is a hallucination. The output definition provided by the model is incorrect. The term \"slurred over\" in the given context does not refer to speaking in a slurred manner, but rather to dealing with something in a hurried or perfunctory way, as indicated in the target definition.", "rationale_1": "The output is a hallucination. The target suggests that 'slurred over' refers to dealing with something hurriedly or in a superficial manner, while the output defines it as speaking in a slurred manner, which is incorrect in the given context.", "rationale_2": "The output is a hallucination. The target suggests that 'slurred over' refers to dealing with something hurriedly or in a perfunctory manner, but the output defines it as speaking in a slurred manner. The output is therefore incorrect.", "rationale_3": "The output is a hallucination. The target definition suggests that 'slurred over' refers to handling something in a hurried or superficial manner, while the output incorrectly defines it as speaking in a slurred, unclear manner. The output does not align with the target and doesn't correctly define the term based on the given context.", "rationale_4": "The output is a hallucination. It provides a definition that involves 'speaking in a slurred manner', which does not align with the target definition about dealing with something hurriedly or in a perfunctory manner. The output is off point and does not accurately represent the definition of 'slurred over' in the given context."}, {"hyp": "A device that simulates walking.", "ref": "tgt", "src": "During the late 1960s and early 1970s , it was also the site of the lunar 1\u20446 gravity <define> walking simulator </define> rig .", "tgt": "Used other than figuratively or idiomatically: see walking,\u200e simulator.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Not Hallucination"], "predicted": "Hallucination", "predicted_p": 0.8, "timestamp": "2023-11-05T18:18:32Z", "rationale_0": "The output is incorrect and can be considered as a hallucination. While it correctly identifies that a 'walking simulator' is a device that simulates walking, it misses the key aspect of the lunar 1\u20446 gravity context which is integral to the specific 'walking simulator' being referenced in the input.", "rationale_1": "The output is incorrect. While it correctly identifies that the term refers to a device simulating walking, it fails to incorporate the important contextual information from the input, namely that it is a simulator specifically for lunar 1/6 gravity conditions. Therefore, the output is a hallucination.", "rationale_2": "The output is a hallucination. The model's output is too general and does not capture the specific context of the term \"walking simulator\" as provided in the input, which refers to a device used to simulate the experience of walking in the 1/6th lunar gravity. The target definition also implies that the term is used in a non-figurative or idiomatic context, which is not captured in the output.", "rationale_3": "The output is a hallucination. While it correctly identifies that a \"walking simulator\" is a device that simulates walking, it neglects to include the specific context provided in the input. The input mentions a \"lunar 1/6 gravity walking simulator rig\", implying that this simulator was specifically designed for training astronauts to walk in the moon's gravity, which is not conveyed in the output.", "rationale_4": "The output is partially correct but not entirely accurate. While the output does correctly identify that the \"walking simulator\" is a device that simulates walking, it leaves out the crucial detail from the input that it is specifically designed to simulate walking in lunar 1\u20446 gravity conditions. This missing information makes the output incomplete."}, {"hyp": "(intransitive, colloquial) To be very hot.", "ref": "tgt", "src": "Let 's face it , they 're there for a good stroll on a Sunday afternoon when it 's <define> pissing </define>   outside .", "tgt": "(ambitransitive, mildly, _, vulgar) To rain heavily.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:22:18Z", "rationale_0": "The output is a hallucination. The term 'pissing' in this context is meant to describe a state of heavy rain, not extreme heat as the output suggests. Therefore, the output is incorrect.", "rationale_1": "The output is a hallucination. The term \"pissing\" in the context provided, refers to heavy rain, not hot weather. Therefore, the output is incorrect.", "rationale_2": "The output is a hallucination. The target definition indicates that 'pissing' in this context refers to heavy rain, but the output inaccurately defines it as being very hot. This is incorrect and does not align with the target definition.", "rationale_3": "The output is a hallucination. It defines \"pissing\" as being very hot, which is incorrect. The target definition, which is to rain heavily, is more accurate given the context provided in the input.", "rationale_4": "The output is a hallucination. The term 'pissing' in this context refers to heavy rain, not hot weather, hence the output doesn't match with the target definition."}, {"hyp": "(geology) Synonym of synecdoche", "ref": "tgt", "src": "In the Ronne <define> syneclise </define> the thickness of sedimentary cover reaches 13.5 km and the folded basement has a complex relief owing to block movements along faults of different rank .", "tgt": "(geology) A large, shallow depression formed on a continental platform due to slow subsidence.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:22:44Z", "rationale_0": "The output is a hallucination. The target indicates that a \"syneclise\" is a type of geological formation, specifically a large, shallow depression formed on a continental platform due to slow subsidence. However, the output inaccurately defines \"syneclise\" as a synonym for \"synecdoche,\" which is a figure of speech in literature, not a geological term.", "rationale_1": "The output is a hallucination. The provided definition does not match the target definition; it appears to confuse \"syneclise\" with \"synecdoche,\" which is a figure of speech, not a geological term.", "rationale_2": "The output is a hallucination. The term \"syneclise\" is inaccurately defined as a synonym of \"synecdoche\", which is a completely unrelated term from the field of rhetoric, not geology. The correct definition, as shown in the target, refers to a geological feature.", "rationale_3": "The output is a hallucination. The target definition discusses a geological feature, a large shallow depression due to slow subsidence, however, the output incorrectly defines the term 'syneclise' as a synonym of 'synecdoche', which is a literary term and not related to geology or the context provided in the input.", "rationale_4": "The output is a hallucination. The term \"syneclise\" in the context of geology is incorrectly defined as a synonym of \"synecdoche,\" which is a literary term, not a geological one. The correct definition related to geology, as indicated by the target, is a large, shallow depression formed on a continental platform due to slow subsidence."}, {"hyp": "(informal) A person who is addicted to sport.", "ref": "tgt", "src": "I have spent much of my life a recovering <define> sportaholic </define> . If it bounced , rolled , slid , or flew , I chased it . Or watched it .", "tgt": "A sportsaholic.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T18:23:05Z", "rationale_0": "The output is not a hallucination. It correctly defines 'sportaholic' as a person who is addicted to sports, which aligns with the target definition. The term 'sportaholic' implies an excessive or compulsive interest in sports, which is correctly captured by the term 'addicted' in the output.", "rationale_1": "The output is correct and accurate. It defines the term 'sportaholic' correctly as a person who is addicted to sports, which aligns with the target. Therefore, it is not a hallucination.", "rationale_2": "The output is correct and not a hallucination. It accurately defines the term 'sportaholic' as a person who is addicted to sport, which is in line with the target.", "rationale_3": "The output is not a hallucination. It accurately defines the term \"sportaholic\" as someone who is addicted to sports, which aligns with the target definition. The additional information that it is an informal term is not extraneous but provides useful context.", "rationale_4": "The output is not a hallucination. It accurately defines the term \"sportaholic\" as a person who is addicted to sports, which aligns with the target."}, {"hyp": "Resembling or characteristic of French surrealism.", "ref": "tgt", "src": "Quatermass also mediated Wellsian influence on the tone and preoccupations of the new hybrid SF \u2013 horror - film genre , with its monstrous <define> Gigeresque </define> fusions of machine and organism [ \u2026 ]", "tgt": "Reminiscent of H. R. Giger (born 1940), Swiss surrealist painter best known for nightmarish biomechanical imagery.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Not Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:23:30Z", "rationale_0": "The output is a hallucination. The output is incorrect as it associates the term 'Gigeresque' with French surrealism, while the target correctly identifies it as reminiscent of H. R. Giger, a Swiss surrealist painter. The output is off-point in terms of geographical and individual reference.", "rationale_1": "The output is a hallucination. The term \"Gigeresque\" refers to the style of H. R. Giger, a Swiss surrealist artist, not French surrealism. The output does not accurately reflect the target definition.", "rationale_2": "The output is a hallucination. It incorrectly identifies \"Gigeresque\" as being related to French surrealism, when it should be associated with H. R. Giger, a Swiss surrealist painter. The output does not accurately reflect the target definition.", "rationale_3": "The output is a hallucination because it incorrectly identifies 'Gigeresque' as being characteristic of French surrealism. The term 'Gigeresque' actually refers to the style of Swiss artist H.R. Giger, known for his nightmarish biomechanical imagery, as correctly identified in the target.", "rationale_4": "The output is a hallucination. The term 'Gigeresque' indeed refers to the style of H.R. Giger, a Swiss surrealist painter known for his biomechanical imagery, as correctly indicated in the target. However, the output incorrectly attributes the style to French surrealism, which is inaccurate."}, {"hyp": "The state or quality of being a princess.", "ref": "tgt", "src": "\u201c What are you doing ? \u201d Carly asked , looking around . \u201c You do n\u2019t want to be in here . You \u2019re way too much of a princess . \u201d / \u201c Remember how I grew up , Carly . I \u2019ve earned my <define> princessness </define> . \u201d", "tgt": "The quality of being a princess.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T18:23:48Z", "rationale_0": "The output is correct and is not a hallucination. It matches the target closely, providing an accurate definition of \"princessness\" as the state or quality of being a princess.", "rationale_1": "The output is not a hallucination. It accurately captures the definition of the term 'princessness', aligning it correctly with the target. The output definition essentially means the same as the target definition, using slightly different wording.", "rationale_2": "The output is not a hallucination. It correctly defines \"princessness\" as the state or quality of being a princess, which aligns with the target definition.", "rationale_3": "The output is not a hallucination. It correctly provides a definition for 'princessness' which aligns with the target definition. The small variation in wording does not change the meaning.", "rationale_4": "The output is not a hallucination. It accurately defines the term 'princessness' as the state or quality of being a princess, which closely aligns with the target definition. The output is correct and does not include any extraneous information."}, {"hyp": "(Australia, New Zealand, colloquial) A tree.", "ref": "tgt", "src": "He climbed over the sedge and eely oarweeds and sat on a stool of rock , resting his ashplant in a <define> grike </define> .", "tgt": "(chiefly, British) A deep cleft formed in limestone surfaces due to water erosion; providing a unique habitat for plants.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:24:20Z", "rationale_0": "The output is a hallucination. The target defines \"grike\" as a deep cleft formed in limestone surfaces due to water erosion, primarily in British English. However, the output inaccurately defines \"grike\" as a tree in Australian and New Zealand English, which is not correct.", "rationale_1": "The output is a hallucination. The target indicates that \"grike\" is a deep cleft formed in limestone surfaces due to water erosion, which is in line with the context given in the input sentence. However, the output incorrectly defines \"grike\" as a tree, which is not correct and does not match the context of the input.", "rationale_2": "The output is a hallucination. The target definition of \"grike\" as a deep cleft formed in limestone surfaces due to water erosion is not consistent with the output definition of it as a tree. Therefore, the output does not accurately define the term in question.", "rationale_3": "The output is a hallucination. The target definition of \"grike\" is a deep cleft formed in limestone due to water erosion, while the output provides an entirely different and incorrect definition, referring to it as a tree. This shows the output is not accurate or correct.", "rationale_4": "The output is a hallucination. The term 'grike' is defined in the target as a deep cleft formed in limestone surfaces due to water erosion, which is a definition based on geographical context. However, the output provides a completely different definition, stating that a 'grike' is a tree in Australia and New Zealand. This definition not only contradicts the target, but also adds extraneous information that cannot be inferred from the input."}, {"hyp": "(intransitive) To die.", "ref": "tgt", "src": "\" But why should I be in another room ? \" \" You <define> passed over </define> in the night . \" \" Passed over ? Do you mean I died ? \" \" Yes , lady , you died . \" There was a long silence .", "tgt": "(intransitive, euphemistic) To die and thus progress to the afterlife.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T18:24:48Z", "rationale_0": "The output is not a hallucination. It correctly captures the primary meaning of the term \"passed over\" in the context provided. However, it is slightly less precise than the target, as it doesn't include the euphemistic aspect or the reference to progressing to the afterlife.", "rationale_1": "The output is not a hallucination. It is correct and accurate, albeit simplified. The target definition includes the euphemistic aspect and the idea of progressing to the afterlife, which are implicit in the context, but the output's simpler definition of \"to die\" is still fundamentally correct.", "rationale_2": "The output is not a hallucination. Although it does not include the entire target definition, specifically the part about progressing to the afterlife, it correctly identifies that \"passed over\" is a euphemism for dying. However, it is slightly incomplete when compared to the target.", "rationale_3": "The output is not a hallucination. Although it doesn't include the more detailed phrase \"and thus progress to the afterlife\" found in the target, the basic definition of \"passed over\" as a euphemism for dying is still correctly identified.", "rationale_4": "The output is not a hallucination. It accurately captures the main point of the target definition, which is that \"passed over\" means \"to die.\" However, it does omit the euphemistic aspect and the part about progressing to the afterlife. Nevertheless, the output is still factually correct and not off point."}, {"hyp": "Alternative form of scatter site", "ref": "tgt", "src": "It is designed for single - family use in subdivisions or <define> scatter sites </define> and available as a standardized product   [ \u2026 ]", "tgt": "An area of state-sponsored housing used as a shelter for homeless people; such housing is scattered across different parts of a city rather than concentrated in one place.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Not Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:25:12Z", "rationale_0": "The output is a hallucination. It does not provide a proper definition of the term \"scatter sites\" as required, but instead it vaguely refers to it as an alternative form of itself. Furthermore, it does not match the target definition, which accurately describes \"scatter sites\" as areas of state-sponsored housing scattered across different parts of a city.", "rationale_1": "The output is a hallucination. It does not provide a correct definition for 'scatter sites'. The target definition suggests that scatter sites refer to different parts of a city where state-sponsored housing for homeless people is placed, but the output does not provide any such information.", "rationale_2": "The output is a hallucination. The output does not provide a definition for the term 'scatter sites' as requested in the input and does not match with the target definition. Moreover, it is vague and non-informative.", "rationale_3": "The output is a hallucination. It does not provide a clear or accurate definition of \"scatter sites\" as stated in the target. Instead, it simply refers to an alternative form of the term without any additional context or explanation.", "rationale_4": "The output is a hallucination as it does not provide a correct or clear definition for 'scatter sites'. The target definition indicates that 'scatter sites' refers to state-sponsored housing scattered across different parts of a city. The output, however, does not provide this information."}, {"hyp": "The state or condition of being obsolescent.", "ref": "tgt", "src": "One way is to legislate extended warranties on products , so washing machines and refrigerators last for 30 years instead of 10 . Another is to ban planned <define> obsolescence </define> , so manufacturers ca n\u2019t create products that are designed to fail .", "tgt": "(uncountable) The state of being obsolete\u2014no longer in use; gone into disuse; disused or neglected.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:26:01Z", "rationale_0": "The output is a hallucination. While obsolescence does refer to something being out of use or outdated, the output incorrectly defines it as the state of becoming obsolete (obsolescent), rather than being already obsolete. This discrepancy makes the output an incorrect definition.", "rationale_1": "The output is a hallucination. While the provided definition is technically correct, it is not fully accurate to the term in question. \"Obsolescence\" is specifically about items or concepts becoming out of date or no longer used, not just the state of being \"obsolescent\" which implies something is becoming obsolete but hasn't yet reached that state. The output thus provides a slightly different definition from the target.", "rationale_2": "The output is incorrect. The term \"obsolescence\" was defined as \"the state or condition of being obsolescent\" which is not in line with the target definition. The target definition explains obsolescence as the state of being obsolete, no longer in use or neglected. Therefore, the output is a hallucination.", "rationale_3": "The output is incorrect. The term 'obsolescence' was defined incorrectly by the model. The output definition describes 'obsolescent' which refers to the process of becoming obsolete, not the state of being obsolete. Therefore, this output can be considered a hallucination.", "rationale_4": "The output is incorrect. The term 'obsolescence' is not defined as the state or condition of being obsolescent. The correct definition is provided in the target, which is the state of being obsolete or no longer in use. Therefore, the output can be considered as a hallucination."}, {"hyp": "Alternative form of gartel (\u201cdance\u201d)", "ref": "tgt", "src": "The bride stands perfectly still at one end of the room and holds a long <define> gartel </define> while the male dancing before her holds the other end .", "tgt": "(Judaism) A belt or sash used in prayer.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:26:28Z", "rationale_0": "The output is a hallucination. The term 'gartel' in the given context refers to a belt or sash used in Jewish prayer, as indicated in the target. The output, however, incorrectly defines 'gartel' as an alternative form of dance, which is not accurate or relevant to the input.", "rationale_1": "The output is a hallucination. The output incorrectly defines \"gartel\" as an alternative form of dance, while the target accurately defines it as a belt or sash used in prayer in Judaism. Therefore, the output contains incorrect information that cannot be inferred from the input.", "rationale_2": "The output is a hallucination. The term \"gartel\" is inaccurately defined as an alternative form of dance, which is incorrect. The target accurately defines it as a belt or sash used in prayer in Judaism.", "rationale_3": "The output is a hallucination. The target correctly identifies a \"gartel\" as a belt or sash used in prayer in Judaism, whereas the output incorrectly defines it as an alternative form of a dance, which is not accurate or relevant to the context provided in the input.", "rationale_4": "The output is a hallucination. The target defines 'gartel' as a belt or sash used in prayer in Judaism, which aligns with the context provided in the input. However, the output incorrectly defines 'gartel' as an alternative form of dance, which is not accurate or relevant to the input or target."}, {"hyp": "Capable of being endured.", "ref": "tgt", "src": "Misery colored by the greens and blues in my mother 's voice took all of the grief out of the words and left me with a conviction that pain was not only <define> endurable </define> , it was sweet .", "tgt": "Able to be endured; tolerable; bearable.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T18:26:52Z", "rationale_0": "The output is correct and accurate. It correctly defines \"endurable\" as being capable of being endured, which aligns with the target definition of being able to be endured, tolerable, or bearable. There is no hallucination as the output does not contain any incorrect or extraneous information.", "rationale_1": "The output is not a hallucination. It correctly defines the term \"endurable\" as being capable of being endured, which aligns with the target definition of being able to be endured, tolerable, or bearable.", "rationale_2": "The output is not a hallucination. It accurately defines the term 'endurable' as being capable of being endured, which aligns with the target definition of being able to be endured, tolerable, or bearable.", "rationale_3": "The output is correct and accurate. It correctly defines 'endurable' as something that is capable of being endured, which aligns with the target definition. There is no hallucination in the output.", "rationale_4": "The output is not a hallucination. It accurately defines the term \"endurable\" as being capable of being endured, which aligns with the target definition of being able to be endured, tolerable, or bearable."}, {"hyp": "(geology) Of or pertaining to the Alps.", "ref": "tgt", "src": "In 1884 O. Heer published a comprehensive account of the <define> nival </define> flora of   Switzerland , in which he listed 338 species of flowering plants found above 2600   m. ; of these , 6 were found above 3900 m.", "tgt": "(botany) Found or thriving in snowy conditions.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:27:19Z", "rationale_0": "The output is a hallucination. The term \"nival\" in botany refers to plants found or thriving in snowy conditions, not specifically related to the Alps or geology as the output suggests. The output is incorrect and does not match the target definition.", "rationale_1": "The output is a hallucination. The target definition indicates that 'nival' pertains to plants found or thriving in snowy conditions. The output, however, defines 'nival' in geological terms and associates it with the Alps, which is incorrect and not inferred from the input.", "rationale_2": "The output is a hallucination. The term \"nival\" is defined within the context of botany, referring to plants that thrive in snowy conditions. The output incorrectly defines \"nival\" in a geological context and associates it with the Alps specifically, which is not part of the given input or target definition.", "rationale_3": "The output is a hallucination. The term 'nival' in the context of this sentence should pertain to botany and its relation to snowy conditions, as per the target. However, the output incorrectly defines 'nival' in terms of geology and the Alps, which is not supported by the given input.", "rationale_4": "The output is a hallucination. The target suggests that \"nival\" refers to something found or thriving in snowy conditions, particularly in the field of botany. This can be inferred from the context provided in the input. However, the output incorrectly defines \"nival\" as pertaining to the Alps, which is a geographical rather than botanical interpretation. Thus, the output does not match the target."}, {"hyp": "Capable of being parachuted.", "ref": "tgt", "src": "<define> parachutable </define> supplies", "tgt": "Capable of being deployed by parachute.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T18:27:41Z", "rationale_0": "The output is not a hallucination. Although the phrasing is different than the target, the output still correctly defines \"parachutable\" as being capable of being parachuted.", "rationale_1": "The output is not a hallucination. While the wording is slightly different from the target, the output accurately defines 'parachutable' as something that is capable of being parachuted, which is synonymous with the target definition of being capable of being deployed by parachute.", "rationale_2": "The output is not a hallucination. It accurately defines the term 'parachutable' but uses slightly different wording than the target. Both the target and output definitions mean the same thing.", "rationale_3": "The output is not a hallucination. It correctly defines the term 'parachutable' as something capable of being parachuted. The output and target are semantically similar and convey the same idea, despite using slightly different wording.", "rationale_4": "The output is not a hallucination. Although the wording is slightly different from the target, the output essentially conveys the same meaning - that the subject can be deployed via a parachute."}, {"hyp": "In a muffled manner.", "ref": "tgt", "src": "A voice came <define> muffledly </define> from inside the closet .", "tgt": "In a muffled manner; indistinctly.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T18:28:06Z", "rationale_0": "The output is not a hallucination. While it doesn't contain the full details of the target (\"indistinctly\"), it is still correct and accurately defines the term \"muffledly\" as \"in a muffled manner\".", "rationale_1": "The output is not a hallucination. It accurately captures the essence of the target, which is defining \"muffledly\" as occurring in a muffled manner. While it does not include the term \"indistinctly\" that is present in the target, this omission does not make the output incorrect or off point.", "rationale_2": "The output is not a hallucination. It accurately defines the term \"muffledly\" as \"in a muffled manner\". However, it is missing the \"indistinctly\" part of the target definition. Despite this, the provided definition is still correct and accurate.", "rationale_3": "The output is not a hallucination. It correctly defines \"muffledly\" as \"in a muffled manner.\" However, it doesn't include the \"indistinctly\" part of the target, but this does not make it a hallucination, just slightly incomplete.", "rationale_4": "The output is correct and not a hallucination. While it does not include the \"indistinctly\" part from the target, the core definition of \"muffledly\" as \"in a muffled manner\" is accurately provided in the output."}, {"hyp": "(transitive) To cook (something) in a frying pan.", "ref": "tgt", "src": "Innawong et al . ( 2006 ) conducted experiments to study the effect of using nitrogen gas on the quality of <define> fried </define> chicken nuggets during pressure frying in terms of moisture retention and reduction in fat   [ \u2026 ]", "tgt": "Cooked in a deep fryer or pressure fryer or the like after being coated (breaded) in batter; compare deep-fried.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:28:38Z", "rationale_0": "The output is a hallucination. While the output correctly defines \"fried\" as a method of cooking, it does not match the target definition which specifically refers to cooking in a deep fryer or pressure fryer, particularly in relation to chicken nuggets. The output is too general and misses the specifics provided in the target.", "rationale_1": "The output is a hallucination. The target definition specifies that 'fried' refers to a food item (in this case, chicken nuggets) being cooked in a deep fryer or pressure fryer, especially after being coated in batter. However, the output incorrectly defines 'fried' as the act of cooking something in a frying pan, which is not specific or accurate in the context of the given study.", "rationale_2": "The output is a hallucination. While the output provides a general definition of frying, it does not accurately reflect the specific context of the input, which refers to the frying of chicken nuggets in a deep or pressure fryer. The output also omits the crucial aspect of the food being coated or breaded before frying.", "rationale_3": "The output is a hallucination. The given output defines the general term 'fry' but not specifically 'fried' in the context of chicken nuggets which is expected based on the input. The target definition correctly identifies the preparation method of chicken nuggets, which is not reflected in the output.", "rationale_4": "The output is a hallucination. While the output does provide a general definition for the term 'fried', it does not match the target definition which specifically refers to the context of frying in a deep fryer or pressure fryer, particularly in the context of chicken nuggets. The output also excludes any mention of the coating process that is part of the target definition."}, {"hyp": "A sleeveless garment worn at night.", "ref": "tgt", "src": "Winston wore a <define> nightcap </define> to stave off the cold .", "tgt": "A warm cloth cap worn while sleeping, often with pajamas, being common attire in northern Europe before effective home heating became widespread. [From 14th c.]", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Not Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:28:57Z", "rationale_0": "The output is a hallucination because it is incorrect. A nightcap is not a sleeveless garment but rather a warm cloth cap worn while sleeping. The output does not accurately define the term 'nightcap'.", "rationale_1": "The output is a hallucination. The definition provided is incorrect. A nightcap is not a 'sleeveless garment' but a 'warm cloth cap worn while sleeping'. The output seems to be confusing a nightcap with a nightgown or similar type of sleepwear.", "rationale_2": "The output is a hallucination. The definition provided is incorrect; a nightcap is not a \"sleeveless garment\" but a type of headwear worn during sleep. The output does not match the target definition.", "rationale_3": "The output is a hallucination. The target defines a nightcap as a warm cloth cap worn while sleeping, while the output incorrectly defines it as a sleeveless garment worn at night.", "rationale_4": "The output is a hallucination. The definition provided for 'nightcap' in the output is incorrect. A nightcap is not a sleeveless garment but a warm cloth cap worn during sleep, often to stave off the cold. The output does not match the target."}, {"hyp": "(obsolete) Old; old-fashioned.", "ref": "tgt", "src": "And thou , our Mother , twice two centuries <define> young </define> ,", "tgt": "(Not) advanced in age; (far towards or) at a specified stage of existence or age.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:29:24Z", "rationale_0": "The output is a hallucination. The target definition states that the term \"young\" refers to not being advanced in age or at a specified stage of existence or age. However, the output gives an incorrect definition, stating that \"young\" is an obsolete term for old or old-fashioned. This is not accurate as \"young\" is still widely used to denote the opposite of old.", "rationale_1": "The output is a hallucination. The target suggests that \"young\" in this context means not advanced in age or at a specified stage of existence or age. However, the output incorrectly defines \"young\" as old or old-fashioned, which is the opposite of the intended meaning.", "rationale_2": "The output is a hallucination as it is incorrect in relation to the target. The term \"young\" is defined as not being advanced in age or at a specified stage of existence or age. However, the output incorrectly defines \"young\" as old or old-fashioned.", "rationale_3": "The output is a hallucination. The term to be defined is 'young', which generally denotes being not advanced in age or at an early stage of existence. However, the output defines 'young' as 'old' or 'old-fashioned', which is clearly incorrect and opposite to the target. Therefore, the output is not accurate.", "rationale_4": "The output is a hallucination. The term to be defined is \"young\", which means not advanced in age or at a specified stage of existence. However, the output defines it as \"old; old-fashioned\" which is the opposite of the target definition. Hence, the output is incorrect and off point."}, {"hyp": "A county of Hotan, Sichuan, China.", "ref": "tgt", "src": "The \u201c living fossil \u201d , metasequoia , for example , was once distributed over large areas of Europe , Asia and the Americas from the Cretaceous to the Tertiary periods . Destroyed by glaciers , its natural distribution in China is today limited to Sichuan \u2019s <define> Shizhu </define> county , Hubei \u2019s Lichuan county and Hunan \u2019s Longshan county .", "tgt": "A county of Chongqing, China.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:29:42Z", "rationale_0": "The output is a hallucination. The term 'Shizhu' is defined as being in Chongqing, China according to the target, but the output incorrectly places it in Hotan, Sichuan, China.", "rationale_1": "The output is a hallucination. The input specifies that Shizhu is a county in Sichuan, but the output incorrectly places it in Hotan, Sichuan, China. The target correctly identifies it as a county in Chongqing, China.", "rationale_2": "The output is a hallucination. The correct location of Shizhu county is in Chongqing, China, as per the target. The output inaccurately places Shizhu county in Hotan, Sichuan, China.", "rationale_3": "The output is a hallucination. The correct information should be that Shizhu is a county of Chongqing, China as stated in the target. The output incorrectly identifies Shizhu as a county of Hotan, Sichuan, China.", "rationale_4": "The output is a hallucination. The correct output should have been that Shizhu is a county of Chongqing, China, not Hotan, Sichuan, China. The output doesn't match the target, making it incorrect."}, {"hyp": "A small flag.", "ref": "tgt", "src": "Given the present crisis and empty coffers , working meetings geared toward results are more appropriate for politicians than a program of touristy forays , throngs waving <define> flaglets </define> and bulletproof glass , the whole culminating in a neo - feudal state banquet .", "tgt": "A small flag.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T18:30:02Z", "rationale_0": "The output is correct and accurate. It aligns perfectly with the target, meaning it is not a hallucination. The term \"flaglets\" is correctly defined as \"a small flag\".", "rationale_1": "The output is not a hallucination. It correctly and accurately provides the definition of \"flaglets\" as given in the target, which is \"a small flag\".", "rationale_2": "The output is correct and accurate. The term \"flaglets\" is correctly defined as a small flag in the output, which matches with the target. Therefore, it is not a hallucination.", "rationale_3": "The output is not a hallucination. It correctly matches the target, providing an accurate and succinct definition for the term \"flaglets\".", "rationale_4": "The output is correct and accurate. It matches the target exactly, providing the correct definition for \"flaglets\" as small flags. It is not a hallucination as it does not include any incorrect or extraneous information."}, {"hyp": "(zoology) Of or pertaining to a minotaur.", "ref": "tgt", "src": "Elytra <define> miniatous </define> , with a large somewhat triangular black spot on their disk ,   [ \u2026 ]", "tgt": "(formal) Orange-red, the colour of red lead.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:30:27Z", "rationale_0": "The output is a hallucination. The target suggests that 'miniatous' refers to an orange-red color, presumably related to the 'Elytra' (beetle wings) mentioned in the input. However, the output incorrectly defines 'miniatous' as pertaining to a minotaur, which is not supported by the given context.", "rationale_1": "The output is a hallucination. The target definition shows that \"miniatous\" is related to a color, specifically orange-red, while the output incorrectly defines it as something related to a minotaur. The output is not correct or accurate in the context of the given input.", "rationale_2": "The output is a hallucination. The target indicates that 'miniatous' is related to a specific color, not pertaining to a minotaur as suggested in the output. Thus, the output is incorrect and not related to the input.", "rationale_3": "The output is a hallucination. The target definition refers to a specific color, while the output definition incorrectly refers to a mythological creature, the minotaur. The output does not match the input or target in any way.", "rationale_4": "The output is a hallucination. The target suggests that 'miniatous' refers to a specific color, not something pertaining to a minotaur as the output suggests. Therefore, the output is incorrect."}, {"hyp": "(chemistry) The degree to which a substance is hydrated.", "ref": "tgt", "src": "DuBois and coworkers carried out extensive studies of the thermodynamic <define> hydricity </define> of metal hydrides ( 3.2 ) ; in many cases the metal product resulting following hydride transfer will bind a CH3CN ligand ( not shown in 3.2 ) , so comparisons of hydricity will be solvent - dependent .", "tgt": "(chemistry) The tendency in a transition metal hydride for an H- ion to transfer to a substrate", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:31:00Z", "rationale_0": "The output is a hallucination. The definition provided in the output is incorrect. The term \"hydricity\" in the context of chemistry and specifically in relation to metal hydrides, refers to the tendency for a hydrogen ion to transfer to a substrate, not the degree to which a substance is hydrated.", "rationale_1": "The output is a hallucination. The output defines hydricity as the degree to which a substance is hydrated, which is incorrect. The target clearly states that hydricity refers to the tendency in a transition metal hydride for an H- ion to transfer to a substrate, aligning with the context provided in the input.", "rationale_2": "The output is a hallucination. The target definition indicates that hydricity refers to the tendency in a transition metal hydride for an H- ion to transfer to a substrate, whereas the output definition mistakenly defines it as the degree to which a substance is hydrated, which is not the correct definition in the context of the input.", "rationale_3": "The output is a hallucination. The generated definition does not match the target. The target describes hydricity as the tendency for an H- ion to transfer to a substrate in a transition metal hydride, while the output incorrectly defines it as the degree to which a substance is hydrated.", "rationale_4": "The output is a hallucination. The output incorrectly defines hydricity as \"the degree to which a substance is hydrated\", which is not accurate. The target definition indicates that it is about the tendency of a transition metal hydride for an H- ion to transfer to a substrate. Thus, the output is not correct according to the context provided by the input or the target."}, {"hyp": "(video games) The state or condition of being bisexual in a video game.", "ref": "tgt", "src": "It can be argued that explicit representations of bisexuality , pansexuality , and other multiple - gender - attracted people are erased from games that use ' <define> playersexuality </define> ' as a mechanic .", "tgt": "(video games) The state of an NPC being attracted to the player character, especially without regard to gender, race, etc.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:31:26Z", "rationale_0": "The output is a hallucination. The given output incorrectly defines 'playersexuality' as being bisexual in a video game. The target indicates that 'playersexuality' refers to the state of a non-player character (NPC) being attracted to the player character, regardless of factors like gender or race. The output does not match the target and is therefore considered a hallucination.", "rationale_1": "The output is a hallucination. It inaccurately defines 'playersexuality' as being bisexual in a video game, which deviates from the target definition. The target definition explains that 'playersexuality' refers to the game mechanic where non-player characters (NPCs) are attracted to the player's character regardless of gender, race, etc. The output does not capture this nuance.", "rationale_2": "The output is a hallucination. The target specifies that 'playersexuality' refers to the state of an NPC being attracted to the player character, regardless of gender, race etc. The output, however, incorrectly defines 'playersexuality' as the state of being bisexual in a video game.", "rationale_3": "The output is a hallucination. The correct definition of 'playersexuality' in the context of video games is the state of a non-player character (NPC) being attracted to the player character, regardless of gender, race, etc. The output incorrectly defines it as the state or condition of being bisexual in a video game.", "rationale_4": "The output is a hallucination. The term 'playersexuality' is defined as an NPC being attracted to the player character, regardless of gender, race, etc. The output incorrectly defines it as the state or condition of being bisexual in a video game, which is not accurate."}, {"hyp": "That\u2019s not happening at the moment.", "ref": "either", "src": "That\u2019s not happening.", "tgt": "That isn\u2019t gonna happen.", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:31:47Z", "rationale_0": "The output can be considered as a hallucination, as it includes the extra information \"at the moment\" which isn't present or implied in the original input or the target. The input and target convey a more definitive tone, while the output implies a temporary state.", "rationale_1": "The output is a hallucination. Although the output maintains the general idea of the input, it introduces new information (\"at the moment\") that isn't present or implied in the input or target, making it less accurate.", "rationale_2": "The output is a hallucination. While it maintains the general meaning of the input, it adds extra information (\"at the moment\") that is not present or implied in the original input or target.", "rationale_3": "The output is a hallucination. The added phrase \"at the moment\" implies a temporal context not present in the input or target. The input statement is definitive, while the output suggests the situation might change in the future.", "rationale_4": "The output is a hallucination. The paraphrase added extraneous information (\"at the moment\") that cannot be inferred from the input. The input gives no indication of time, making the output inaccurate."}, {"hyp": "I have a permit to carry it.", "ref": "either", "src": "I have a permit.", "tgt": "Uh, I\u2019m validated.", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:32:14Z", "rationale_0": "The output is a hallucination. The output adds extra information that is not present or suggested in the input. The phrase \"to carry it\" is an addition that is not inferred from the original statement \"I have a permit.\" The target paraphrase keeps the statement general, while the output narrows it down to a specific type of permit.", "rationale_1": "The output is a hallucination. The model has added an extra detail (\"to carry it\") that was not specified or inferred from the original input. The target paraphrase does not mention anything about carrying anything, hence the output is incorrect and contains extraneous information.", "rationale_2": "The output is a hallucination. The target paraphrase suggests a general validation or permission, which is true to the input. However, the output adds information (\"to carry it\") that is not present or implied in the original input, hence it is considered a hallucination.", "rationale_3": "The output is a hallucination. The output adds extra information (\"to carry it\") that is not present or implied in the original input or the target. It is also not a paraphrase of the input.", "rationale_4": "The output is a hallucination. Even though the output correctly acknowledges that the speaker has a permit, it adds extraneous information (\"to carry it\") that cannot be inferred from the input. The input does not specify what the permit is for, so it's incorrect for the model to assume it's for carrying something."}, {"hyp": "The process is easy.", "ref": "either", "src": "Easy, easy.", "tgt": "Watch it now.", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Hallucination", "Hallucination", "Not Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:32:41Z", "rationale_0": "The output is a hallucination. Although it correctly interprets the input's tone of simplicity or ease, it fails to convey the cautionary or warning sentiment found in the target. The output does not accurately paraphrase the target.", "rationale_1": "The output is a hallucination. The target phrase \"Watch it now\" suggests a note of caution or attention, which is not reflected in the output \"The process is easy\". The output seems to interpret the input \"Easy, easy\" as referring to a simple process, which is not necessarily the intended meaning.", "rationale_2": "The output is a hallucination. While it accurately captures the sense of simplicity suggested by the input, it doesn't align with the target's sense of caution or warning. It has added the context of a \"process\" which is not indicated in the input or the target.", "rationale_3": "The output is a hallucination. Although both the input and output refer to something being easy, the target phrase 'Watch it now' suggests caution or attention, which isn't reflected in the output. This indicates that the output phrase isn't a correct or accurate paraphrase of the input.", "rationale_4": "The output is a hallucination. While it correctly interprets the input term \"easy\", it does not capture the cautionary sense of the target. Instead, it suggests a process, which is not implied in either the input or the target."}, {"hyp": "A number between five and eight.", "ref": "either", "src": "A five, six, seven, eight.", "tgt": "And 5, 6, 7, 8.", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Hallucination", "Hallucination", "Not Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:33:07Z", "rationale_0": "The output is a hallucination. The input is referring to a sequence of numbers (5, 6, 7, 8), while the output incorrectly implies that it's referring to a single number in the range between five and eight.", "rationale_1": "The output is a hallucination. The input is a sequence of numbers, suggesting a count or list, while the output refers to a range of numbers. The output doesn't accurately reflect the content and meaning of the input.", "rationale_2": "The output is a hallucination. The output is incorrect as it changes the meaning of the original input. The input lists discrete numbers (five, six, seven, and eight), but the output implies a range between five and eight, which is not the same thing.", "rationale_3": "The output is a hallucination. The input seems to be a sequence of numbers in ascending order, and the target confirms this interpretation. However, the output incorrectly interprets the input as a range between two numbers (five and eight), which is not what the input or target suggest.", "rationale_4": "The output is a hallucination. The input is a list of consecutive numbers and the target accurately paraphrases this list. However, the output provides a range of numbers, which is not the same as the individual numbers listed in the input. It is adding additional interpretation that is not present in the input."}, {"hyp": "That is a safer way to travel.", "ref": "either", "src": "A lot safer that way.", "tgt": "Because it\u2019s safer.", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Not Hallucination", "Hallucination", "Not Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 0.6000000000000001, "timestamp": "2023-11-05T18:33:31Z", "rationale_0": "The output is not a hallucination. Although it introduces the context of 'travel' which is not explicitly mentioned in the input, the core message of safety is consistent with the input and the target. However, the output is not entirely accurate as it deviates from the target's message.", "rationale_1": "The output is a hallucination. The input phrase \"A lot safer that way\" doesn't specify any context about travelling. Hence, the output \"That is a safer way to travel\" is introducing new information, thus it is a hallucination.", "rationale_2": "The output is not a hallucination. However, it is not entirely accurate when compared to the target. The input suggests a certain method is safer, and the output does convey this, albeit with the added context of travel which was not mentioned in the input. While the general idea is communicated correctly, the specific context of 'travel' makes it slightly off from the target.", "rationale_3": "The output is a hallucination. The original input does not provide information about \"travel\", therefore the output contains extraneous information that cannot be reasonably inferred from the input.", "rationale_4": "The output is a hallucination. The input statement does not specify anything about travel, yet the output introduces this new, extraneous detail. Thus, the output is not accurate to the original input."}, {"hyp": "You\u2019re not a good scam artist.", "ref": "either", "src": "You\u2019re a scam artist.", "tgt": "You are an imposter.", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:34:00Z", "rationale_0": "The output is a hallucination. While the input suggests that the person is a scam artist, the output adds extraneous information, implying that the person is not a \"good\" scam artist. The target phrase does not include any judgement on the quality of the person's scam artistry, hence the output is not correct or accurate.", "rationale_1": "The output is a hallucination. It introduces the notion that the person is not \"good\" at being a scam artist, which is not present or inferred from the input. The input only labels the person as a scam artist, without any qualification of their proficiency.", "rationale_2": "The output is a hallucination. The input statement clearly labels the person as a \"scam artist\", while the output adds extraneous information by including \"not a good\", which is not indicated or inferred from the original input. The target paraphrase correctly maintains the negative connotation without adding any extra information.", "rationale_3": "The output is a hallucination. While it maintains the negative connotation of the input, it adds extraneous information (\"not a good\") that changes the meaning of the sentence. The input accuses the person of being a scam artist, while the output implies that the person is a scam artist but not a skilled one. This information was not present or implied in the input or the target.", "rationale_4": "The output is a hallucination. The input does not make any assertion about the quality of the scam artist, it simply states that the person is a scam artist. The output adds information that was not present or inferred from the input."}, {"hyp": "When did you see him?", "ref": "either", "src": "When\u2019d you last see him?", "tgt": "When was the last time you saw him?", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T18:34:25Z", "rationale_0": "The output is not a hallucination. However, it is not entirely accurate because it misses the \"last time\" aspect from the input and the target. The original sentence is asking specifically about the most recent encounter, while the output could be interpreted as asking about any past encounter.", "rationale_1": "The output is not a hallucination. It is a correct and accurate paraphrase of the input. However, it lacks the specificity of the original sentence and the target in terms of indicating a \"last time\", but it does not add any extraneous information or deviate from the main point.", "rationale_2": "The output is not a hallucination. It is a correct and accurate paraphrase of the input, although it's not an exact match of the target. It omitted the \"last time\" part, but the meaning remains essentially the same.", "rationale_3": "The output is not a hallucination. It is correct and accurate, but it lacks the specificity of the \"last time\" mentioned in the input and target. However, it still fundamentally asks about a past instance of seeing someone, which aligns with the general intent of the input statement.", "rationale_4": "The output is not a hallucination, but it is not entirely accurate either. The input is asking about the most recent time someone saw 'him', but the output is asking about any time the person saw 'him'. Therefore, while the output is similar, it does not precisely capture the same meaning as the input or the target."}, {"hyp": "Let me leave.", "ref": "either", "src": "Let me out of here.", "tgt": "Someone let me out.", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T18:34:49Z", "rationale_0": "The output is not a hallucination. The output \"Let me leave\" accurately represents the same sentiment as the input \"Let me out of here\". Although it does not match the target exactly, it is still a valid paraphrase of the input.", "rationale_1": "The output is not a hallucination. It accurately paraphrases the input without introducing extraneous or incorrect information. However, it doesn't match the target exactly, as it changes the structure of the sentence somewhat.", "rationale_2": "The output is not a hallucination. It accurately paraphrases the input's meaning, even though it doesn't exactly match the target. Both the input and output express the desire to leave a certain place.", "rationale_3": "The output is not a hallucination. It accurately paraphrases the input without adding any extraneous or incorrect information. While it does not perfectly match the target, it still conveys the same underlying meaning as the input.", "rationale_4": "The output is not a hallucination. It accurately paraphrases the input \"Let me out of here\" to \"Let me leave.\" Both phrases express the same sentiment of wanting to exit a place or situation. Although it doesn't match the target exactly, it still correctly expresses the same idea. The target is just one possible paraphrase among many acceptable ones."}, {"hyp": "It is not impossible.", "ref": "either", "src": "Nothing is impossible.", "tgt": "There\u2019s nothing that can\u2019t be done.", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T18:35:17Z", "rationale_0": "The output is not a hallucination, but it's not entirely correct either. The target and input indicate that \"nothing\" is impossible, meaning everything is possible. However, the output says \"it\" is not impossible, which refers to a specific thing rather than \"everything\". So, while the output is related to the input, it is not a perfect paraphrase.", "rationale_1": "The output is not a hallucination. It effectively paraphrases the input statement. However, it does not perfectly match the target. It maintains the same meaning as the input, asserting that everything is possible, although in a more concise manner.", "rationale_2": "The output is not a hallucination. It accurately captures the meaning of the input, although it is not identical to the target. The phrases \"Nothing is impossible\" and \"It is not impossible\" are equivalent in meaning, both implying that everything is possible.", "rationale_3": "The output is not a hallucination. Although it does not perfectly match the target, it retains the same meaning as the input. Both the input and output convey the idea that nothing is beyond the realm of possibility.", "rationale_4": "The output is not a hallucination. It accurately paraphrases the input, \"Nothing is impossible,\" by saying, \"It is not impossible.\" However, it doesn't perfectly match the target, \"There\u2019s nothing that can\u2019t be done.\" Nonetheless, both the target and output convey the same general idea as the input."}, {"hyp": "Tom decided to leave the company.", "ref": "either", "src": "Tom d\u00e9cida de quitter la soci\u00e9t\u00e9.", "tgt": "Tom has decided to leave the company.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T18:35:44Z", "rationale_0": "The output is not a hallucination. It correctly conveys the meaning of the input, even though it is in the simple past tense (\"decided\") instead of the present perfect tense (\"has decided\") as in the target. The difference in tense does not significantly alter the meaning of the sentence.", "rationale_1": "The output is not a hallucination. It correctly translates the input from French to English. The only difference with the target is the use of the present perfect tense (\"has decided\") instead of the simple past tense (\"decided\"), but this is a minor variation and doesn't change the overall meaning or correctness of the translation.", "rationale_2": "The output is not a hallucination. It accurately translates the input from French to English. Although the tense of the verb differs slightly from the target (has decided vs decided), the overall meaning remains the same.", "rationale_3": "The output is not a hallucination. It accurately translates the input from French to English, although the tense of the verb \"decided\" is in simple past instead of present perfect (\"has decided\") as in the target. However, this is a minor difference and does not change the overall meaning of the sentence.", "rationale_4": "The output is not a hallucination. It accurately translates the input from French to English. The only slight discrepancy is the tense used (\"has decided\" versus \"decided\") but the overall meaning remains consistent."}, {"hyp": "Do you love her?", "ref": "either", "src": "Est-ce que tu l'aimes ?", "tgt": "Do you love him?", "model": "", "task": "MT", "labels": ["Not Hallucination", "Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:36:04Z", "rationale_0": "The output is a hallucination. The input in French is asking about a male subject (\"l'aimes\" refers to \"him\"), but the output incorrectly translates this to \"her.\" Therefore, the output is not accurate.", "rationale_1": "The output is a hallucination. The French pronoun \"le\" in the input refers to \"him\". However, the model incorrectly translated it to \"her\" in English, which is not accurate according to the target.", "rationale_2": "The output is a hallucination. The target translation indicates that the object of affection is a male (\"him\"), but the model's output incorrectly refers to a female (\"her\").", "rationale_3": "The output is a hallucination. While it does correctly translate the general sentiment of the input sentence, it inaccurately translates the gender. The French pronoun \"le\" in \"l'aimes\" should be translated as \"him,\" not \"her.\"", "rationale_4": "The output is a hallucination. The English translation of the French input should refer to a male (\"him\") as indicated in the target, but the output incorrectly refers to a female (\"her\")."}, {"hyp": "I got the company.", "ref": "either", "src": "J'ai de la compagnie.", "tgt": "I've got company.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "predictions": ["Hallucination", "Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.4, "timestamp": "2023-11-05T18:36:33Z", "rationale_0": "The output is incorrect. While \"I got the company\" can be a valid English sentence, in this context it implies ownership or acquisition of a business, not the presence of other people as indicated by the input. Therefore, this can be considered as a hallucination.", "rationale_1": "The output is incorrect. The correct translation of \"J'ai de la compagnie\" is \"I have company\" or \"I've got company\". The output \"I got the company\" changes the meaning of the sentence, implying that the speaker acquired a business, rather than having guests or companions. Therefore, the output can be considered a hallucination.", "rationale_2": "The output is not a hallucination, but it is not entirely correct either. The phrase \"I got the company\" could be interpreted as the person having acquired a company, rather than having guests or company, as implied by the target translation. Therefore, while the output is not entirely off point, it is not as accurate as the target.", "rationale_3": "The output is incorrect but it's not a hallucination. The translated output \"I got the company\" is not completely accurate. The correct translation should be \"I've got company\". Nevertheless, the output is still somewhat related to the input and does not include any extraneous information that can't be inferred from the input.", "rationale_4": "The output is not a hallucination, but it is not entirely accurate. The translation is semantically a bit different from the target. The phrase \"I got the company\" could be misinterpreted as acquiring a business, rather than having guests or people around, which is what the input sentence implies. Therefore, the translation is not entirely correct."}, {"hyp": "He's got several friends.", "ref": "either", "src": "Ann a plusieurs amis.", "tgt": "Ann has many friends.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:36:51Z", "rationale_0": "The output is a hallucination. The input text is about \"Ann\" while the output incorrectly refers to a male subject \"He\". The correct translation should refer to \"Ann\" as in the target.", "rationale_1": "The output is a hallucination. The input sentence is about \"Ann\", a female, but the output incorrectly refers to a male \"he\". The correct translation should refer to \"Ann\".", "rationale_2": "The output is a hallucination. The input is talking about 'Ann' but the output incorrectly translates it as 'He'. Thus, the output is not accurate.", "rationale_3": "The output is a hallucination. While it correctly translates the meaning of the sentence, it incorrectly changes the subject from \"Ann\" to \"He\".", "rationale_4": "The output is a hallucination. The input statement is about 'Ann', a female, but the output incorrectly refers to a male with 'He's'. Thus, the output is not accurate."}, {"hyp": "The captain orders the ship on board.", "ref": "either", "src": "Le capitaine donne l'ordre d'embarquer sur le navire.", "tgt": "The skipper is giving the order to board the ship.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:37:22Z", "rationale_0": "The output is a hallucination. The translation is incorrect and does not accurately convey the meaning of the input. The phrase \"The captain orders the ship on board\" doesn't make sense in English, unlike the target sentence which accurately translates the input.", "rationale_1": "The output is a hallucination. Although it correctly translates some words (like 'captain' for 'capitaine' and 'ship' for 'navire'), the sentence structure and the meaning of the output is not accurate. The correct translation should be about the captain giving the order to board the ship, not the captain ordering the ship on board.", "rationale_2": "The output is a hallucination. While it is somewhat close to the target, the sentence structure makes it difficult to understand and it does not convey the same meaning as the input. The phrase \"the captain orders the ship on board\" is nonsensical and does not match the input's meaning of the captain giving an order to board the ship.", "rationale_3": "The output is a hallucination. The sentence in the output is not correctly translated from the input. The correct translation should be similar to the target, which is \"The skipper is giving the order to board the ship\". Instead, the output, \"The captain orders the ship on board\", doesn't make sense as it implies the captain is ordering the ship, not the people, to board.", "rationale_4": "The output is a hallucination. Although it includes most of the correct elements from the input, it rearranges them in a way that changes the meaning. The correct translation should indicate that the captain is giving the order to board the ship, not ordering the ship on board."}, {"hyp": "Sami called 911.", "ref": "either", "src": "Sami a appel\u00e9 le 911.", "tgt": "Sami made a call to 911.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T18:37:45Z", "rationale_0": "The output is correct and accurate. It conveys the same meaning as the target, though it uses slightly different wording. It is not a hallucination because it correctly translates the input without adding any extraneous information.", "rationale_1": "The output is correct and accurate. It correctly translates the input from French to English, and the meaning is consistent with the target. Therefore, the output is not a hallucination.", "rationale_2": "The output is not a hallucination. It accurately translates the input from French to English. Although the wording is slightly different from the target, the meaning remains the same.", "rationale_3": "The output is not a hallucination. Although it is not a word-for-word translation of the input, it conveys the same meaning as the target. The phrase \"made a call to 911\" is equivalent to \"called 911.\" Thus, the output is correct and accurate.", "rationale_4": "The output is correct and accurate. Even though the wording is slightly different from the target, the meaning is the same. The output correctly translates the French input to English without adding or omitting any information. Therefore, it is not a hallucination."}, {"hyp": "We love our school.", "ref": "either", "src": "Nous aimons notre \u00e9cole.", "tgt": "We like our school.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:38:08Z", "rationale_0": "The output is a hallucination. The French verb \"aimons\" translates to \"like\" not \"love\" in English, so the translation is not accurate.", "rationale_1": "The output is a hallucination. Although \"aimons\" can be translated as both \"like\" and \"love\" in English, the intended translation provided in the target is \"like\". Therefore, \"love\", while not entirely incorrect, is a stronger sentiment and may not accurately reflect the original intent.", "rationale_2": "The output is a hallucination. Although \"aimons\" can be translated as either \"like\" or \"love\" from French to English, in this context it is more accurate to translate it as \"like\", as per the target. Therefore, the output is not entirely correct.", "rationale_3": "The output is a hallucination. While \"aimons\" can be translated as both \"like\" and \"love\" from French to English, the target indicates that the more accurate translation in this context is \"like.\" Therefore, the use of \"love\" in the output is incorrect.", "rationale_4": "The output is a hallucination. The French verb \"aimons\" translates to \"like\" in English, not \"love\". Therefore, the output has inaccurately translated the sentiment of the input."}, {"hyp": "How'd you get \"pretty\"?", "ref": "either", "src": "Comment \u00e9pelles-tu \"pretty\" ?", "tgt": "How do you spell \"pretty\"?", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:38:28Z", "rationale_0": "The output is a hallucination. The correct translation from French to English should be \"How do you spell 'pretty'?\" The output \"How'd you get 'pretty'?\" does not correspond to the input and adds extraneous information that cannot be inferred from the input.", "rationale_1": "The output is a hallucination. The target is asking how to spell \"pretty\", but the output is asking how someone obtained \"pretty\", which is not the same meaning as the input.", "rationale_2": "The output is a hallucination. The correct translation from French to English should be \"How do you spell 'pretty'?\" not \"How'd you get 'pretty'?\" The output does not match the target and is not a correct translation of the input.", "rationale_3": "The output is a hallucination. The correct translation of the input from French to English is \"How do you spell 'pretty'?\" However, the output provided is \"How'd you get 'pretty'?\", which is not a correct translation and doesn't match the target. The output is therefore incorrect and off point.", "rationale_4": "The output is a hallucination. The target is asking for the spelling of the word \"pretty\", while the output is asking how the person came up with the word \"pretty\". The output is not correctly translating the input."}, {"hyp": "The old days will never come back.", "ref": "either", "src": "Les jours anciens ne reviendront jamais.", "tgt": "The old days have gone never to return.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T18:38:49Z", "rationale_0": "The output is not a hallucination. Although it is not an exact match of the target, the output and target both convey the same general idea: that the old days will not return. The specific wording is different, but the meaning is essentially the same.", "rationale_1": "The output is not a hallucination. It correctly translates the input phrase, albeit with a slightly different wording. Both the target and the output convey the same meaning from the original French sentence.", "rationale_2": "The output is not a hallucination. It is a correct and accurate translation of the input, although it is not a word-for-word match for the target. Both the target and output convey the same meaning that the old days will not return.", "rationale_3": "The output is not a hallucination. While the wording is slightly different from the target, the output still correctly and accurately translates the overall meaning of the original French sentence.", "rationale_4": "The output is not a hallucination. Although it is not a verbatim translation of the target, it conveys the same meaning as the input and the target. The phrase \"The old days will never come back\" is semantically equivalent to \"The old days have gone never to return\"."}, {"hyp": "I bought three different varieties of flowers.", "ref": "either", "src": "J\u2019ai achet\u00e9 trois diff\u00e9rentes sortes de fleurs.", "tgt": "I bought three different kinds of flowers.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T18:39:06Z", "rationale_0": "The output is not a hallucination. Although the word \"varieties\" is used instead of \"kinds\", both words have the same meaning in this context, thus the translation is accurate and correct.", "rationale_1": "The output is not a hallucination. Although the exact wording differs from the target, the meaning remains the same. Both \"kinds\" and \"varieties\" in this context refer to different types of flowers.", "rationale_2": "The output is not a hallucination. The output accurately translates the input from French to English. The use of \"varieties\" instead of \"kinds\" doesn't change the overall meaning of the sentence.", "rationale_3": "The output is not a hallucination. The translation is accurate and conveys the same meaning as the target, even though a different word (\"varieties\" instead of \"kinds\") is used. The term \"varieties\" is synonymous with \"kinds\" in this context, so the meaning is preserved.", "rationale_4": "The output is not a hallucination. The sentence is accurately translated from French to English. Although the word \"varieties\" is used instead of \"kinds\", they both convey the same meaning in this context."}, {"hyp": "It's my duty.", "ref": "either", "src": "C'est mon m\u00e9tier.", "tgt": "It's my job.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "predictions": ["Hallucination", "Hallucination", "Not Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 0.8, "timestamp": "2023-11-05T18:39:32Z", "rationale_0": "The output is a hallucination. Although \"duty\" and \"job\" can be used interchangeably in some contexts, in a direct translation from French to English, \"m\u00e9tier\" translates to \"job\" or \"profession\", not \"duty\". Therefore, the output does not accurately reflect the input.", "rationale_1": "The output is a hallucination. Even though \"duty\" and \"job\" can sometimes be used interchangeably, in this context, the correct translation of \"m\u00e9tier\" from French to English is \"job\". Therefore, the output is not completely accurate.", "rationale_2": "The output is not a hallucination, but it is not entirely accurate. The French word \"m\u00e9tier\" directly translates to \"job\" in English, not \"duty\". While \"job\" and \"duty\" can sometimes be used interchangeably, they do not have the exact same meaning. Thus, the translation is not entirely correct.", "rationale_3": "The output is a hallucination. While \"duty\" and \"job\" have similar connotations, they do not mean the same thing. The French word for job is \"m\u00e9tier,\" not duty. Therefore, the correct translation should be \"It's my job,\" not \"It's my duty.\"", "rationale_4": "The output is incorrect. Even though \"duty\" and \"job\" are sometimes used interchangeably, the correct and direct translation of \"m\u00e9tier\" from French to English is \"job\". Therefore, the output is a hallucination."}, {"hyp": "I have nothing to do with it.", "ref": "either", "src": "J'en ai rien \u00e0 secouer.", "tgt": "I don't give a shit about it.", "model": "", "task": "MT", "labels": ["Hallucination", "Not Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:41:43Z", "rationale_0": "The output is incorrect. The English translation in the output does not accurately capture the colloquial, dismissive sentiment expressed in the French input. The target provides a more accurate translation of the input, thus the output can be considered as a hallucination.", "rationale_1": "The output is a hallucination. While it is technically a correct translation of the French phrase, it does not convey the same tone or level of emphasis as the target translation. The idiomatic expression \"J'en ai rien \u00e0 secouer\" is more accurately translated as \"I don't give a shit about it\" in English, which carries a stronger, more dismissive tone than \"I have nothing to do with it.\" Therefore, the output is not an accurate translation of the input.", "rationale_2": "The output is a hallucination. Although the output is not entirely incorrect, it fails to convey the same level of intensity and disregard expressed in the target. The input phrase is a French idiomatic expression that aligns more closely with the target translation, indicating a strong indifference or lack of care about something. The output is too mild and doesn't fully capture the sentiment of the input.", "rationale_3": "The output is a hallucination. Although it is a valid translation of the input, it doesn't convey the same intensity or vulgar tone of the original French phrase as the target does. The target translation more accurately captures the dismissive and negative sentiment of the input.", "rationale_4": "The output is a hallucination. Although the output is a literal translation of the input, it fails to convey the colloquial and somewhat vulgar emphasis of the original French phrase, which is more accurately captured in the target translation."}, {"hyp": "I've been confiscated.", "ref": "either", "src": "On m'a confisqu\u00e9 mon permis.", "tgt": "I've had my driving license confiscated.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:42:05Z", "rationale_0": "The output is a hallucination. It is not accurate because it does not correctly translate the entire phrase from French to English. The output does not include the detail about the \"driving license\" being confiscated, as mentioned in the input.", "rationale_1": "The output is a hallucination. The output sentence \"I've been confiscated\" doesn't correctly translate the input and it lacks the important information about the driving license being confiscated.", "rationale_2": "The output is a hallucination. The output does not accurately translate the input. It misses the key information about what has been confiscated, which is the \"driving license\".", "rationale_3": "The output is a hallucination. The output translation is incorrect and does not accurately convey the meaning of the original French sentence. The original sentence mentions a driving license being confiscated, which is completely omitted in the output.", "rationale_4": "The output is a hallucination. The output does not accurately translate the input. Specifically, it omits critical information about what has been confiscated (\"my driving license\") and also uses incorrect grammar. The input implies that the speaker's driving license was confiscated, but the output suggests that the speaker themselves were confiscated."}, {"hyp": "Stop turning.", "ref": "either", "src": "Arr\u00eate de tourner.", "tgt": "Stop spinning.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T18:42:37Z", "rationale_0": "The output is not a hallucination. Although the output doesn't match the target exactly, \"stop turning\" is an accurate translation of the French input, since \"tourner\" can mean both \"spinning\" and \"turning\". Therefore, it is not incorrect, off point or introducing extraneous information.", "rationale_1": "The output is not a hallucination. Although the output doesn't match the target exactly, \"Stop turning\" is a correct and reasonable translation of the French input \"Arr\u00eate de tourner\". The words \"turning\" and \"spinning\" are close in meaning and can be interchangeable in certain contexts.", "rationale_2": "The output is not a hallucination. While it does not match the target exactly, \"stop turning\" can be considered a valid translation of \"arr\u00eate de tourner\" as both \"turning\" and \"spinning\" can be interchangeable in certain contexts in English. Therefore, the output is still correct and accurate.", "rationale_3": "The output is not a hallucination. While the translated output is not an exact match to the target, it is still a correct and accurate translation of the input. \"Tourner\" can be translated as both \"spinning\" and \"turning\" in English, hence the translation \"Stop turning\" is correct.", "rationale_4": "The output is not a hallucination. Although the output does not match the target exactly, \"stop turning\" is a valid translation for \"arr\u00eate de tourner\". The terms \"turning\" and \"spinning\" can often be used interchangeably depending on the context. Therefore, the output is correct and accurate."}, {"hyp": "What kind of bread are you eating in general?", "ref": "either", "src": "Quel genre de pain est-ce que tu manges en g\u00e9n\u00e9ral ?", "tgt": "What kind of bread do you usually eat?", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T18:42:56Z", "rationale_0": "The output is not a hallucination. Although the phrasing is slightly different than the target, the output still accurately translates the input and conveys the same meaning.", "rationale_1": "The output is not a hallucination. The output is a correct and accurate translation of the input, although the phrase \"in general\" is slightly less common in English than \"usually\".", "rationale_2": "The output is not a hallucination. It is a correct and accurate translation of the input, although it's slightly less natural sounding than the target. The meaning of the input is fully preserved in the output.", "rationale_3": "The output is not a hallucination. It is a correct and accurate translation of the input, although the phrasing is slightly different from the target. Both the output and target convey the same meaning.", "rationale_4": "The output is not a hallucination. It accurately translates the input, though it uses a slightly different phrase (\"are you eating in general\" instead of \"do you usually eat\"). The meaning remains the same."}, {"hyp": "The eagles are friends.", "ref": "either", "src": "Les araign\u00e9es sont mignonnes.", "tgt": "Spiders are cute.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:43:16Z", "rationale_0": "The output is a hallucination. The translated output does not match the target at all. The input is about spiders being cute, but the output talks about eagles being friends, which is completely unrelated and off point.", "rationale_1": "The output is a hallucination. It is completely unrelated to the input as it changes the subject from \"spiders\" to \"eagles\" and the attribute from being \"cute\" to being \"friends\". This information cannot be inferred from the given input.", "rationale_2": "The output is a hallucination. The input is about spiders being cute, but the output talks about eagles being friends, which is unrelated and not inferred from the input.", "rationale_3": "The output is a hallucination. The input sentence is about spiders being cute, but the output talks about eagles being friends, which is not related to the input at all. The translation is completely incorrect.", "rationale_4": "The output is a hallucination. This is because the input is about spiders being cute, but the output talks about eagles being friends, which is completely unrelated to the original input."}, {"hyp": "Farhat Mehenni's separatist group concluded a compromise with the radical Islamist group Rachad for the destabilization of Algeria. This led Algeria to officially consider the two groups as terrorist organizations.", "ref": "either", "src": "Le groupe s\u00e9paratiste de Ferhat Mehenni a conclu un compromis avec le groupe islamiste radical Rachad pour la d\u00e9stabilisation de l'Alg\u00e9rie. C'est ce qui a conduit l'Alg\u00e9rie \u00e0 officiellement consid\u00e9rer les deux groupes comme des organisations terroristes.", "tgt": "Ferhat Mehenni's separatist group cut a deal with the radical Islamist group Rachad to destabilize Algeria. That's what led Algeria to officially consider both groups as terrorist organizations.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T18:43:44Z", "rationale_0": "The output is correct and accurate. It accurately translates the input from French to English. The minor difference in the spelling of the name \"Ferhat\" as \"Farhat\" does not qualify as a hallucination, as it might be due to different transliteration standards. The rest of the output correctly captures the key information from the input, including the compromise between the two groups and Algeria's response.", "rationale_1": "The output is not a hallucination. It accurately translates the input from French to English, maintaining the same meaning and content. The only slight difference is the use of \"concluded a compromise\" instead of \"cut a deal\", which are synonymous in this context. The name Ferhat Mehenni is slightly misspelled in the output, but this appears to be a minor typographical error rather than a hallucination.", "rationale_2": "The output is not a hallucination. It accurately and correctly translates the input, even if it differs slightly in wording (e.g., \"concluded a compromise\" instead of \"cut a deal\"). The key information, such as the groups involved and the response from Algeria, is correctly translated and included in the output.", "rationale_3": "The output is not a hallucination. It accurately translates the input provided, with only minor differences in word choice such as \"concluded a compromise\" instead of \"cut a deal\". However, the overall meaning and context of the sentence remain the same.", "rationale_4": "The output is not a hallucination. The output accurately and correctly translates the input from French to English, maintaining the key points and context of the original statement. The only difference is the use of \"concluded a compromise\" instead of \"cut a deal\", both of which convey the same meaning. There's a minor mistake in the spelling of the name \"Ferhat\", but it doesn't significantly alter the meaning or context of the statement."}, {"hyp": "You certainly don't have your mother's good nature.", "ref": "either", "src": "Tu n'as certainement pas la bonne nature de ta m\u00e8re.", "tgt": "You definitely don't have the good nature of your mother.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T18:44:02Z", "rationale_0": "The output is not a hallucination. Although the output is not a word-for-word translation of the input, it still accurately conveys the same meaning as the target.", "rationale_1": "The output is not a hallucination. It is accurate and correct, and it captures the meaning of the input appropriately albeit with slightly different phrasing.", "rationale_2": "The output is not a hallucination. It accurately translates the input to English, conveying the same meaning as the target. The slight variation in word order is normal in translation and does not change the meaning.", "rationale_3": "The output is not a hallucination. It accurately translates the input from French to English, although it phrases the translation slightly differently than the target. The meanings of the target and output are the same.", "rationale_4": "The output is not a hallucination. The output accurately translates the input from French to English, capturing the meaning and sentiment of the original phrase without introducing any extraneous or incorrect information."}, {"hyp": "Tom didn't hurry.", "ref": "either", "src": "Tom n'a pas hurl\u00e9.", "tgt": "Tom didn't scream.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:44:25Z", "rationale_0": "The output is a hallucination. The correct translation of \"hurl\u00e9\" from French to English is \"scream\". The model incorrectly translated it as \"hurry\". Therefore, the output does not match the target.", "rationale_1": "The output is a hallucination. The target translation from French indicates that the correct translation of \"hurl\u00e9\" is \"scream\". However, the model has incorrectly translated it as \"hurry\". Therefore, the output is not correct or accurate.", "rationale_2": "The output is a hallucination. The target translation indicates that the correct translation of \"hurl\u00e9\" is \"scream,\" while the output incorrectly translates it as \"hurry.\" Therefore, the output is not accurate.", "rationale_3": "The output is a hallucination. The translation is incorrect as the French word \"hurl\u00e9\" translates to \"scream\" in English, not \"hurry\". Therefore, the output does not accurately reflect the input.", "rationale_4": "The output is a hallucination. The reason being that the output does not accurately translate the input. The French verb \"hurl\u00e9\" means \"screamed\", not \"hurry\". Therefore, the output is not correct."}, {"hyp": "Do you like tomatoes?", "ref": "either", "src": "Tom aime-t-il les tomates ?", "tgt": "Tom likes tomatoes?", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:44:43Z", "rationale_0": "The output is a hallucination. The input sentence is asking whether a person named Tom likes tomatoes, but the output is asking if \"you\" like tomatoes. The model seems to have misinterpreted \"Tom\" as \"you\".", "rationale_1": "The output is a hallucination. The translation is incorrect as it changes the subject of the sentence from \"Tom\" to \"you\". The correct translation should be \"Does Tom like tomatoes?\"", "rationale_2": "The output is a hallucination. The target translation indicates that the subject of the sentence is 'Tom'. However, the output translation incorrectly changes the subject to 'you'.", "rationale_3": "The output is a hallucination. The input is asking specifically about \"Tom\" but the output incorrectly translates it to \"you\".", "rationale_4": "The output is a hallucination. The input is asking whether a specific person, Tom, likes tomatoes. However, the output generalizes the question to \"you,\" which is not accurate according to the target translation."}, {"hyp": "In this case we see the results all the time.", "ref": "either", "src": "Dans ce m\u00e9tier on voit tout de suite les r\u00e9sultats.", "tgt": "In this activity one immediately sees the result.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:45:09Z", "rationale_0": "The output is a hallucination. Although it's not entirely off point, it fails to accurately convey the immediacy emphasized in the input (\"tout de suite\" translates to \"immediately\"), instead suggesting that results are seen constantly (\"all the time\").", "rationale_1": "The output is a hallucination. Although the output is not completely off point, it does not accurately translate the original input. The phrase \"on voit tout de suite les r\u00e9sultats\" directly translates to \"one immediately sees the results\", not \"we see the results all the time\". This changes the meaning of the sentence, making the output inaccurate.", "rationale_2": "The output is a hallucination. The original sentence indicates that the results are seen immediately in this activity, but it does not suggest that the results are seen all the time. Thus, the phrase \"all the time\" is extraneous information not inferred from the input.", "rationale_3": "The output is a hallucination. While it somewhat conveys the meaning of the original sentence, it changes the context by implying that results are seen \"all the time\" instead of \"immediately\", which is the accurate translation of \"tout de suite\".", "rationale_4": "The output is a hallucination. The input sentence talks about seeing results immediately, whereas the output suggests that results are seen all the time. The nuance of immediacy is lost in the translation."}, {"hyp": "I really think you should leave.", "ref": "either", "src": "Je pense vraiment que vous devriez partir.", "tgt": "I really think you should leave.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T18:45:24Z", "rationale_0": "The output is not a hallucination. It perfectly matches the target, which means the translation from French to English is accurate and correct.", "rationale_1": "The output is not a hallucination. It perfectly matches the target, which means the translation from French to English is correct and accurate.", "rationale_2": "The output is not a hallucination. It matches perfectly with the target, meaning the translation from French to English is accurate and correct.", "rationale_3": "The output is not a hallucination. It accurately translates the input to English and matches the target perfectly.", "rationale_4": "The output is correct and accurate. It matches the target translation exactly, demonstrating that the language model has translated the input correctly from French to English. There is no hallucination present."}, {"hyp": "Make him a horse!", "ref": "either", "src": "Fais-lui un c\u00e2lin !", "tgt": "Give her a hug.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:45:47Z", "rationale_0": "The output is a hallucination. It is neither correct nor accurate. The output has completely mistranslated the input, changing the action from giving a hug to making a horse, and also changing the gender from female ('her') to male ('him').", "rationale_1": "The output is a hallucination. It is incorrect and does not accurately translate the input. The input, when translated to English, should be \"Give her a hug,\" not \"Make him a horse!\" The output is not related to the input in any way.", "rationale_2": "The output is a hallucination. The translated output does not accurately reflect the original French input. The input is asking to give someone a hug, not to make someone a horse.", "rationale_3": "The output is a hallucination. It is not correct or accurate as it does not match the target. The translation provided is completely different from the intended meaning of the French input, which should be \"Give her a hug\".", "rationale_4": "The output is a hallucination. The translation is completely incorrect and doesn't match the target. The target asks for a hug, but the output translation is about making a horse, which is not mentioned anywhere in the input."}, {"hyp": "Don't lend anyone else the book you borrowed.", "ref": "either", "src": "Ne pr\u00eate pas \u00e0 un autre le livre que tu as emprunt\u00e9.", "tgt": "Don't lend a borrowed book to another.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T18:46:05Z", "rationale_0": "The output is not a hallucination. It correctly and accurately translates the input from French to English, capturing the main idea without adding any extraneous information.", "rationale_1": "The output is not a hallucination. It accurately translates the meaning of the original French input. Even though the wording is slightly different than the target, the overall message remains the same.", "rationale_2": "The output is not a hallucination. It accurately translates the input from French to English, effectively conveying the same meaning as the target.", "rationale_3": "The output is not a hallucination. It correctly and accurately translates the input. Both the target and output convey the same meaning, which is advising not to lend a book to someone else if you have borrowed it yourself.", "rationale_4": "The output is not a hallucination. It correctly and accurately translates the input from French to English. The slight variation in phrasing compared to the target does not change the overall meaning."}, {"hyp": "I want to drink something free.", "ref": "either", "src": "Je veux boire quelque chose de frais.", "tgt": "I want something cold to drink.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:46:20Z", "rationale_0": "The output is incorrect. The term \"frais\" in French means \"cold,\" not \"free.\" Therefore, the output is a hallucination as it incorrectly translated the French word \"frais\" to \"free\" instead of the correct translation which is \"cold\".", "rationale_1": "The output is incorrect. The correct translation of \"frais\" from French to English in this context is \"cold\", not \"free\". Therefore, the output is a hallucination.", "rationale_2": "The output is incorrect. The correct translation of 'frais' from French to English is 'cold', not 'free'. Therefore, the output does not match the target and is a hallucination.", "rationale_3": "The output is a hallucination. The correct translation of \"frais\" from French to English is \"cold\", not \"free\". The output is therefore not accurate.", "rationale_4": "The output is incorrect. The French word \"frais\" translates to \"cold\" in English, not \"free\". Hence, the output is a hallucination."}, {"hyp": "Do you have a cryon?", "ref": "either", "src": "As-tu un crayon ?", "tgt": "Have you got a pencil?", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:46:40Z", "rationale_0": "The output is a hallucination. While the general meaning of the sentence is correctly translated, the word \"crayon\" is incorrectly translated as \"cryon\", which is not a valid English word.", "rationale_1": "The output is a hallucination. While the translation is mostly correct, it contains a spelling mistake. The correct English word for \"crayon\" is \"pencil\", not \"cryon\".", "rationale_2": "The output is a hallucination. The translation of the word \"crayon\" from French to English is \"pencil\", not \"cryon\". Therefore, the output contains incorrect information.", "rationale_3": "The output is a hallucination. While it correctly translates the general meaning of the French sentence, it uses \"cryon\" instead of \"pencil\". This seems to be a typographical error rather than a translation error.", "rationale_4": "The output is a hallucination. Although the translation is mostly correct, the word \"cryon\" is not a correct translation of the French word \"crayon,\" which should be translated as \"pencil.\" Therefore, the output is incorrect."}, {"hyp": "I talked to other people in the same situation.", "ref": "either", "src": "J'ai discut\u00e9 avec d'autres personnes dans la m\u00eame situation.", "tgt": "I have talked with others in the same situation.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T18:47:02Z", "rationale_0": "The output is not a hallucination. Although the verb tense is slightly different (\"I have talked\" vs \"I talked\"), the meaning of the sentence remains the same and accurately reflects the input.", "rationale_1": "The output is not a hallucination. It accurately translates the input from French to English, maintaining the original meaning. The difference in verb tense (from \"have talked\" to \"talked\") is minor and does not fundamentally change the meaning of the sentence.", "rationale_2": "The output is not a hallucination. Although the translation is not word-for-word identical to the target, it conveys the same meaning as the input. Both \"I have talked\" and \"I talked\" are past tenses in English and can be used interchangeably in this context. Similarly, \"others\" and \"other people\" share the same meaning.", "rationale_3": "The output is not a hallucination. The output accurately translates the input from French to English, although it uses slightly different phrasing (\"I talked\" instead of \"I have talked\"). The meaning of the sentence is preserved and there is no addition of extraneous information.", "rationale_4": "The output is not a hallucination. It accurately translates the input to English, even though it uses slightly different words (\"talked to\" instead of \"have talked with\"). The meaning remains the same."}, {"hyp": "The nurse will check your arm within 2 days to see if there's any reaction.", "ref": "either", "src": "L'infirmier v\u00e9rifiera ton bras dans les 2 jours pour voir s'il y a une r\u00e9action.", "tgt": "The nurse will check your arm within 2 days to see if there is a reaction.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T18:47:24Z", "rationale_0": "The output is not a hallucination. It accurately translates the input from French to English. The slight variation in phrasing, \"if there's any reaction\" instead of \"if there is a reaction\", does not change the overall meaning and remains true to the original input.", "rationale_1": "The output is not a hallucination. It accurately translates the input to English, maintaining the original meaning and context without adding any extraneous information. The slight rephrasing of \"if there is a reaction\" to \"if there's any reaction\" doesn't change the overall meaning.", "rationale_2": "The output is not a hallucination. It accurately translates the input to English, albeit with a slight variation in phrasing (\"if there's any reaction\" versus \"if there is a reaction\"). This variation does not change the overall meaning of the sentence, so it's still correct and accurate.", "rationale_3": "The output is not a hallucination. It accurately translates the input from French to English, maintaining the original meaning and context. The slight difference in phrasing (\"if there's any reaction\" versus \"if there is a reaction\") doesn't change the overall meaning.", "rationale_4": "The output is not a hallucination. It accurately translates the input to English, maintaining the original meaning and context. The difference in the phrase \"if there is a reaction\" and \"if there's any reaction\" is negligible and does not affect the overall meaning."}, {"hyp": "You're not missing anyone.", "ref": "either", "src": "Tu ne manques \u00e0 personne.", "tgt": "No one misses you.", "model": "", "task": "MT", "labels": ["Hallucination", "Not Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:47:42Z", "rationale_0": "The output is a hallucination. The translation provided by the model is incorrect as it changes the meaning of the original sentence. The correct translation from French to English should be \"No one misses you,\" not \"You're not missing anyone.\"", "rationale_1": "The output is a hallucination. The given translation does not accurately reflect the meaning of the input. The correct translation should be \"No one misses you\" as per the target, not \"You're not missing anyone\". The output has twisted the meaning of the original sentence.", "rationale_2": "The output is a hallucination. Although the translation is grammatically correct, it does not accurately convey the sentiment of the input. The input sentence \"Tu ne manques \u00e0 personne\" translates to \"No one misses you,\" not \"You're not missing anyone.\" Thus, the output is not correct or accurate.", "rationale_3": "The output is a hallucination. The translation provided in the output is incorrect. The correct translation, as given in the target, is \"No one misses you\". The output inaccurately translates the sentence to \"You're not missing anyone\", which changes the meaning of the original sentence.", "rationale_4": "The output is a hallucination. The output incorrectly translates the input. The correct translation is \"No one misses you\" as given in the target. The output \"You're not missing anyone\" changes the meaning of the sentence."}, {"hyp": "I've got the floor and the furniture.", "ref": "either", "src": "J'ai poli le plancher et les meubles.", "tgt": "I polished up the floor and furniture.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:47:59Z", "rationale_0": "The output is a hallucination. The correct translation of the input should include the action of \"polishing\" which is missing in the output. The output suggests that the speaker has acquired the floor and furniture, which is not the intended meaning of the original sentence.", "rationale_1": "The output is a hallucination. The output does not correctly translate the input, as it does not include the action of polishing. The translation is inaccurate and misses the essential information conveyed in the source sentence.", "rationale_2": "The output is a hallucination. The correct translation of \"J'ai poli\" is \"I polished\", not \"I've got\". The output does not accurately reflect the action of polishing stated in the input.", "rationale_3": "The output is a hallucination. The translation is incorrect because it omits the key action of \"polishing\" conveyed in the input. Instead, it suggests that the speaker has acquired or possesses the floor and furniture, which is not inferred from the original French sentence.", "rationale_4": "The output is a hallucination. The output does not correctly translate the action \"poli\" (polished) from the input, instead it uses \"got\" which changes the meaning of the sentence."}, {"hyp": "I can't do it alone.", "ref": "either", "src": "Je ne peux le faire seule. Il vous faut m'aider.", "tgt": "I can't do it alone. You have to help me.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Hallucination", "Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.4, "timestamp": "2023-11-05T18:48:18Z", "rationale_0": "The output is a hallucination. While the first sentence is translated correctly, the output completely omits the second sentence of the input, \"Il vous faut m'aider,\" which should be translated as \"You have to help me.\" Therefore, the output is not fully accurate.", "rationale_1": "The output is not entirely accurate. While it correctly translates the first sentence, it completely omits the second sentence, \"You have to help me.\" This makes the translation incomplete. Therefore, while not a hallucination, it is an incomplete translation.", "rationale_2": "The output is a hallucination. While the first part of the translation, \"I can't do it alone,\" is correct, the second part, \"You have to help me,\" is missing from the output. This makes the output incomplete and inaccurate compared to the target.", "rationale_3": "The output is a hallucination. Although the first sentence is translated correctly, the second sentence is completely missing from the output. The output should have included \"You have to help me.\"", "rationale_4": "The output is a hallucination. While the first sentence is translated correctly, the second sentence from the input (\"Il vous faut m'aider\" - \"You have to help me\") is completely missing from the output, making it incomplete and inaccurate."}, {"hyp": "He lost what he received from his father.", "ref": "either", "src": "Il a perdu ce qu'il a re\u00e7u de son p\u00e8re.", "tgt": "He wasted that which he had received from his father.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T18:48:40Z", "rationale_0": "The output is not a hallucination. It is a correct and accurate translation of the input, although it uses \"lost\" instead of \"wasted\". The meaning of the sentence remains the same, implying that what he received from his father is no longer in his possession.", "rationale_1": "The output is not a hallucination. It provides an accurate translation of the input, even though it is not an exact match with the target. The verb \"perdu\" can be translated as both \"wasted\" and \"lost\", thus both translations are correct.", "rationale_2": "The output is not a hallucination. While the exact verb used in the target (\"wasted\") is different from the one used in the output (\"lost\"), both verbs convey a similar meaning in this context. Therefore, the output is still a correct and accurate translation of the input.", "rationale_3": "The output is not a hallucination. However, it is not entirely accurate. The input sentence in French translates to \"He wasted what he received from his father\" in English, not \"He lost what he received from his father\". Therefore, while the output is not entirely correct, it does not contain extraneous information or deviate completely from the input.", "rationale_4": "The output is not a hallucination. It is a correct and accurate translation of the input. However, it does not fully capture the connotation of the target. The target implies that the person didn't just lose what they had received, but wasted it. The output doesn't convey this nuance."}, {"hyp": "We've discovered a lot of news.", "ref": "either", "src": "Nous avons d\u00e9couvert une grande nouveaut\u00e9.", "tgt": "We have discovered a great novelty.", "model": "", "task": "MT", "labels": ["Hallucination", "Not Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:49:02Z", "rationale_0": "The output is a hallucination. Although it maintains a similar semantic field, it does not accurately translate the original French sentence. The French word \"nouveaut\u00e9\" was translated into \"news\" instead of \"novelty\". \"A lot of\" is also added information not present in the original sentence.", "rationale_1": "The output is a hallucination. Although it maintains a similar theme to the target (discovery of something new), it incorrectly translates \"une grande nouveaut\u00e9\" as \"a lot of news\" instead of \"a great novelty\". Therefore, it does not accurately represent the original French sentence.", "rationale_2": "The output is a hallucination. While the output is not entirely off point, it is not an accurate translation of the input. \"Une grande nouveaut\u00e9\" should be translated as \"a great novelty\", not \"a lot of news\". The output introduces the concept of quantity which is not present in the input.", "rationale_3": "The output is a hallucination. Even though it generally conveys a similar meaning, it is not an accurate translation of the input. \"A grande nouveaut\u00e9\" directly translates to \"a great novelty\", not \"a lot of news\".", "rationale_4": "The output is a hallucination. Although it captures the general theme of discovery from the input, it incorrectly translates \"une grande nouveaut\u00e9\" as \"a lot of news\" instead of \"a great novelty\". The output misses the specific detail of a single, significant novelty."}, {"hyp": "Why is everyone okay?", "ref": "either", "src": "Pourquoi est-ce que tout le monde rigole ?", "tgt": "Why is everyone laughing?", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:49:21Z", "rationale_0": "The output is a hallucination. The correct translation of \"rigole\" from French to English is \"laughing\", not \"okay\". Therefore, the output does not accurately translate the original input.", "rationale_1": "The output is a hallucination. The translated output, \"Why is everyone okay?\" does not accurately reflect the meaning of the input. The correct translation should be \"Why is everyone laughing?\" as given in the target. Therefore, the output is incorrect.", "rationale_2": "The output is a hallucination. The target translation indicates the correct translation of the input, asking why everyone is laughing. The output, however, incorrectly translates \"rigole\" (laughs) as \"okay\", which is not accurate.", "rationale_3": "The output is a hallucination. The output translates the French phrase to \"Why is everyone okay?\" whereas the correct translation, as given in the target, is \"Why is everyone laughing?\" Therefore, the output is incorrect and off point.", "rationale_4": "The output is a hallucination. The target translation from French to English should be \"Why is everyone laughing?\" However, the output translates to \"Why is everyone okay?\" which does not match the intended meaning of the input."}, {"hyp": "No matter what you do to your guide.", "ref": "either", "src": "Chacun fait \u00e0 sa guise.", "tgt": "Each one does as he likes.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T18:49:43Z", "rationale_0": "The output is a hallucination. The translation does not accurately reflect the meaning of the original French sentence. The French sentence is about individuals doing as they please, not about doing something to a guide.", "rationale_1": "The output is a hallucination. The translated output does not match the target translation. The correct translation should be \"Each one does as he likes\" but the output translation has completely different meaning, making it incorrect and a hallucination.", "rationale_2": "The output is a hallucination. The translated output is not accurate and does not match the target. The input sentence in French means \"Each one does as he likes\", but the output suggests something entirely different, introducing the concept of a 'guide' which is not present in the input.", "rationale_3": "The output is a hallucination. It does not accurately translate the given French input. The meaning of the input is completely changed in the output and it contains extraneous information that cannot be inferred from the input.", "rationale_4": "The output is a hallucination. The output translation provided does not accurately reflect the meaning of the original French sentence. The correct translation is the target \"Each one does as he likes,\" which indicates individual freedom of action, whereas the output talks about doing something to a guide, which is not at all mentioned or inferred in the original input."}]