[{"hyp": "A district of Kowloon, China.", "ref": "tgt", "src": "The City <define> Chiuchow </define> is Kowloon 's other top restaurant and is famous for its goose dishes and other specialties from the Chiuchow region ( you may also wish to try the beef satay done in a creamy sauce ) .", "tgt": "The Chaoshan region where the Teochew dialect is spoken.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:03:45Z", "rationale_0": "The output is a hallucination. The input does not state that Chiuchow is a district of Kowloon, China. Instead, it mentions that a restaurant in Kowloon is famous for its dishes from the Chiuchow region. The target provides the correct definition that Chiuchow refers to the Chaoshan region where the Teochew dialect is spoken.", "rationale_1": "The output is a hallucination. The input mentions \"Chiuchow\" as a region, not a district of Kowloon, China. Furthermore, it is incorrect because it does not match the target which states that Chiuchow refers to the Chaoshan region where the Teochew dialect is spoken.", "rationale_2": "The output is a hallucination. The input does mention Kowloon, China, but it does not definitively state that Chiuchow is a district in Kowloon. Instead, it describes Chiuchow as a region with its own specialties, suggesting that it's a separate geographical area. The output appears to infer from the restaurant's location that Chiuchow must also be a district in Kowloon, which is an incorrect inference. The target definition correctly identifies Chiuchow as the Chaoshan region where the Teochew dialect is spoken.", "rationale_3": "The output is a hallucination. The input indicates that Chiuchow is a region from which the restaurant derives its specialties, not a district in Kowloon, China. The output does not align with the target, which identifies Chiuchow as being associated with the Chaoshan region and the Teochew dialect.", "rationale_4": "The output is a hallucination. While the input mentions that Chiuchow is a restaurant in Kowloon, it does not imply that Chiuchow is a district of Kowloon, China. The output is therefore inaccurate."}, {"hyp": "(Wicca) A witchdoctor.", "ref": "tgt", "src": "\u201c I went to see the witchdoctor , the <define> igqira </define> . And he spoke to the izinyanya , the spirits of the ancestors . \u201d", "tgt": "(South Africa) A traditional tribal diviner or spiritual healer.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Not Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:04:16Z", "rationale_0": "The output is a hallucination. While it is correct in defining 'igqira' as a kind of witchdoctor, the context provided in brackets is incorrect. The term 'igqira' is specific to South Africa, not Wicca. Therefore, the output provides incorrect extraneous information.", "rationale_1": "The output is a hallucination. The output incorrectly defines \"igqira\" as a term from Wicca, while the target specifies that it is a term used in South Africa to refer to a traditional tribal diviner or spiritual healer. The output does not provide the complete and accurate information as specified in the target.", "rationale_2": "The output is a hallucination. While the output is not completely off point, it incorrectly identifies \"igqira\" as a term from Wicca instead of its correct cultural context, South Africa. Therefore, it does not match the target, which correctly defines \"igqira\" as a traditional tribal diviner or spiritual healer in South Africa.", "rationale_3": "The output is a hallucination. While the output does correctly identify \"igqira\" as a type of witchdoctor, it incorrectly associates the term with Wicca, which is not mentioned or implied in the input. The target indicates that \"igqira\" is a term from South Africa referring to a traditional tribal diviner or spiritual healer, which aligns more closely with the context provided in the input.", "rationale_4": "The output is a hallucination. The target definition specifies that \"igqira\" is a South African term for a traditional tribal diviner or spiritual healer. The output, however, incorrectly associates the term with Wicca and simply defines it as a witchdoctor, missing the cultural and spiritual aspects of the term's meaning."}, {"hyp": "(nautical) A halyard.", "ref": "tgt", "src": "Haul away , keeping strain on both parts of the halyard so that the <define> pigstick </define> remains vertical as it goes up and does n't foul the spreaders .", "tgt": "(nautical) A staff that carries a flag or pennant above the mast of a sailboat.", "model": "", "task": "DM", "labels": ["Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:04:40Z", "rationale_0": "The output is a hallucination. The term 'pigstick' is inaccurately defined as a 'halyard'. As per the target, 'pigstick' is a staff that carries a flag or pennant above the mast of a sailboat, not a halyard.", "rationale_1": "The output is a hallucination. The term \"pigstick\" is inaccurately defined as a \"halyard\" in the output, whereas the target correctly identifies it as a staff that carries a flag or pennant above the mast of a sailboat.", "rationale_2": "The output is a hallucination. The target definition indicates that a pigstick is a staff that carries a flag or pennant above the mast of a sailboat, not a halyard as stated in the output.", "rationale_3": "The output is a hallucination. The output incorrectly defines \"pigstick\" as a halyard, which is not aligned with the target definition of \"a staff that carries a flag or pennant above the mast of a sailboat.\"", "rationale_4": "The output is a hallucination. The term \"pigstick\" is inaccurately defined as a \"halyard\" in the output, while the target clearly states that it is a type of staff used to carry a flag or pennant above the mast of a sailboat."}, {"hyp": "The quality of being rational.", "ref": "tgt", "src": "And what difference is there between the credibleness and <define> rationalness </define> of any of these wonders and the credibleness and rationalness of Papal infallibility ?", "tgt": "(archaic) The quality or state of being rational.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T19:06:44Z", "rationale_0": "The output is not a hallucination. It accurately defines the term \"rationalness\" as being the quality of being rational, which aligns with the target definition.", "rationale_1": "The output is not a hallucination. It correctly defines the term 'rationalness' as the quality of being rational, which is essentially the same as the target definition.", "rationale_2": "The output is not a hallucination. It accurately reflects the target, defining \"rationalness\" as the quality of being rational. Although it doesn't use the exact phrasing of the target, the meaning is the same.", "rationale_3": "The output is not a hallucination. It accurately defines the term \"rationalness\" as the quality of being rational, which aligns with the target definition. The difference in phrasing does not change the meaning of the definition.", "rationale_4": "The output is not a hallucination. Although the output does not include the term \"archaic\" as in the target, it accurately defines the term \"rationalness\" as the quality of being rational."}, {"hyp": "(uncountable) The study of trees.", "ref": "tgt", "src": "It is now generally supposed that the forbidden fruit was a kind of citrus , but certain facts connected with <define> arborolatry </define> seem to me to disprove this opinion .", "tgt": "The worship of trees.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:07:05Z", "rationale_0": "The output is a hallucination. The target definition of \"arborolatry\" is the worship of trees, whereas the output incorrectly defines it as the study of trees.", "rationale_1": "The output is a hallucination. The target definition indicates that \"arborolatry\" is the worship of trees, while the output incorrectly defines it as the study of trees.", "rationale_2": "The output is a hallucination. The target defines \"arborolatry\" as the worship of trees, but the output incorrectly defines it as the study of trees.", "rationale_3": "The output is a hallucination. The target definition of \"arborolatry\" is the worship of trees, not the study of trees as suggested by the output.", "rationale_4": "The output is a hallucination. The target indicates that \"arborolatry\" refers to the worship of trees, whereas the output incorrectly defines it as the study of trees."}, {"hyp": "(zoology) A pseudostome.", "ref": "tgt", "src": "The pseudembryo moves rapidly in the water , rolling round and swinging from side to side ; as a rule , and especially when at rest , the surface bearing the pseudostome and <define> pseudoproct </define> is turned downwards .", "tgt": "(biology) The anal opening on the pseudembryo of an echinoderm.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:07:31Z", "rationale_0": "The output is a hallucination. The term pseudoproct is incorrectly defined as a pseudostome, which is different from the target definition. The target correctly defines pseudoproct as the anal opening on the pseudembryo of an echinoderm, but the output does not provide this information.", "rationale_1": "The output is a hallucination. The target definition refers to the pseudoproct as the anal opening on the pseudembryo of an echinoderm, which is not mentioned in the output. Instead, the output incorrectly defines pseudoproct as a pseudostome, which is not accurate.", "rationale_2": "The output is a hallucination. The output incorrectly defines 'pseudoproct' as a 'pseudostome', which is not aligned with the target definition that identifies 'pseudoproct' as the anal opening on the pseudembryo of an echinoderm.", "rationale_3": "The output is a hallucination. The term \"pseudoproct\" is incorrectly defined as a \"pseudostome\" in the output, while the target correctly specifies it as the anal opening on a pseudembryo of an echinoderm.", "rationale_4": "The output is a hallucination. It does not match the target definition. The target defines \"pseudoproct\" as the anal opening on the pseudembryo of an echinoderm, while the output incorrectly defines it as a pseudostome."}, {"hyp": "Resembling or characteristic of umber.", "ref": "tgt", "src": "<define> umbery </define> gold", "tgt": "Of or pertaining to umber; like umber.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T19:07:55Z", "rationale_0": "The output is not a hallucination. While the output doesn't match the target exactly, it is in essence saying the same thing, that 'umbery' refers to something that resembles or is characteristic of umber, which is in line with the target definition.", "rationale_1": "The output is correct and not a hallucination. Both the target and output convey the same meaning - that \"umbery\" pertains to or is like umber. The output does not provide any extraneous or off-point information.", "rationale_2": "The output is not a hallucination. It accurately defines 'umbery' as resembling or characteristic of umber, which is consistent with the target definition. The term 'gold' in the input does not seem to have any bearing on the definition and can be ignored.", "rationale_3": "The output is not a hallucination. Both the target and output give similar definitions that relate to something resembling or being characteristic of umber. The phrase \"of or pertaining to umber\" in the target and \"resembling or characteristic of umber\" in the output have essentially the same meaning.", "rationale_4": "The output is not a hallucination. It correctly defines \"umbery\" as resembling or being characteristic of umber, which aligns well with the target definition."}, {"hyp": "(music, transitive) To play (a note) at the same time.", "ref": "tgt", "src": "Now the two bounding notes of an enharmonic tetrachord of the relevant sort will indeed both be the lowest notes of pykna when the tetrachords are put together in conjunction ; but the higher of them can never <define> abut on </define> a pyknon in the case envisaged here , where the tone is introduced to disjoin the tetrachords .", "tgt": "(transitive) To border on.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:08:16Z", "rationale_0": "The output is a hallucination. The target definition is about bordering on something, which can metaphorically apply to a range of contexts. However, the output definition is specifically about playing a note at the same time, which is not mentioned or inferred in the input or target.", "rationale_1": "The output is a hallucination. The target definition indicates that \"abut on\" means to border on, not to play a note at the same time as suggested by the output. The output definition is incorrect and does not match the target.", "rationale_2": "The output is a hallucination. The target suggests that \"abut on\" means to border on, whereas the output defines \"abut on\" as playing a note at the same time. The output does not match the target and is therefore inaccurate.", "rationale_3": "The output is a hallucination. The correct definition of \"abut on\" is to border on, as given in the target. However, the output provides a definition related to playing a note at the same time, which is not correct.", "rationale_4": "The output is a hallucination. The target definition suggests that \"abut on\" means to border on, while the output suggests it relates to playing a note at the same time. The output does not match the target and does not accurately define \"abut on\" in the given context."}, {"hyp": "(Australia, New Zealand, colloquial) A hatfish.", "ref": "tgt", "src": "Noah did n't realize when he stayed on the job - he was then about 600 years old and built the ark and drove the animals in two by two , the <define> hatfish </define> and the kangaroo \u2014 \u2014 he did n't realize he was laying the foundation for an occupation for old men in New York , several years later .", "tgt": "(colloquial) Synonym of halibut", "model": "", "task": "DM", "labels": ["Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:08:43Z", "rationale_0": "The output is a hallucination. It does not match the target definition, as it does not explain that a hatfish is a synonym of halibut. It instead provides a regional context for the term without defining it.", "rationale_1": "The output is a hallucination. The target definition suggests that 'hatfish' is a synonym for 'halibut'. However, the output generates a different definition, associating 'hatfish' with Australia and New Zealand but not providing any meaningful definition for it. The context provided in the input does not in any way suggest a link with Australia and New Zealand, making the output incorrect and off point.", "rationale_2": "The output is a hallucination. The target indicates that \"hatfish\" is a colloquial synonym for halibut, however, the output does not correctly reflect this and instead offers a regional definition without specifying what the term means.", "rationale_3": "The output is a hallucination. The output defines 'hatfish' as a term used in Australia and New Zealand, while the target specifies it as a synonym of halibut. The input doesn't provide any information to support the output's definition.", "rationale_4": "The output is a hallucination. The target defines 'hatfish' as a synonym of halibut, but the output gives an incorrect and unrelated definition stating that it is a term used in Australia and New Zealand. The input doesn't provide any information to infer this definition."}, {"hyp": "Having a keen sense of humor.", "ref": "tgt", "src": "<define> keen </define> satire or sarcasm", "tgt": "Acrimonious, bitter, piercing.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:09:09Z", "rationale_0": "The output is a hallucination. While the term \"keen\" can refer to having a sharp sense of something, the output misinterprets the term by applying it to humor instead of satire or sarcasm as indicated in the input. In this context, \"keen\" should refer to acrimony, bitterness, or piercing sarcasm or satire, not humor.", "rationale_1": "The output is a hallucination. It does not match with the target definition of being acrimonious, bitter or piercing. Instead, it gives a definition related to humor, which is not inferred from the input.", "rationale_2": "The output is a hallucination. The term \"keen\" is being asked to be defined in the context of satire or sarcasm, but the output provides a definition related to sense of humor, which is not necessarily the same context. The target definition suggests a more negative or harsh connotation, which the output does not reflect.", "rationale_3": "The output is a hallucination. The target suggests the term 'keen' to be related to acrimony, bitterness, or piercing, while the output incorrectly associates 'keen' with a sense of humor. The output is therefore not accurate.", "rationale_4": "The output is a hallucination. The definition provided (\"Having a keen sense of humor\") is not in line with the target definition which describes keen as \"acrimonious, bitter, piercing\". The output seems to be defining a character trait using the word 'keen' instead of defining the term 'keen' itself."}, {"hyp": "A person who has a pass.", "ref": "tgt", "src": "<define> Passholders </define> can visit the theme park all year round .", "tgt": "One who holds a pass.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T19:09:27Z", "rationale_0": "The output is not a hallucination. It accurately defines the term \"Passholders\" as someone who has a pass, which is consistent with the target definition, albeit worded slightly differently.", "rationale_1": "The output is not a hallucination. It correctly defines the term \"Passholders\" as a person who has a pass, which aligns with the target definition.", "rationale_2": "The output is not a hallucination. Both the target and output essentially provide the same definition of 'passholders' - individuals who possess a pass. Although there is a slight difference in wording, the meaning remains the same.", "rationale_3": "The output is not a hallucination. It correctly defines 'Passholders' as a person who has a pass, which is similar to the target definition 'One who holds a pass.'", "rationale_4": "The output is not a hallucination. It accurately defines the term \"Passholders\" as someone who possesses a pass, aligning with the target definition."}, {"hyp": "(colloquial) A term of endearment.", "ref": "tgt", "src": "Hey , <define> babe </define> , how 's about you and me getting together ?", "tgt": "(affectionate) Darling (term of endearment).", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T19:09:49Z", "rationale_0": "The output is not a hallucination. While it doesn't specify the affectionate nature of the term \"babe\" as the target does, it correctly identifies it as a term of endearment, which aligns with the target. It also adds that it's a colloquial term, which is accurate and not extraneous information.", "rationale_1": "The output is not a hallucination. While it is not identical to the target, it is still a correct and accurate definition of the term \"babe\". It correctly identifies \"babe\" as a term of endearment. However, it does not include the additional context of it being an affectionate term that the target provides.", "rationale_2": "The output is not a hallucination. While it doesn't match the target exactly, it is still a correct definition of the term \"babe\". The term is indeed often used as a colloquial term of endearment.", "rationale_3": "The output is not a hallucination. It correctly defines \"babe\" as a term of endearment, although it does not include the \"affectionate\" or \"darling\" aspects mentioned in the target. However, the output is still accurate and does not include extraneous or incorrect information.", "rationale_4": "The output is not a hallucination. Although it does not use the exact verbiage from the target, it correctly identifies \"babe\" as a term of endearment and even provides the additional context that it is often used in colloquial language."}, {"hyp": "(intransitive) To speak in a slurred manner.", "ref": "tgt", "src": "Sometimes life takes hold of one , carries the body along , accomplishes one 's history , and yet is not real , but leaves oneself as it were <define> slurred over </define> .", "tgt": "(dated) To deal with something hurriedly; to treat in a perfunctory manner.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:10:11Z", "rationale_0": "The output is a hallucination. The definition provided does not match the target definition. The output gives a definition that relates to speaking in a slurred manner, while the target definition refers to dealing with something hurriedly or in a perfunctory manner.", "rationale_1": "The output is a hallucination. The target definition speaks about dealing with something hurriedly or treating something in a perfunctory manner, while the output speaks about speaking in a slurred manner, which is not related to the target definition.", "rationale_2": "The output is a hallucination. The output provides a definition related to speech, while the target and input suggest a metaphorical use of the term \"slurred over\" that refers to dealing with something quickly or in a superficial manner. The output does not match the target or context given in the input.", "rationale_3": "The output is a hallucination. The provided definition in the output does not match the target definition. The target talks about dealing with something hurriedly, while the output talks about speaking in a slurred manner.", "rationale_4": "The output is a hallucination. The provided definition in the output does not match the target definition. The target definition talks about handling something in a hurried or careless manner, while the output definition refers to speaking in a slurred manner. Therefore, the output is incorrect."}, {"hyp": "A device that simulates walking.", "ref": "tgt", "src": "During the late 1960s and early 1970s , it was also the site of the lunar 1\u20446 gravity <define> walking simulator </define> rig .", "tgt": "Used other than figuratively or idiomatically: see walking,\u200e simulator.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:10:41Z", "rationale_0": "The output is a hallucination. The output description does not capture the specific detail of the 'walking simulator' being a device used to simulate the experience of walking under lunar gravity conditions, as implied by the input. Instead, it offers a more generic definition.", "rationale_1": "The output is a hallucination. While it is not entirely incorrect, it fails to capture the full specificity of the target definition. The target implies that the \"walking simulator\" is not just any device that simulates walking, but specifically one that was used to simulate walking in a 1/6 gravity environment, like that of the moon. This key detail is missing from the output.", "rationale_2": "The output is a hallucination. While it is true that a 'walking simulator' might be a device that simulates walking, the output fails to capture the specific context provided in the input. The definition should include information about the 'lunar 1/6 gravity' element and the time period specified in the input.", "rationale_3": "The output is incorrect, hence it can be considered a hallucination. The output fails to mention the key aspect of '1\u20446 lunar gravity' which is a critical part of the definition of the 'walking simulator' in this context. The output's definition is too general and does not match the specificity of the target.", "rationale_4": "The output is a hallucination. Although the output is somewhat accurate in defining a \"walking simulator\" as \"a device that simulates walking,\" it lacks specificity and does not mention the key detail from the input that this particular simulator was used to simulate the lunar 1/6 gravity conditions experienced on the moon."}, {"hyp": "(intransitive, colloquial) To be very hot.", "ref": "tgt", "src": "Let 's face it , they 're there for a good stroll on a Sunday afternoon when it 's <define> pissing </define>   outside .", "tgt": "(ambitransitive, mildly, _, vulgar) To rain heavily.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:11:02Z", "rationale_0": "The output is a hallucination. The target definition describes \"pissing\" as referring to heavy rain, which aligns with the context given in the input. However, the output inaccurately defines \"pissing\" as referring to very hot weather, which is completely opposite to the intended meaning.", "rationale_1": "The output is a hallucination. The target definition indicates that 'pissing' in this context refers to heavy rain, not hot weather, as the output suggests. Therefore, the output is not correct or accurate.", "rationale_2": "The output is a hallucination. The target definition indicates that \"pissing\" in this context refers to heavy rain, but the output incorrectly defines it as being very hot. Therefore, the output is not accurate.", "rationale_3": "The output is a hallucination. The expected definition was supposed to revolve around heavy rain, as indicated by the target, but the output generated a definition related to hot weather, which is incorrect and off point.", "rationale_4": "The output is a hallucination. The target definition states that 'pissing' in this context refers to heavy rain, which is accurate. However, the output completely misinterprets the term and inaccurately defines it as being very hot, which is incorrect."}, {"hyp": "(geology) Synonym of synecdoche", "ref": "tgt", "src": "In the Ronne <define> syneclise </define> the thickness of sedimentary cover reaches 13.5 km and the folded basement has a complex relief owing to block movements along faults of different rank .", "tgt": "(geology) A large, shallow depression formed on a continental platform due to slow subsidence.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:11:30Z", "rationale_0": "The output is a hallucination. The generated output incorrectly identifies \"syneclise\" as a synonym of \"synecdoche,\" which is not accurate. The target correctly defines \"syneclise\" as a geological term referring to a large, shallow depression formed on a continental platform due to slow subsidence.", "rationale_1": "The output is a hallucination. The term 'syneclise' is incorrectly defined as a synonym of 'synecdoche', which is a figure of speech, not a geological term. The correct definition is a large, shallow depression formed on a continental platform due to slow subsidence, as given in the target.", "rationale_2": "The output is a hallucination. The term 'syneclise' in geology refers to a large, shallow depression formed on a continental platform due to slow subsidence as stated in the target. The output incorrectly defines 'syneclise' as a synonym of 'synecdoche', which is a figure of speech in literature, not a geological term.", "rationale_3": "The output is a hallucination. The term \"syneclise\" is incorrectly defined as a synonym of \"synecdoche,\" which is a completely unrelated term from a different field (literature). The target provides the correct definition related to geology.", "rationale_4": "The output is a hallucination. The output incorrectly defines \"syneclise\" as a synonym of \"synecdoche\", which is not accurate according to the target definition. The target accurately describes \"syneclise\" as a geological term referring to a large, shallow depression formed on a continental platform due to slow subsidence."}, {"hyp": "(informal) A person who is addicted to sport.", "ref": "tgt", "src": "I have spent much of my life a recovering <define> sportaholic </define> . If it bounced , rolled , slid , or flew , I chased it . Or watched it .", "tgt": "A sportsaholic.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T19:11:54Z", "rationale_0": "The output is not a hallucination. It accurately defines the term \"sportaholic\" as a person who is addicted to sports. This inference could be reasonably drawn from the input sentence, as it describes a person who chased or watched anything that bounced, rolled, slid, or flew, indicating a strong interest or obsession with sports.", "rationale_1": "The output is not a hallucination. It correctly and accurately defines \"sportaholic\" as a person who is addicted to sports. This definition is in line with the context provided in the input, where the person is narrating their intense involvement with sports.", "rationale_2": "The output is not a hallucination. It accurately defines the term \"sportaholic\" as a person who is addicted to sports, which is consistent with the target definition. The context provided by the input also supports this definition.", "rationale_3": "The output is not a hallucination. It correctly defines \"sportaholic\" as a person who is addicted to sports, which matches the context provided in the input. The term \"sportaholic\" is inferred to mean someone who is obsessed with sports, aligning with the target.", "rationale_4": "The output is not a hallucination. The output accurately defines the term \"sportaholic\" as a person who is addicted to sports, which aligns with the target definition. It captures the essence of the term in a more formal and detailed way than the target."}, {"hyp": "Resembling or characteristic of French surrealism.", "ref": "tgt", "src": "Quatermass also mediated Wellsian influence on the tone and preoccupations of the new hybrid SF \u2013 horror - film genre , with its monstrous <define> Gigeresque </define> fusions of machine and organism [ \u2026 ]", "tgt": "Reminiscent of H. R. Giger (born 1940), Swiss surrealist painter best known for nightmarish biomechanical imagery.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Not Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:12:22Z", "rationale_0": "The output is a hallucination. The term 'Gigeresque' refers to the style of H. R. Giger, a Swiss surrealist painter known for his biomechanical imagery, not French surrealism. The output is incorrect and does not match the target.", "rationale_1": "The output is a hallucination. The output incorrectly identifies \"Gigeresque\" as being associated with French surrealism, while the target correctly identifies it as being reminiscent of the work of H. R. Giger, a Swiss surrealist painter. The output does not accurately define the term.", "rationale_2": "The output is a hallucination. The term \"Gigeresque\" refers specifically to the style of H. R. Giger, a Swiss surrealist painter, not French surrealism in general. The output fails to mention the key elements of H.R. Giger's work and his nationality, which makes it incorrect and misleading.", "rationale_3": "The output is a hallucination. It incorrectly states that \"Gigeresque\" is characteristic of French surrealism instead of correctly attributing it to H. R. Giger, a Swiss surrealist painter known for his biomechanical imagery.", "rationale_4": "The output is a hallucination. While it correctly identifies 'Gigeresque' as referring to a style reminiscent of a particular artist, it inaccurately claims that this artist is associated with French surrealism. The target definition correctly identifies H. R. Giger, a Swiss surrealist artist, as the source of the term."}, {"hyp": "The state or quality of being a princess.", "ref": "tgt", "src": "\u201c What are you doing ? \u201d Carly asked , looking around . \u201c You do n\u2019t want to be in here . You \u2019re way too much of a princess . \u201d / \u201c Remember how I grew up , Carly . I \u2019ve earned my <define> princessness </define> . \u201d", "tgt": "The quality of being a princess.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T19:12:44Z", "rationale_0": "The output is not a hallucination. It accurately defines \"princessness\" as the state or quality of being a princess, which aligns well with the target definition.", "rationale_1": "The output is not a hallucination. It accurately defines the term \"princessness\" in a manner that aligns with the target definition. The inclusion of \"state or\" in the output does not detract from its accuracy or relevance.", "rationale_2": "The output is not a hallucination. The output correctly and accurately defines the term \"princessness\" as the state or quality of being a princess, which aligns with the target definition.", "rationale_3": "The output is not a hallucination. It accurately provides the definition of \"princessness\" as the state or quality of being a princess, which is in alignment with the target definition.", "rationale_4": "The output is not a hallucination. It accurately provides the definition of 'princessness' as being the state or quality of being a princess, which aligns well with the target."}, {"hyp": "(Australia, New Zealand, colloquial) A tree.", "ref": "tgt", "src": "He climbed over the sedge and eely oarweeds and sat on a stool of rock , resting his ashplant in a <define> grike </define> .", "tgt": "(chiefly, British) A deep cleft formed in limestone surfaces due to water erosion; providing a unique habitat for plants.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:13:11Z", "rationale_0": "The output is a hallucination. The target definition indicates that a \"grike\" is a deep cleft formed in limestone surfaces, typically in Britain. However, the output provides a completely different definition, suggesting that it's a tree in Australia and New Zealand. Therefore, the output does not match the target and is incorrect.", "rationale_1": "The output is a hallucination. The term \"grike\" is defined correctly in the target as a deep cleft formed in limestone surfaces due to water erosion, whereas the output incorrectly defines it as a tree in Australia and New Zealand.", "rationale_2": "The output is a hallucination. The definition provided in the output does not match with the target definition. The term 'grike' is defined as a deep cleft formed in limestone surfaces due to water erosion in the target, while the output defines it as a tree, which is incorrect.", "rationale_3": "The output is a hallucination. The target definition indicates that a 'grike' is a type of cleft formed in limestone surfaces due to water erosion, primarily in British usage. However, the output incorrectly identifies a 'grike' as a colloquial term for a tree in Australia and New Zealand, which is not accurate.", "rationale_4": "The output is a hallucination. The target defines \"grike\" as a deep cleft formed in limestone surfaces due to water erosion. However, the output incorrectly defines it as a tree, which doesn't match with the target."}, {"hyp": "(intransitive) To die.", "ref": "tgt", "src": "\" But why should I be in another room ? \" \" You <define> passed over </define> in the night . \" \" Passed over ? Do you mean I died ? \" \" Yes , lady , you died . \" There was a long silence .", "tgt": "(intransitive, euphemistic) To die and thus progress to the afterlife.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T19:13:39Z", "rationale_0": "The output is not a hallucination. While it is not as detailed as the target and does not include the euphemistic nature or the concept of progressing to the afterlife, it is still an accurate definition of \"passed over\" in the given context. The output correctly identifies \"passed over\" as a term meaning \"to die\".", "rationale_1": "The output is not a hallucination. It is correct and accurate, albeit a bit simplified. It correctly captures the essence of the phrase \"passed over\" used in the context of the conversation provided, which is indeed a euphemism for dying. However, it omits the aspect of progressing to the afterlife, which is included in the target definition. Despite this omission, it's not incorrect or off point.", "rationale_2": "The output is not a hallucination. It provides a correct and simplified definition of 'passed over.' However, it misses out on some details from the target, such as the euphemistic nature of the term and the implication of progressing to the afterlife.", "rationale_3": "The output is not a hallucination. Although it misses the specific mention of progressing to the afterlife which is present in the target, its definition that 'passed over' means 'to die' is still correct and accurate.", "rationale_4": "The output is not a hallucination. Although it is not as detailed as the target, the output correctly defines \"passed over\" as a euphemism for dying. The target includes the detail of progressing to the afterlife, but this is not strictly necessary to understand the basic meaning of the term."}, {"hyp": "Alternative form of scatter site", "ref": "tgt", "src": "It is designed for single - family use in subdivisions or <define> scatter sites </define> and available as a standardized product   [ \u2026 ]", "tgt": "An area of state-sponsored housing used as a shelter for homeless people; such housing is scattered across different parts of a city rather than concentrated in one place.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Not Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:14:01Z", "rationale_0": "The output is a hallucination. The output does not provide a clear definition of the term \"scatter sites\" and the information given is not in line with the target, which explains that scatter sites refer to state-sponsored housing scattered across different parts of a city.", "rationale_1": "The output is a hallucination. The output does not provide a definition for 'scatter sites', instead it refers to it as an alternative form without providing any context or meaning. The target indicates that 'scatter sites' refers to an area of state-sponsored housing scattered across different parts of a city, which is not mentioned or inferred in the output.", "rationale_2": "The output is a hallucination. The output does not provide a definition for the term \"scatter sites\", instead, it just refers to an alternative form of the term. Therefore, it does not align with the target.", "rationale_3": "The output is a hallucination. It does not provide a definition for 'scatter sites' as requested in the input. Instead, it simply indicates that the term has an alternative form, without providing any actual definition. It does not match the target definition at all.", "rationale_4": "The output is a hallucination. Although the output acknowledges that \"scatter sites\" is an alternative form of \"scatter site\", it fails to provide the detailed definition that is expected, which is to describe it as an area of state-sponsored housing scattered across different parts of a city."}, {"hyp": "The state or condition of being obsolescent.", "ref": "tgt", "src": "One way is to legislate extended warranties on products , so washing machines and refrigerators last for 30 years instead of 10 . Another is to ban planned <define> obsolescence </define> , so manufacturers ca n\u2019t create products that are designed to fail .", "tgt": "(uncountable) The state of being obsolete\u2014no longer in use; gone into disuse; disused or neglected.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:14:28Z", "rationale_0": "The output is a hallucination. While it is somewhat related to the target, it is not accurate. The term 'obsolescence' does not simply refer to the state of being obsolescent but specifically to the state of being no longer in use or having been intentionally designed to become outdated or fail. The output fails to capture this crucial aspect of the definition.", "rationale_1": "The output is incorrect. The term \"obsolescence\" does not refer to the state of being obsolescent, but rather to the state of being obsolete or no longer in use. The output is a hallucination because it does not match the target definition.", "rationale_2": "The output is incorrect. It is a hallucination because it does not provide a definition that aligns with the target. The correct definition is the policy of designing a product with an artificially limited useful life or a purposely shortened life span in order to become obsolete or no longer functional after a certain period. The output definition provided does not provide this context.", "rationale_3": "The output is a hallucination. The term 'obsolescence' is not correctly defined according to the target. The output defines 'obsolescent' which refers to the process of becoming obsolete, not the state of being obsolete as defined in the target.", "rationale_4": "The output is incorrect. The term 'obsolescence' is defined as the state of being obsolete or no longer in use, whereas 'obsolescent' refers to something that is becoming obsolete. Therefore, the output does not accurately define the term in the input."}, {"hyp": "Alternative form of gartel (\u201cdance\u201d)", "ref": "tgt", "src": "The bride stands perfectly still at one end of the room and holds a long <define> gartel </define> while the male dancing before her holds the other end .", "tgt": "(Judaism) A belt or sash used in prayer.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:14:54Z", "rationale_0": "The output is a hallucination. The term 'gartel' is incorrectly defined as an \"alternative form of gartel ('dance')\". The correct definition, as per the target, is \"a belt or sash used in prayer\". The output does not match the target and is not accurate.", "rationale_1": "The output is a hallucination. The target defines \"gartel\" as a belt or sash used in prayer in Judaism, but the output incorrectly defines it as an alternative form of dance. This is a clear deviation from the correct definition.", "rationale_2": "The output is a hallucination. The target definition refers to a gartel as a belt or sash used in prayer in Judaism, but the output incorrectly defines it as an alternative form of gartel meaning \"dance\". This is incorrect and does not align with the provided target definition.", "rationale_3": "The output is a hallucination. The target definition states that a gartel is a belt or sash used in prayer in Judaism, but the output incorrectly defines it as an alternative form of \"gartel\" meaning \"dance\". This is not correct or accurate based on the target.", "rationale_4": "The output is a hallucination. The output defines \"gartel\" as an alternative form of dance, which is incorrect. The target correctly defines \"gartel\" as a belt or sash used in prayer in Judaism."}, {"hyp": "Capable of being endured.", "ref": "tgt", "src": "Misery colored by the greens and blues in my mother 's voice took all of the grief out of the words and left me with a conviction that pain was not only <define> endurable </define> , it was sweet .", "tgt": "Able to be endured; tolerable; bearable.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T19:15:18Z", "rationale_0": "The output is not a hallucination. The definition provided (\"Capable of being endured\") accurately reflects the target (\"Able to be endured; tolerable; bearable\"). Although it is simpler than the target, it still accurately defines the term 'endurable'.", "rationale_1": "The output is not a hallucination. It accurately defines \"endurable\" as being capable of being endured, which is synonymous with the target definition of being able to be endured or tolerable.", "rationale_2": "The output is not a hallucination. It accurately defines the term 'endurable' as something that is capable of being endured, which aligns with the target definition of being able to be endured, tolerable, or bearable.", "rationale_3": "The output is not a hallucination. It correctly defines \"endurable\" as something that is capable of being endured, which aligns well with the target definition that defines \"endurable\" as something that is able to be endured, tolerable, or bearable.", "rationale_4": "The output is not a hallucination. It correctly defines 'endurable' as something that is capable of being endured, which aligns with the target definition of being able to be endured, tolerable, or bearable."}, {"hyp": "(geology) Of or pertaining to the Alps.", "ref": "tgt", "src": "In 1884 O. Heer published a comprehensive account of the <define> nival </define> flora of   Switzerland , in which he listed 338 species of flowering plants found above 2600   m. ; of these , 6 were found above 3900 m.", "tgt": "(botany) Found or thriving in snowy conditions.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:15:49Z", "rationale_0": "The output is a hallucination. The term \"nival\" is described in the target as relating to snowy conditions and its botanical significance, which aligns with the context of the input mentioning flowering plants. However, the output incorrectly assigns a geological definition and associates the term with the Alps, which isn't mentioned in the input or target.", "rationale_1": "The output is a hallucination. The term \"nival\" is defined in the target as related to snowy conditions in the context of botany. However, the output incorrectly defines it as a term related to the Alps in the context of geology. The input does mention Switzerland, a country known for the Alps, but it does not tie the term \"nival\" specifically to the Alps.", "rationale_2": "The output is a hallucination. The term 'nival' in the context of the input refers to plants found or thriving in snowy conditions. The output incorrectly defines it as pertaining to the Alps, which is not accurate. The term 'nival' does not specifically pertain to the Alps, but to snowy conditions in general.", "rationale_3": "The output is a hallucination. The term 'nival' in the context of botany refers to something found or thriving in snowy conditions, not necessarily related to the Alps as the output suggests. The output seems to be influenced by the mention of Switzerland in the input, but this is not correct in defining 'nival'.", "rationale_4": "The output is a hallucination. While the input discusses a study about flora in Switzerland, which includes the Alps, the term 'nival' in the context of botany refers to plants found or thriving in snowy conditions. The output incorrectly defines 'nival' as pertaining to the Alps, which is not accurate."}, {"hyp": "Capable of being parachuted.", "ref": "tgt", "src": "<define> parachutable </define> supplies", "tgt": "Capable of being deployed by parachute.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T19:16:12Z", "rationale_0": "The output is not a hallucination. While the wording is slightly different from the target, the definition provided is still accurate and conveys the intended meaning of the term 'parachutable'.", "rationale_1": "The output is not a hallucination. While the wording is slightly different from the target, the output still accurately defines the term \"parachutable\" as something capable of being parachuted, which is essentially the same as being deployed by parachute.", "rationale_2": "The output is not a hallucination. It accurately defines \"parachutable\" as something capable of being parachuted, which aligns with the target definition of being capable of being deployed by parachute. The wording is slightly different, but the meaning is essentially the same.", "rationale_3": "The output is not a hallucination. The output \"Capable of being parachuted\" accurately defines the term \"parachutable\", even though it's not an exact match of the target \"Capable of being deployed by parachute\". Both convey the same meaning.", "rationale_4": "The output is not a hallucination. Although the wording is slightly different from the target, the output accurately conveys the meaning of the term \"parachutable\" as something that is capable of being parachuted or deployed via a parachute."}, {"hyp": "In a muffled manner.", "ref": "tgt", "src": "A voice came <define> muffledly </define> from inside the closet .", "tgt": "In a muffled manner; indistinctly.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T19:16:35Z", "rationale_0": "The output is not a hallucination. Even though it is missing the \"indistinctly\" part from the target, the main meaning of \"muffledly\" as \"in a muffled manner\" is still accurately captured in the output.", "rationale_1": "The output is not a hallucination. It correctly defines \"muffledly\" as \"in a muffled manner\". Although the output is slightly less detailed than the target, it still accurately captures the essence of the term's definition.", "rationale_2": "The output is not a hallucination. Although it does not include the term \"indistinctly\" as in the target, it still correctly defines \"muffledly\" as meaning \"in a muffled manner\". The absence of \"indistinctly\" does not make the output incorrect or off point.", "rationale_3": "The output is not a hallucination. It correctly captures the essence of the target definition, though it is less detailed. \"In a muffled manner\" accurately describes the concept of \"muffledly\", even if it doesn't include the aspect of being indistinct.", "rationale_4": "The output is not a hallucination. It accurately captures the essence of the target definition, which is doing something in a muffled manner. Even though it doesn't include the word \"indistinctly\", this word is somewhat implied in \"muffled manner\"."}, {"hyp": "(transitive) To cook (something) in a frying pan.", "ref": "tgt", "src": "Innawong et al . ( 2006 ) conducted experiments to study the effect of using nitrogen gas on the quality of <define> fried </define> chicken nuggets during pressure frying in terms of moisture retention and reduction in fat   [ \u2026 ]", "tgt": "Cooked in a deep fryer or pressure fryer or the like after being coated (breaded) in batter; compare deep-fried.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:17:01Z", "rationale_0": "The output is a hallucination. While the output does provide a broad definition of the term 'fried', it is not specific enough to the context provided in the input. The input implies a specific method of cooking, namely deep frying or pressure frying, which is not mentioned in the output.", "rationale_1": "The output is a hallucination. Although the output is a generally correct definition of the word \"fried\", it is not accurate in the context provided. The input is discussing deep frying or pressure frying, specifically in regard to chicken nuggets, not simply cooking something in a frying pan.", "rationale_2": "The output is a hallucination. The definition provided in the output is general and does not specifically refer to the term 'fried' in the context of chicken nuggets as described in the input. The target provides a more specific definition related to deep frying or pressure frying, which is more relevant to the input context.", "rationale_3": "The output is a hallucination. The definition provided in the output is a general definition of the term \"fried\", and does not align with the specific context given in the input of frying chicken nuggets in a pressure fryer. The target definition accurately describes this context.", "rationale_4": "The output is a hallucination. While the output correctly identifies \"fried\" as a cooking method, it does not provide the specific context indicated in the input and target, which is deep frying or pressure frying and specifically related to chicken nuggets. Instead, it gives a generic definition of frying in a pan."}, {"hyp": "A sleeveless garment worn at night.", "ref": "tgt", "src": "Winston wore a <define> nightcap </define> to stave off the cold .", "tgt": "A warm cloth cap worn while sleeping, often with pajamas, being common attire in northern Europe before effective home heating became widespread. [From 14th c.]", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Not Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:20:46Z", "rationale_0": "The output is a hallucination. The definition provided for 'nightcap' is incorrect as it describes it as a 'sleeveless garment worn at night', whereas the target correctly defines it as a 'warm cloth cap worn while sleeping'.", "rationale_1": "The output is a hallucination. The output incorrectly defines a nightcap as a \"sleeveless garment worn at night,\" while the target clearly indicates that a nightcap is a \"warm cloth cap worn while sleeping.\"", "rationale_2": "The output is a hallucination. The definition provided is incorrect. A nightcap is a warm cloth cap worn while sleeping, not a sleeveless garment.", "rationale_3": "The output is a hallucination. The definition provided does not accurately describe a 'nightcap'. A nightcap is not a 'sleeveless garment' but a type of headwear.", "rationale_4": "The output is a hallucination. The definition provided is incorrect as a nightcap is not a \"sleeveless garment\" but a cap worn on the head, typically when sleeping."}, {"hyp": "(obsolete) Old; old-fashioned.", "ref": "tgt", "src": "And thou , our Mother , twice two centuries <define> young </define> ,", "tgt": "(Not) advanced in age; (far towards or) at a specified stage of existence or age.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:21:09Z", "rationale_0": "The output is a hallucination. The term \"young\" is being defined as being not advanced in age or at a specific stage of existence or age, which is contrary to the output that defines it as being old or old-fashioned. The output is incorrect and does not match with the target.", "rationale_1": "The output is a hallucination. The target definition suggests that in this context, \"young\" refers to not being advanced in age or being at a specified stage of existence. However, the output provides a definition that is the opposite, suggesting that \"young\" is obsolete or old-fashioned, which is incorrect.", "rationale_2": "The output is a hallucination. The term to define was \"young,\" but the model incorrectly defined it as \"old; old-fashioned,\" which is the opposite of the target definition. The model apparently misunderstood the context.", "rationale_3": "The output is a hallucination. The term \"young\" is being asked to be defined and the target correctly describes it as not advanced in age or at a specific stage of existence. However, the output incorrectly defines \"young\" as \"old\" or \"old-fashioned\", which is the opposite of the actual meaning of the term.", "rationale_4": "The output is a hallucination. The target indicates that 'young' in this context refers to not being advanced in age, or being at a specific stage of existence or age. However, the output incorrectly defines 'young' as obsolete or old-fashioned, which is the opposite of the correct definition."}, {"hyp": "A county of Hotan, Sichuan, China.", "ref": "tgt", "src": "The \u201c living fossil \u201d , metasequoia , for example , was once distributed over large areas of Europe , Asia and the Americas from the Cretaceous to the Tertiary periods . Destroyed by glaciers , its natural distribution in China is today limited to Sichuan \u2019s <define> Shizhu </define> county , Hubei \u2019s Lichuan county and Hunan \u2019s Longshan county .", "tgt": "A county of Chongqing, China.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:23:15Z", "rationale_0": "The output is a hallucination. The correct location of Shizhu county is in Chongqing, China as per the target. The output incorrectly places it in Hotan, Sichuan, China.", "rationale_1": "The output is a hallucination. The output incorrectly states that Shizhu is a county of Hotan, Sichuan, China when the target and input clearly state that it is a county of Chongqing, China.", "rationale_2": "The output is a hallucination. The target specifies that Shizhu is a county of Chongqing, China, while the output incorrectly identifies it as a county of Hotan, Sichuan, China. The output does not align with the target, making it inaccurate.", "rationale_3": "The output is a hallucination. The target correctly identifies Shizhu as a county of Chongqing, China. However, the output incorrectly locates Shizhu in Hotan, Sichuan, China. The input text also does not mention Hotan or Sichuan in relation to Shizhu, making the output information extraneous and incorrect.", "rationale_4": "The output is a hallucination. The target specifies that Shizhu is a county of Chongqing, China, not Hotan, Sichuan, China as the output states. The output is incorrect and does not match the target."}, {"hyp": "A small flag.", "ref": "tgt", "src": "Given the present crisis and empty coffers , working meetings geared toward results are more appropriate for politicians than a program of touristy forays , throngs waving <define> flaglets </define> and bulletproof glass , the whole culminating in a neo - feudal state banquet .", "tgt": "A small flag.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T19:25:15Z", "rationale_0": "The output is not a hallucination. It correctly and accurately defines the term \"flaglets\" as provided in the target.", "rationale_1": "The output is not a hallucination. It correctly defines the term \"flaglets\" as given in the target, which is 'A small flag'.", "rationale_2": "The output is correct and accurate. It correctly defines the term \"flaglets\" as a small flag, which is in alignment with the target. There is no hallucination present as the output does not add any extraneous or incorrect information.", "rationale_3": "The output is not a hallucination. It correctly and accurately provides the definition for \"flaglets\" as given in the target.", "rationale_4": "The output is correct and accurate. It matches the target, correctly defining \"flaglets\" as small flags. Therefore, it is not a hallucination."}, {"hyp": "(zoology) Of or pertaining to a minotaur.", "ref": "tgt", "src": "Elytra <define> miniatous </define> , with a large somewhat triangular black spot on their disk ,   [ \u2026 ]", "tgt": "(formal) Orange-red, the colour of red lead.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:25:35Z", "rationale_0": "The output is a hallucination. The target definition talks about a color (orange-red), while the output refers to something related to a minotaur, which is incorrect and unrelated to the input.", "rationale_1": "The output is a hallucination. The target indicates that the term 'miniatous' describes a specific color, while the output suggests the term is related to a minotaur, which is incorrect.", "rationale_2": "The output is a hallucination. The target definition refers to a specific color (orange-red), while the output refers to something related to a minotaur, which is completely unrelated. The output does not match the target at all.", "rationale_3": "The output is a hallucination. The target definition refers to a specific color, while the output refers to something pertaining to a minotaur, which is not related to the input or target at all.", "rationale_4": "The output is a hallucination. The target definition is related to a color, while the output definition describes something related to a minotaur in zoology. The output is not relevant to the input or target."}, {"hyp": "(chemistry) The degree to which a substance is hydrated.", "ref": "tgt", "src": "DuBois and coworkers carried out extensive studies of the thermodynamic <define> hydricity </define> of metal hydrides ( 3.2 ) ; in many cases the metal product resulting following hydride transfer will bind a CH3CN ligand ( not shown in 3.2 ) , so comparisons of hydricity will be solvent - dependent .", "tgt": "(chemistry) The tendency in a transition metal hydride for an H- ion to transfer to a substrate", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:25:57Z", "rationale_0": "The output is a hallucination. The target definition indicates that hydricity refers to the tendency in a transition metal hydride for an H- ion to transfer to a substrate, which is in line with the context provided in the input. However, the output definition incorrectly defines hydricity as the degree to which a substance is hydrated, which is not relevant or accurate to the term as used in the input or target definition.", "rationale_1": "The output is a hallucination. The target definition refers to the tendency of an H- ion in a transition metal hydride to transfer to a substrate, while the output definition incorrectly refers to the degree to which a substance is hydrated. These are not the same concepts.", "rationale_2": "The output is a hallucination. The target definition talks about the tendency of an H- ion to transfer to a substrate, which is different from the output's claim about the degree to which a substance is hydrated. Hence, the output is not correct.", "rationale_3": "The output is a hallucination. It incorrectly defines \"hydricity\" as the degree to which a substance is hydrated, whereas the target definition correctly defines it as the tendency in a transition metal hydride for an H- ion to transfer to a substrate. The output is therefore incorrect.", "rationale_4": "The output is a hallucination. The definition provided does not match with the target. The target defines hydricity as the tendency in a transition metal hydride for an H- ion to transfer to a substrate, while the output incorrectly defines it as the degree to which a substance is hydrated."}, {"hyp": "(video games) The state or condition of being bisexual in a video game.", "ref": "tgt", "src": "It can be argued that explicit representations of bisexuality , pansexuality , and other multiple - gender - attracted people are erased from games that use ' <define> playersexuality </define> ' as a mechanic .", "tgt": "(video games) The state of an NPC being attracted to the player character, especially without regard to gender, race, etc.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:26:20Z", "rationale_0": "The output is a hallucination. The target definition explains that 'playersexuality' is the state of an NPC being attracted to the player character, irrespective of the gender, race, etc. However, the output incorrectly defines the term as the state of being bisexual in a video game, which is not accurate.", "rationale_1": "The output is a hallucination. The definition given in the output is not accurate as it incorrectly defines 'playersexuality' as being bisexual in a video game, while the target definition explains it as the state of an NPC being attracted to the player, without regard to gender, race, etc. The output has failed to capture the essence of the term 'playersexuality' and hence, it is a hallucination.", "rationale_2": "The output is a hallucination. It doesn't accurately define 'playersexuality' as in the target. Instead, it incorrectly defines the term as the state of being bisexual in a video game, which is not the same as an NPC being attracted to the player character without regard to gender, race, etc.", "rationale_3": "The output is a hallucination. While it involves the context of video games, it incorrectly defines 'playersexuality' as being bisexual in a video game, instead of the correct definition where an NPC is attracted to the player character without regard to gender, race, etc.", "rationale_4": "The output is a hallucination. The term 'playersexuality' is inaccurately defined as being bisexual in a video game. The correct definition is the state of a non-playable character (NPC) being attracted to the player character regardless of factors like gender or race."}, {"hyp": "That\u2019s not happening at the moment.", "ref": "either", "src": "That\u2019s not happening.", "tgt": "That isn\u2019t gonna happen.", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:26:42Z", "rationale_0": "The output is a hallucination. Although the output is close to the input, it adds extraneous information (\"at the moment\") that cannot be inferred from the original input or target. The input and target both imply a definitive statement that something will not happen, whereas the output suggests it might happen in the future.", "rationale_1": "The output is a hallucination. The input statement is absolute and doesn't refer to any specific point in time, it generally means something will not occur. However, the output suggests a temporary situation, implying that something is not happening \"at the moment\", but could potentially happen in the future. This is an addition of information not present or implied in the input.", "rationale_2": "The output is a hallucination. The addition of \"at the moment\" introduces a temporal element that isn't present or implied in the input or the target. This additional information could change the meaning of the sentence, implying that the event could occur in the future, which is not inferred from the input.", "rationale_3": "The output is a hallucination. The input statement definitively states that something will not happen, while the output suggests that it's not happening now, but it could potentially happen in the future, introducing information not present in the input.", "rationale_4": "The output is a hallucination. The additional information \"at the moment\" cannot be inferred from the initial input or the target. The initial statement implies a general negation, not limited to any specific time."}, {"hyp": "I have a permit to carry it.", "ref": "either", "src": "I have a permit.", "tgt": "Uh, I\u2019m validated.", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:27:02Z", "rationale_0": "The output is a hallucination. The input does not specify what the permit is for, therefore the addition of \"to carry it\" is an assumption that isn't grounded in the provided information.", "rationale_1": "The output is a hallucination. The output adds information (\"to carry it\") that was not present or inferred from the original input. The input does not specify what the permit is for, and thus the output is adding extraneous information.", "rationale_2": "The output is a hallucination. The input doesn't specify what the permit is for, but the output assumes it's for carrying something, which is an addition of information not present or suggested in the input.", "rationale_3": "The output is a hallucination. The output adds extra information (\"to carry it\") that is not present or implied in the original input. The target shows that a correct paraphrase should only convey the idea of having permission or validation, without specifying what the permit is for.", "rationale_4": "The output is a hallucination. The input \"I have a permit\" does not specify what the permit is for, while the output specifically adds the detail \"to carry it\". This information is not present in the original input or the target, making the output a hallucination."}, {"hyp": "The process is easy.", "ref": "either", "src": "Easy, easy.", "tgt": "Watch it now.", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Hallucination", "Hallucination", "Not Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:27:26Z", "rationale_0": "The output is a hallucination. The target implies a warning or caution, whereas the output is a comment on the simplicity of a process. The output does not align with the intended meaning in the target.", "rationale_1": "The output is a hallucination. Although it maintains the theme of \"ease\" from the input, it changes the context completely. The target suggests a warning or cautionary tone, which is not present in the output. The output instead indicates a description of a process, which is not inferred from the input.", "rationale_2": "The output is a hallucination. The target suggests a cautionary tone, while the output talks about a process being easy, which doesn't align with the target. The model's output is not a correct paraphrase of the input as it introduces new information that is not inferred from the input.", "rationale_3": "The output is a hallucination. Although it correctly interprets the input as referring to something being 'easy', it does not capture the cautionary or warning tone suggested by the target. Instead, it provides a statement about a process being easy, which is not the intended message of the input.", "rationale_4": "The output is a hallucination. Although it correctly interprets the input's connotation of simplicity or easiness, it does not convey the cautious or warning tone implied in the target (\"Watch it now\"). The output also adds information about a \"process,\" which is not mentioned or implied in the input."}, {"hyp": "A number between five and eight.", "ref": "either", "src": "A five, six, seven, eight.", "tgt": "And 5, 6, 7, 8.", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Hallucination", "Hallucination", "Not Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:27:48Z", "rationale_0": "The output is a hallucination. The output changes the meaning of the input. The input lists four separate numbers (5, 6, 7, 8), while the output implies a range between five and eight. The output does not accurately convey the specific numbers mentioned in the input.", "rationale_1": "The output is a hallucination. Although it mentions numbers five through eight, it changes the meaning by suggesting a single number between five and eight, rather than listing the sequential numbers as in the input and target.", "rationale_2": "The output is a hallucination. The target suggests a simple rephrasing of the input, maintaining the sequence of numbers. However, the output has misinterpreted the input, suggesting a range rather than a sequence, which is not the correct paraphrasing.", "rationale_3": "The output is a hallucination. The input specifies four distinct numbers (\"five, six, seven, eight\") rather than a range between two numbers. The output incorrectly interprets the input as a range (\"a number between five and eight\") instead of a list of specific, individual numbers.", "rationale_4": "The output is a hallucination. The input is clearly enumerating a series of numbers (5, 6, 7, 8) individually. The output incorrectly interprets it as a range from 5 to 8, which is not the same meaning as the input or target."}, {"hyp": "That is a safer way to travel.", "ref": "either", "src": "A lot safer that way.", "tgt": "Because it\u2019s safer.", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:28:06Z", "rationale_0": "The output is a hallucination. The output contains extraneous information (\"to travel\") that is not present or implied in the input or target. The input and target do not specify what the \"safer way\" is referring to, so adding \"to travel\" is a hallucination.", "rationale_1": "The output is a hallucination. Although the output maintains the concept of safety from the input, it introduces the concept of \"travel\", which is not mentioned or inferred in either the input or the target.", "rationale_2": "The output is a hallucination. The input does not mention anything about \"travel,\" but the output introduces this new concept. Therefore, the output contains extraneous information that cannot be inferred from the input.", "rationale_3": "The output is a hallucination. The input statement does not specify what is safer, let alone mentioning anything related to travel. The output introduces \"travel\" which is not implied or stated in the input.", "rationale_4": "The output is a hallucination. While the output does maintain the idea of safety from the input, it introduces the context of \"travel,\" which is not present or inferred in the original input or target."}, {"hyp": "You\u2019re not a good scam artist.", "ref": "either", "src": "You\u2019re a scam artist.", "tgt": "You are an imposter.", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:30:15Z", "rationale_0": "The output is a hallucination. The original input and the target both denote accusing someone of fraudulent activities without any reference to their skill level. However, the output introduces an extraneous element by suggesting the person is not \"good\" at being a scam artist. This change in meaning and introduction of new information makes the output a hallucination.", "rationale_1": "The output is a hallucination. The target paraphrase suggests that the person is a scammer or a fraud, but the output incorrectly implies that the person is a scam artist but not a very good one. The input does not give any information about the skill level of the scam artist, therefore this is an addition of extraneous information.", "rationale_2": "The output is a hallucination. While it maintains the accusation of the individual being a \"scam artist,\" it introduces an evaluation (\"not a good\") that is not present in the input or target. The input and target are simply identifying the individual as deceptive, not qualifying their skill level in deception.", "rationale_3": "The output is a hallucination. The original input does not specify whether the person is a good or bad scam artist, it merely states that the person is a scam artist. The output introduces a new concept (\"not a good\") which cannot be inferred from the input.", "rationale_4": "The output is a hallucination. Although it retains the negative connotation, the output adds information not present or inferred from the input. The input accuses someone of being a scam artist, while the output negates this, implying the person is a failed scam artist. This additional context is not present in the input nor matches the target."}, {"hyp": "When did you see him?", "ref": "either", "src": "When\u2019d you last see him?", "tgt": "When was the last time you saw him?", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T19:30:36Z", "rationale_0": "The output is not a hallucination. It correctly paraphrases the input but it does lack some details from the target. The phrase \"last time\" from the target is missing in the output, but it doesn't add any extraneous or incorrect information.", "rationale_1": "The output is not a hallucination. It still conveys the same general idea as the input and the target. However, it lacks the precision of \"last time,\" which is present in both the input and the target. This slight change might alter the context in some scenarios, but it doesn't qualify as a hallucination since it doesn't introduce new, incorrect, or extraneous information.", "rationale_2": "The output is not a hallucination. Although the output does not exactly match the target, it still maintains the core meaning of the original input. The intention of the question in the input, target, and output is to inquire about the last time the person was seen, which is correctly captured in the output.", "rationale_3": "The output is not a hallucination. It accurately paraphrases the input, though it drops the \"last\" element. However, it still retains the same general meaning.", "rationale_4": "The output is not a hallucination. It may not exactly match the target, but it is a correct paraphrase of the input. It maintains the same meaning, asking about the last time the person saw \"him\"."}, {"hyp": "Let me leave.", "ref": "either", "src": "Let me out of here.", "tgt": "Someone let me out.", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T19:30:58Z", "rationale_0": "The output is not a hallucination. Although it is not an exact match of the target, it is a correct and accurate paraphrase of the input, conveying the same meaning of wanting to depart from the current location.", "rationale_1": "The output is not a hallucination. It accurately paraphrases the input without inserting additional or extraneous information. Both the input and the output convey a similar meaning, which is a desire to leave or exit a location. However, it's not a perfect match to the target.", "rationale_2": "The output is not a hallucination. Although it is not a perfect match to the target, it accurately paraphrases the input without adding extra or extraneous information.", "rationale_3": "The output is not a hallucination. It accurately paraphrases the input, but it does not perfectly match the target. The meaning is preserved as both the input and output are requests to leave a certain place. However, the output lacks the direct appeal to \"someone\" present in the target.", "rationale_4": "The output is not a hallucination. It correctly paraphrases the input message, which is about someone asking to be let out of a place. The output, \"Let me leave,\" carries the same meaning."}, {"hyp": "It is not impossible.", "ref": "either", "src": "Nothing is impossible.", "tgt": "There\u2019s nothing that can\u2019t be done.", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T19:31:19Z", "rationale_0": "The output is not a hallucination. It is a correct and accurate paraphrase of the input. While it's not an exact match to the target, it still captures the essence of the original sentence's meaning, implying that anything can be achieved.", "rationale_1": "The output is not a hallucination. It is indeed a correct and accurate paraphrase of the input, as it maintains the same meaning, although it is not as close to the target as it could be. The target and output both affirm that nothing is impossible.", "rationale_2": "The output is not a hallucination. However, it does not fully capture the meaning of the input or the target. The input and target suggest that everything is possible, while the output only states that one unspecified thing is not impossible. Therefore, the output is not entirely accurate or complete.", "rationale_3": "The output is not a hallucination. However, it is not a perfect match to the target. The output still maintains the general idea of the input, stating that something is not impossible, which is a synonymous way of saying \"Nothing is impossible\".", "rationale_4": "The output is not a hallucination. It maintains the same core meaning of the original input, asserting that \"nothing is impossible\". However, it is less strong and less specific than the target paraphrase."}, {"hyp": "Tom decided to leave the company.", "ref": "either", "src": "Tom d\u00e9cida de quitter la soci\u00e9t\u00e9.", "tgt": "Tom has decided to leave the company.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T19:31:40Z", "rationale_0": "The output is not a hallucination. Although the output doesn't use the perfect tense (\"has decided\") as in the target, it is still a correct and accurate translation of the input. The meaning of the sentence is preserved in the output.", "rationale_1": "The output is not a hallucination. Although the output uses the past tense (\"decided\") versus the present perfect tense (\"has decided\") in the target, the overall meaning remains the same - Tom is leaving the company. Therefore, the translation is correct and accurate.", "rationale_2": "The output is not a hallucination. Although the output is in past tense while the target is in present perfect tense, both sentences accurately translate the original French sentence, without adding any extraneous information.", "rationale_3": "The output is not a hallucination. Even though the output uses the simple past tense (\"decided\") instead of the present perfect tense (\"has decided\") used in the target, the meaning is still correctly and accurately conveyed. The tense difference doesn't change the essential information that Tom is leaving the company.", "rationale_4": "The output is not a hallucination. It accurately translates the input from French to English, even though it uses simple past tense \"decided\" instead of present perfect \"has decided\". The meaning remains the same."}, {"hyp": "Do you love her?", "ref": "either", "src": "Est-ce que tu l'aimes ?", "tgt": "Do you love him?", "model": "", "task": "MT", "labels": ["Not Hallucination", "Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:31:58Z", "rationale_0": "The output is a hallucination. The input sentence in French is asking about a male object (\"him\"), but the output incorrectly translates this to \"her\".", "rationale_1": "The output is a hallucination. The input in French is asking \"Do you love him?\" but the model translated it incorrectly to \"Do you love her?\" This shows a lack of gender accuracy in the translation.", "rationale_2": "The output is a hallucination. The input in French is asking about a male object (\"l'aimes\" refers to \"him\"), but the output inaccurately translates this to \"her.\"", "rationale_3": "The output is a hallucination. The correct translation of \"l'aimes\" from French to English is \"love him\", not \"love her\". Therefore, the model is generating incorrect information.", "rationale_4": "The output is a hallucination. The input is asking about a male subject (\"l'aimes\" is referring to \"him\"), but the output incorrectly translates it to \"her\"."}, {"hyp": "I got the company.", "ref": "either", "src": "J'ai de la compagnie.", "tgt": "I've got company.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "predictions": ["Hallucination", "Hallucination", "Not Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 0.8, "timestamp": "2023-11-05T19:32:28Z", "rationale_0": "The output is a hallucination. While the verb \"got\" is correctly translated, the context changes in the output. \"I've got company\" implies that someone is visiting or present with the speaker, while \"I got the company\" implies that the speaker has obtained a business or organization. The output does not accurately reflect the meaning of the input.", "rationale_1": "The output is incorrect. The target translation suggests a casual context where the speaker has guests or visitors. The output, on the other hand, could be interpreted as the speaker having acquired a business. Therefore, the output is a hallucination, as it implies a different context that cannot be inferred from the input.", "rationale_2": "The output is not a hallucination but it is not entirely correct either. The phrase \"I got the company\" can be inferred from the input, but it does not accurately represent the target translation. The correct translation should be \"I've got company\", which indicates the presence of others, not the possession of a business or corporation as suggested by \"I got the company\".", "rationale_3": "The output is incorrect. Although it's very close to the target, the phrase \"I got the company\" changes the meaning of the sentence. The correct translation should be \"I've got company,\" indicating the presence of guests or other individuals. The output makes it sound like the person acquired a business. Therefore, the output can be considered a hallucination.", "rationale_4": "The output is incorrect. Though it conveys a similar message, the phrase \"I got the company\" might also be interpreted as the person having acquired a business, which is not the meaning of the original French sentence. The correct translation is \"I've got company\", indicating the presence of other people. Thus, the output seems to be a hallucination."}, {"hyp": "He's got several friends.", "ref": "either", "src": "Ann a plusieurs amis.", "tgt": "Ann has many friends.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:32:46Z", "rationale_0": "The output is a hallucination. The output incorrectly translates \"Ann\" to \"He\". The correct translation should refer to \"Ann\", not \"He\".", "rationale_1": "The output is a hallucination. The translation is incorrect because the subject, \"Ann\", has been wrongly translated as \"He\". The correct translation should refer to \"Ann\" and not \"He\".", "rationale_2": "The output is a hallucination. The main issue is that the gender of the subject (\"Ann\") is incorrect. The output incorrectly uses \"he\" instead of \"she\". Also, the name \"Ann\" is not mentioned in the output. Therefore, the translated sentence is not accurate.", "rationale_3": "The output is a hallucination. The sentence inaccurately translates \"Ann\" to \"He\" instead of maintaining the proper noun. Additionally, \"plusieurs\" is translated as \"several\" instead of \"many\". These errors make the translation inaccurate.", "rationale_4": "The output is a hallucination. It incorrectly translates \"Ann\" as \"He\", which is not accurate according to the target translation. Therefore, the output is incorrect."}, {"hyp": "The captain orders the ship on board.", "ref": "either", "src": "Le capitaine donne l'ordre d'embarquer sur le navire.", "tgt": "The skipper is giving the order to board the ship.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:33:10Z", "rationale_0": "The output is a hallucination. The translation is not accurate, it suggests that the captain is ordering the ship on board, which doesn't make sense. The correct translation should indicate that the captain is giving orders to board the ship, not ordering the ship itself.", "rationale_1": "The output is a hallucination. The translated sentence in the output doesn't correctly convey the meaning of the input. The correct translation is that the captain is giving the order to board the ship, not that the captain is ordering the ship on board.", "rationale_2": "The output is a hallucination. The translation is incorrect and does not accurately reflect the meaning of the original French sentence. The phrase \"The captain orders the ship on board\" does not make sense in English. The correct translation should be \"The captain gives the order to board the ship,\" as reflected in the target.", "rationale_3": "The output is a hallucination. The translation is incorrect and does not accurately convey the meaning of the original sentence. It suggests that the captain is ordering the ship on board, which is nonsensical. The correct translation should indicate the captain is giving the order for people to board the ship.", "rationale_4": "The output is a hallucination. The given translation is not accurately representing the original French sentence. The phrase 'The captain orders the ship on board' makes no sense in English. The correct translation should be 'The captain gives the order to board the ship'."}, {"hyp": "Sami called 911.", "ref": "either", "src": "Sami a appel\u00e9 le 911.", "tgt": "Sami made a call to 911.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T19:33:36Z", "rationale_0": "The output is not a hallucination. It accurately translates the original input, just with a slight variation in wording that doesn't change the meaning (\"Sami called 911\" vs \"Sami made a call to 911\").", "rationale_1": "The output is not a hallucination. Although it doesn't match the target exactly, it conveys the same information as the target: that Sami called 911. The difference in wording does not change the meaning or add any extraneous information.", "rationale_2": "The output is correct and accurate. Although it doesn't use the exact phrasing of the target (\"made a call to\"), the meaning remains the same. \"Sami called 911\" effectively communicates the same information as \"Sami made a call to 911\". Therefore, the output is not a hallucination.", "rationale_3": "The output is correct and accurate. It effectively communicates the same information as the target, although in a slightly different phrasing. There is no hallucination as the output does not contain any incorrect or extraneous information.", "rationale_4": "The output is not a hallucination. It correctly and accurately translates the input from French to English. The difference in wording between the target and output does not change the meaning of the sentence."}, {"hyp": "We love our school.", "ref": "either", "src": "Nous aimons notre \u00e9cole.", "tgt": "We like our school.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:33:55Z", "rationale_0": "The output is a hallucination. Although the sentiment is similar, the translation is not accurate. The French verb \"aimons\" should be translated as \"like\", not \"love\". Therefore, the output is not correct.", "rationale_1": "The output is a hallucination. Although \"aimons\" can translate to either \"like\" or \"love\" in English, the intensity of the emotion conveyed by \"love\" is greater than that of \"like\". Given that the target translation uses \"like\", the output translation should reflect the same level of emotional intensity. Thus, the output is not accurate.", "rationale_2": "The output is a hallucination. While \"aimons\" can be translated as \"love\" or \"like\" from French to English, the target translation uses \"like,\" which more closely mirrors the degree of affection implied in the original French sentence. Therefore, the output is not entirely accurate.", "rationale_3": "The output is a hallucination. The word \"aimons\" in French translates to \"like\" in English, not \"love\". Therefore the output is not accurate.", "rationale_4": "The output is a hallucination. While \"aimons\" does refer to a positive emotion towards the school, the exact translation is \"like\", not \"love\". The strength of feeling is different between \"like\" and \"love\", making the output inaccurate."}, {"hyp": "How'd you get \"pretty\"?", "ref": "either", "src": "Comment \u00e9pelles-tu \"pretty\" ?", "tgt": "How do you spell \"pretty\"?", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:34:18Z", "rationale_0": "The output is a hallucination. The target is asking about how to spell the word \"pretty\", while the output is asking how the person came up with the word \"pretty\". These two interpretations are not the same, hence the translation is incorrect.", "rationale_1": "The output is a hallucination. The translation provided in the output does not match the target. The input is asking for the spelling of the word \"pretty\", not how one came to get the word \"pretty\".", "rationale_2": "The output is a hallucination. The correct translation should ask how to spell \"pretty\", but the output incorrectly asks how you got \"pretty\". The output doesn't match the intended meaning of the input.", "rationale_3": "The output is a hallucination. The input asks for the spelling of \"pretty\", however, the output is asking how the person got \"pretty\". It is not consistent with the input or target.", "rationale_4": "The output is a hallucination. The translation does not correctly reflect the meaning of the input. The input is asking for the spelling of \"pretty\", not how one obtained \"pretty\"."}, {"hyp": "The old days will never come back.", "ref": "either", "src": "Les jours anciens ne reviendront jamais.", "tgt": "The old days have gone never to return.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T19:34:37Z", "rationale_0": "The output is not a hallucination. It accurately translates the input into English, even though it does not match the target exactly. The meaning of the sentence is preserved, as both translations indicate that the old days will not return.", "rationale_1": "The output is not a hallucination. Although the wording is different from the target, the output correctly and accurately translates the meaning of the original French input.", "rationale_2": "The output is not a hallucination. Although it is not a verbatim translation of the target, the output accurately conveys the same sentiment as both the input and target: the notion that the past, or \"the old days,\" can't be revisited.", "rationale_3": "The output is not a hallucination. Both the target and output accurately convey the same sentiment that the old days will not return. The difference in phrasing does not change the overall meaning.", "rationale_4": "The output is not a hallucination. While the translation is not word-for-word the same as the target, it conveys the same meaning as the original French sentence and the target English translation."}, {"hyp": "I bought three different varieties of flowers.", "ref": "either", "src": "J\u2019ai achet\u00e9 trois diff\u00e9rentes sortes de fleurs.", "tgt": "I bought three different kinds of flowers.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T19:34:58Z", "rationale_0": "The output is not a hallucination. Although the word \"varieties\" is used instead of \"kinds\", the meaning remains the same. Therefore, the translation is considered correct and accurate.", "rationale_1": "The output is not a hallucination. Although the word 'varieties' is used instead of 'kinds', both words have the same meaning in this context and the translation is accurate.", "rationale_2": "The output is not a hallucination. Although the specific word 'varieties' is used instead of 'kinds', the meaning remains the same. The translation is correct and accurately reflects the original French sentence.", "rationale_3": "The output is not a hallucination. The translation is accurate and correct. \"Sortes\" can be translated as \"kinds\" or \"varieties\", both of which keep the original meaning of the sentence intact.", "rationale_4": "The output is not a hallucination. Although the word \"varieties\" is used instead of \"kinds\", these words are synonyms in this context and the meaning of the sentence remains the same. The output is correct and accurate."}, {"hyp": "It's my duty.", "ref": "either", "src": "C'est mon m\u00e9tier.", "tgt": "It's my job.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:35:24Z", "rationale_0": "The output is a hallucination. Although \"duty\" and \"job\" can sometimes be used interchangeably in English, the translation is not accurate in this context. The French word \"m\u00e9tier\" translates directly to \"job\" or \"profession\", not \"duty\".", "rationale_1": "The output is a hallucination. Although \"duty\" and \"job\" can be used interchangeably in some contexts, the direct translation of \"m\u00e9tier\" from French to English is \"job\" or \"profession\", not \"duty\". Therefore, the output is not an accurate translation of the input.", "rationale_2": "The output is a hallucination. The translation of \"m\u00e9tier\" from French to English is \"job\" not \"duty\". While \"job\" and \"duty\" might have similar connotations, they are not exact synonyms, and in this case, the translation is not accurate.", "rationale_3": "The output is a hallucination. Although \"duty\" can be a synonym for \"job\" in some contexts, in this case, the translation is not accurate. The French word \"m\u00e9tier\" directly translates to \"job\" or \"profession\" in English, not \"duty.\" Therefore, the output is not correct according to the target.", "rationale_4": "The output is a hallucination. Although \"duty\" and \"job\" can sometimes be used interchangeably, in translation they are not the same. The word \"m\u00e9tier\" in French directly translates to \"job\" or \"profession\" in English, not \"duty\". Therefore, the output is not accurate."}, {"hyp": "I have nothing to do with it.", "ref": "either", "src": "J'en ai rien \u00e0 secouer.", "tgt": "I don't give a shit about it.", "model": "", "task": "MT", "labels": ["Hallucination", "Not Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:35:53Z", "rationale_0": "The output is a hallucination. The target translation suggests a strong emotional indifference or dismissiveness towards something, which is not conveyed in the output. The output's translation is quite literal and does not capture the colloquial meaning of the phrase.", "rationale_1": "The output is a hallucination. Although the output is not entirely unrelated or absurd, it doesn't accurately replicate the colloquial and dismissive tone of the input, which is captured in the target translation. It misses the key idea of not caring about something from the input phrase.", "rationale_2": "The output is a hallucination. Although the output is not entirely off point, it doesn't accurately convey the original meaning of the French input. The input is a slang phrase in French that translates directly to the target \"I don't give a shit about it\", whereas the output \"I have nothing to do with it\" lacks the intensity and rudeness of the original phrase.", "rationale_3": "The output is a hallucination. While the literal translation of the input may mean \"I have nothing to shake,\" in French slang, it is equivalent to the English phrase \"I don't give a shit.\" Therefore, the output translation is incorrect because it does not accurately capture the original sentiment of the input.", "rationale_4": "The output is a hallucination. Although the output is a literal translation of the input, it does not convey the correct meaning in English. The target translation shows that the phrase is an idiomatic expression, meaning \"I don't give a shit about it.\" Hence, the output is incorrect."}, {"hyp": "I've been confiscated.", "ref": "either", "src": "On m'a confisqu\u00e9 mon permis.", "tgt": "I've had my driving license confiscated.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:36:16Z", "rationale_0": "The output is a hallucination. The output does not accurately convey the information in the input. The input mentions a driving license being confiscated but the output does not include this crucial detail.", "rationale_1": "The output is a hallucination. The output sentence is grammatically incorrect and does not accurately convey the meaning of the input sentence. The output does not mention the important detail about the \"driving license\" being confiscated.", "rationale_2": "The output is a hallucination. The output does not accurately reflect the input. The main point that the speaker's driving license has been confiscated is missing in the output. Instead, it incorrectly suggests that the speaker themselves has been confiscated, which doesn't make sense.", "rationale_3": "The output is a hallucination. The main issue is that it does not accurately translate the input. It omits the crucial information about the \"driving license\" being confiscated, which is present in the original French sentence and the target English translation.", "rationale_4": "The output is a hallucination. It is incorrect and does not accurately translate the input. The output does not mention the crucial information about the driving license being confiscated, which is present in the input and target translation."}, {"hyp": "Stop turning.", "ref": "either", "src": "Arr\u00eate de tourner.", "tgt": "Stop spinning.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T19:36:41Z", "rationale_0": "The output is not a hallucination. Although the output is not a direct match with the target, \"Stop turning\" is a valid translation of \"Arr\u00eate de tourner\". In this context, \"turning\" and \"spinning\" can be used interchangeably, so it is still a correct translation.", "rationale_1": "The output is not a hallucination. While the output is not a verbatim translation of the target, it still correctly conveys the meaning of the input. Both \"turning\" and \"spinning\" can be used interchangeably in this context.", "rationale_2": "The output is not a hallucination. The output is accurate and correct, as \"turning\" can be interpreted as \"spinning\" in English. The translation maintains the overall meaning of the original French sentence, even though it does not exactly match the target.", "rationale_3": "The output is not a hallucination. Both \"turning\" and \"spinning\" can be considered correct translations for the French verb \"tourner\". However, the output is not a perfect match to the target.", "rationale_4": "The output is not a hallucination. While the output uses \"turning\" instead of \"spinning,\" both terms can be reasonably inferred from the original French input \"tourner,\" which can mean either \"turn\" or \"spin\" depending on context. Therefore, the output is a correct and accurate translation."}, {"hyp": "What kind of bread are you eating in general?", "ref": "either", "src": "Quel genre de pain est-ce que tu manges en g\u00e9n\u00e9ral ?", "tgt": "What kind of bread do you usually eat?", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T19:37:04Z", "rationale_0": "The output is not a hallucination. While the phrasing is slightly different from the target, it still accurately translates the original French input. The slight difference in phrasing does not change the overall meaning of the sentence.", "rationale_1": "The output is not a hallucination. It is a correct and accurate translation of the French input. Although the phrasing is slightly different from the target, both the output and target essentially ask the same question.", "rationale_2": "The output is not a hallucination. While the phrasing is slightly different from the target, the output still accurately translates the meaning of the French input. Both are asking about the type of bread the person generally consumes.", "rationale_3": "The output is not a hallucination. Although the phrasing is slightly different, it is still an accurate translation of the input. It correctly conveys the same meaning as the target.", "rationale_4": "The output is not a hallucination. It essentially conveys the same meaning as the target, although the phrasing differs slightly. Both versions are asking about the respondent's usual or typical choice of bread."}, {"hyp": "The eagles are friends.", "ref": "either", "src": "Les araign\u00e9es sont mignonnes.", "tgt": "Spiders are cute.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:37:25Z", "rationale_0": "The output is a hallucination. The translation provided (The eagles are friends) does not match the input sentence (Les araign\u00e9es sont mignonnes, meaning Spiders are cute). The output does not accurately translate the subject (\"spiders\") or the adjective (\"cute\"), thus it is incorrect and off point.", "rationale_1": "The output is a hallucination. The translated output is completely irrelevant to the input. The input is talking about spiders being cute, while the output is talking about eagles being friends.", "rationale_2": "The output is a hallucination. The output is talking about eagles being friends, which is completely unrelated to the input which is about spiders being cute. Therefore, the output is incorrect and off point.", "rationale_3": "The output is a hallucination. The input sentence is talking about spiders being cute, but the output is completely unrelated, talking about eagles being friends. This is not a correct translation of the input.", "rationale_4": "The output is a hallucination. The translation is completely incorrect. The correct translation from French to English should be \"Spiders are cute,\" but the output is talking about eagles being friends, which is not related to the input in any way."}, {"hyp": "Farhat Mehenni's separatist group concluded a compromise with the radical Islamist group Rachad for the destabilization of Algeria. This led Algeria to officially consider the two groups as terrorist organizations.", "ref": "either", "src": "Le groupe s\u00e9paratiste de Ferhat Mehenni a conclu un compromis avec le groupe islamiste radical Rachad pour la d\u00e9stabilisation de l'Alg\u00e9rie. C'est ce qui a conduit l'Alg\u00e9rie \u00e0 officiellement consid\u00e9rer les deux groupes comme des organisations terroristes.", "tgt": "Ferhat Mehenni's separatist group cut a deal with the radical Islamist group Rachad to destabilize Algeria. That's what led Algeria to officially consider both groups as terrorist organizations.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T19:37:51Z", "rationale_0": "The output is not a hallucination. It correctly and accurately translates the given French input into English. The slight change in the spelling of the name 'Ferhat Mehenni' to 'Farhat Mehenni' does not affect the overall meaning of the sentence, and could be attributed to variations in translation.", "rationale_1": "The output is not a hallucination. It accurately translates the input from French to English, conveying the exact same meaning as the target. The only difference is the spelling of the name \"Ferhat Mehenni\", which is spelled \"Farhat Mehenni\" in the output. This could be considered a minor error, but it does not constitute a hallucination as it does not alter the overall meaning of the sentence.", "rationale_2": "The output is not a hallucination. Although there is a slight discrepancy in the spelling of \"Ferhat\" in the target and \"Farhat\" in the output, the overall meaning and content of the output is consistent with the target. The output accurately captures and conveys the original information given in the input.", "rationale_3": "The output is not a hallucination. It accurately translates the input from French to English, keeping the key information the same. The small difference in translation of \"cut a deal\" to \"concluded a compromise\" does not change the overall meaning of the sentence. The misspelling of \"Ferhat\" as \"Farhat\" is an error, but it does not qualify as a hallucination.", "rationale_4": "The output is not a hallucination. The output correctly translates the input from French to English, preserving the original meaning and context. The slight discrepancy in the spelling of \"Ferhat Mehenni\" as \"Farhat Mehenni\" is most likely an error or typo but does not constitute hallucination as it doesn't add or infer extraneous information."}, {"hyp": "You certainly don't have your mother's good nature.", "ref": "either", "src": "Tu n'as certainement pas la bonne nature de ta m\u00e8re.", "tgt": "You definitely don't have the good nature of your mother.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T19:38:05Z", "rationale_0": "The output is not a hallucination. The output accurately translates the input from French to English, and the meaning is preserved, although the sentence structure is slightly different from the target.", "rationale_1": "The output is not a hallucination. The translation is correct and accurately conveys the meaning of the input, just using slightly different wording.", "rationale_2": "The output is not a hallucination. Although the wording is slightly different, the output accurately translates the meaning of the input from French to English. Both the target and output convey the same message.", "rationale_3": "The output is not a hallucination. It accurately translates the input to English, just using slightly different phrasing compared to the target. The meaning remains the same.", "rationale_4": "The output is correct and accurate. It conveys the same meaning as the target, just with a slightly different wording. Therefore, it is not a hallucination."}, {"hyp": "Tom didn't hurry.", "ref": "either", "src": "Tom n'a pas hurl\u00e9.", "tgt": "Tom didn't scream.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:38:27Z", "rationale_0": "The output is a hallucination. The correct translation of \"hurl\u00e9\" from French to English is \"scream,\" not \"hurry.\" Therefore, the output provided is not accurate.", "rationale_1": "The output is a hallucination. The correct translation of 'hurl\u00e9' from French to English is 'scream', not 'hurry'. Thus, the output is incorrect.", "rationale_2": "The output is a hallucination. The translation is incorrect because the French verb \"hurl\u00e9\" translates to \"screamed\" in English, not \"hurry\". Therefore, the correct translation should be \"Tom didn't scream\".", "rationale_3": "The output is a hallucination. The translated output \"Tom didn't hurry\" doesn't match with the target \"Tom didn't scream\". The word \"hurl\u00e9\" in French translates to \"scream\" in English, not \"hurry\". Therefore, the output is incorrect.", "rationale_4": "The output is a hallucination. The output inaccurately translates \"hurl\u00e9\" (meaning \"scream\" in French) as \"hurry\". Therefore, the output is incorrect."}, {"hyp": "Do you like tomatoes?", "ref": "either", "src": "Tom aime-t-il les tomates ?", "tgt": "Tom likes tomatoes?", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:38:50Z", "rationale_0": "The output is a hallucination. The output is not accurate because it changes the subject from \"Tom\" in the input to \"you\" in the output. The correct translation should be asking if \"Tom\" likes tomatoes, not \"you\".", "rationale_1": "The output is a hallucination. The input is asking if a specific person, Tom, likes tomatoes, but the output changes the subject to \"you\" instead of \"Tom.\" Therefore, the output is not accurate.", "rationale_2": "The output is a hallucination. The input is asking if a specific person, Tom, likes tomatoes, whereas the output incorrectly generalizes the question to \"you\", not specifying Tom.", "rationale_3": "The output is a hallucination. The translation is incorrect because it changes the subject from \"Tom\" to \"you\". The correct translation is \"Does Tom like tomatoes?\" as per the target.", "rationale_4": "The output is a hallucination. The translation changes the subject of the sentence from \"Tom\" to an unspecific \"you\", which is incorrect based on the original French sentence."}, {"hyp": "In this case we see the results all the time.", "ref": "either", "src": "Dans ce m\u00e9tier on voit tout de suite les r\u00e9sultats.", "tgt": "In this activity one immediately sees the result.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:39:19Z", "rationale_0": "The output is a hallucination. While it generally conveys the same idea as the input, the phrase \"all the time\" adds information that was not present in the original French sentence. The French sentence specifies that the results are seen \"immediately\", not \"all the time\".", "rationale_1": "The output is a hallucination. The translation does not accurately match the target. The phrase \"tout de suite\" should be translated as \"immediately\" not \"all the time\". Also, the use of \"we\" in the output is not as accurate as \"one\" in the target.", "rationale_2": "The output is a hallucination. While it correctly conveys the general idea of seeing results, it does not accurately translate the temporal aspect of the original sentence. The French sentence is about seeing results \"immediately\" (\"tout de suite\"), not \"all the time\".", "rationale_3": "The output is a hallucination. Although it conveys the idea of seeing results, it deviates from the target by suggesting that results are seen \"all the time\" instead of \"immediately,\" which changes the original meaning.", "rationale_4": "The output is a hallucination. Although the overall meaning is somewhat similar, the specific detail about seeing results \"immediately\" has been changed to seeing results \"all the time\" in the output, which is not accurate to the original input."}, {"hyp": "I really think you should leave.", "ref": "either", "src": "Je pense vraiment que vous devriez partir.", "tgt": "I really think you should leave.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T19:39:33Z", "rationale_0": "The output is not a hallucination. It matches the target exactly, accurately translating the original French sentence into English.", "rationale_1": "The output is not a hallucination. It perfectly matches the target, accurately translating the input from French to English without adding any extraneous information.", "rationale_2": "The output is not a hallucination. It matches the target exactly, providing an accurate translation of the input.", "rationale_3": "The output is not a hallucination. The output perfectly matches the target, indicating an accurate and correct translation from the input.", "rationale_4": "The output is not a hallucination. It perfectly matches the target, meaning the translation is accurate and correct."}, {"hyp": "Make him a horse!", "ref": "either", "src": "Fais-lui un c\u00e2lin !", "tgt": "Give her a hug.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:39:56Z", "rationale_0": "The output is a hallucination. The translation is entirely incorrect, as it does not match the target. The correct translation should be 'Give her a hug', but the output is 'Make him a horse', which is unrelated to the original input.", "rationale_1": "The output is a hallucination. The output completely deviates from the target and does not accurately translate the input. The input in English should be 'Give her a hug', not 'Make him a horse'.", "rationale_2": "The output is a hallucination. The translation is incorrect as it does not match the target. The output \"Make him a horse!\" does not convey the same meaning as the input \"Fais-lui un c\u00e2lin !\" which means \"Give her a hug\".", "rationale_3": "The output is a hallucination. The translation is incorrect and does not match the target. The output translates to something completely different and unrelated to the original French input.", "rationale_4": "The output is a hallucination. The translation provided in the output is incorrect and does not match with the target. The correct translation of the input \"Fais-lui un c\u00e2lin !\" is \"Give her a hug.\" The output \"Make him a horse!\" is unrelated and off point."}, {"hyp": "Don't lend anyone else the book you borrowed.", "ref": "either", "src": "Ne pr\u00eate pas \u00e0 un autre le livre que tu as emprunt\u00e9.", "tgt": "Don't lend a borrowed book to another.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T19:40:12Z", "rationale_0": "The output is not a hallucination. It correctly and accurately translates the input from French to English, conveying the same message as the target.", "rationale_1": "The output is not a hallucination. It accurately translates the meaning of the input. Both the target and output convey the same message which is not lending a borrowed book to someone else.", "rationale_2": "The output is not a hallucination. It accurately translates the input and conveys the same meaning as the target.", "rationale_3": "The output is correct and accurate. It successfully conveys the same meaning as the target translation, albeit with slightly different wording. It is not a hallucination because all the information contained in the output can be reasonably inferred from the input.", "rationale_4": "The output is not a hallucination. It accurately translates the input into English and conveys the same essential meaning as the target translation. There is no extraneous or incorrect information added."}, {"hyp": "I want to drink something free.", "ref": "either", "src": "Je veux boire quelque chose de frais.", "tgt": "I want something cold to drink.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:40:31Z", "rationale_0": "The output is a hallucination. The translation is incorrect because the French word \"frais\" means \"cold\", not \"free\". Therefore, the correct translation should be \"I want something cold to drink\".", "rationale_1": "The output is a hallucination. The correct translation of \"frais\" from French to English is \"cold\", not \"free\". Therefore, the output is not accurate.", "rationale_2": "The output is incorrect and can be considered a hallucination. The French phrase \"quelque chose de frais\" translates to \"something cold,\" not \"something free.\" Therefore, the translation provided in the output is not accurate.", "rationale_3": "The output is a hallucination. The correct translation of \"frais\" from French to English is \"cold\", not \"free\". Therefore, the output is inaccurate.", "rationale_4": "The output is a hallucination. The correct translation of \"frais\" from French to English is \"cold,\" not \"free.\" Therefore, the output incorrectly translated the input."}, {"hyp": "Do you have a cryon?", "ref": "either", "src": "As-tu un crayon ?", "tgt": "Have you got a pencil?", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:40:51Z", "rationale_0": "The output is a hallucination. While the translation is mostly correct, the word \"crayon\" is misspelled as \"cryon\", making the output incorrect.", "rationale_1": "The output is a hallucination. While it captures the overall meaning of the input, the term \"cryon\" is not an accurate translation of \"crayon\" from French to English. The correct translation should be \"pencil\", so the output contains incorrect information.", "rationale_2": "The output is a hallucination. While the translation is almost correct, the term \"cryon\" is a mistake. It should be \"pencil\" instead, aligning with the target translation.", "rationale_3": "The output is a hallucination. The output translation is not accurate, the word \"cryon\" does not exist in English. The correct translation should be \"pencil\".", "rationale_4": "The output is a hallucination. The translation is incorrect due to a spelling error. The correct translation should be \"Do you have a pencil?\" instead of \"Do you have a cryon?\""}, {"hyp": "I talked to other people in the same situation.", "ref": "either", "src": "J'ai discut\u00e9 avec d'autres personnes dans la m\u00eame situation.", "tgt": "I have talked with others in the same situation.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T19:41:16Z", "rationale_0": "The output is not a hallucination. While the tense used in the output (\"I talked\") is slightly different from the target (\"I have talked\"), the meaning conveyed in both sentences is essentially the same. The output accurately translates the input, with no extraneous or incorrect information added.", "rationale_1": "The output is not a hallucination. Although the output uses the past tense \"talked\" instead of the present perfect \"have talked\" as in the target, the meaning is still accurately preserved from the input to the output.", "rationale_2": "The output is not a hallucination. Although the translation is not word-for-word, it still accurately conveys the main idea of the sentence. The use of \"talked to\" instead of \"have talked with\" is a minor variation and does not change the overall meaning.", "rationale_3": "The output is not a hallucination. It accurately translates the input, albeit using slightly different wording (\"I talked\" instead of \"I have talked\", \"people\" instead of \"others\"). However, the meaning remains the same.", "rationale_4": "The output is not a hallucination. The output is accurate and correctly translates the input from French to English. Although the target uses \"have talked\" and the output uses \"talked\", both are correct translations and convey the same meaning."}, {"hyp": "The nurse will check your arm within 2 days to see if there's any reaction.", "ref": "either", "src": "L'infirmier v\u00e9rifiera ton bras dans les 2 jours pour voir s'il y a une r\u00e9action.", "tgt": "The nurse will check your arm within 2 days to see if there is a reaction.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T19:41:39Z", "rationale_0": "The output is not a hallucination. The output accurately translates the input text from French to English, maintaining the same meaning as the target translation. The slight difference in phrasing (\"if there is a reaction\" vs \"if there's any reaction\") does not alter the meaning of the sentence.", "rationale_1": "The output is not a hallucination. The output accurately translates the input and does not add any extraneous information. The use of \"there's any\" instead of \"there is a\" does not change the meaning of the sentence.", "rationale_2": "The output is not a hallucination. It accurately translates the input into English and doesn't include any extraneous information. The difference between \"if there is a reaction\" and \"if there's any reaction\" is negligible and doesn't change the meaning of the sentence.", "rationale_3": "The output is not a hallucination. The output accurately translates the input from French to English, conveying the same meaning even though it uses slightly different wording (\"there's any reaction\" instead of \"there is a reaction\").", "rationale_4": "The output is not a hallucination. It correctly and accurately translates the input from French to English. The slight rephrasing of \"if there is a reaction\" to \"if there's any reaction\" does not change the meaning."}, {"hyp": "You're not missing anyone.", "ref": "either", "src": "Tu ne manques \u00e0 personne.", "tgt": "No one misses you.", "model": "", "task": "MT", "labels": ["Hallucination", "Not Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:42:03Z", "rationale_0": "The output is a hallucination. The translation is incorrect because it suggests that the subject of the sentence (you) is not missing anyone, while the target text indicates that no one is missing the subject (you). The output has changed the meaning of the original sentence entirely.", "rationale_1": "The output is a hallucination. The output incorrectly translates the input. The correct translation should be \"No one misses you,\" but the output incorrectly suggests that \"You're not missing anyone.\"", "rationale_2": "The output is a hallucination. The target translation suggests that the input means \"No one misses you.\" However, the output has a different meaning, saying \"You're not missing anyone,\" which doesn't match the target translation. Thus, the output is incorrect.", "rationale_3": "The output is a hallucination. The translation provided in the output is incorrect. The correct translation should be \"No one misses you\" as given in the target. Instead, the output translates to a completely different meaning, implying that the person being spoken to is not missing anyone, rather than no one missing them.", "rationale_4": "The output is a hallucination. The translation provided in the output is incorrect as it does not accurately convey the meaning of the input. The correct translation should be \"No one misses you\", not \"You're not missing anyone\"."}, {"hyp": "I've got the floor and the furniture.", "ref": "either", "src": "J'ai poli le plancher et les meubles.", "tgt": "I polished up the floor and furniture.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:42:25Z", "rationale_0": "The output is a hallucination. The correct translation from French to English should include the action of 'polishing' the floor and furniture, which is missing in the output. Instead, it incorrectly states 'I've got the floor and the furniture,' which does not convey the same meaning as the input.", "rationale_1": "The output is a hallucination. The verb \"polished up\" has been incorrectly translated to \"got\" in the output, which changes the meaning of the sentence from the original input.", "rationale_2": "The output is a hallucination. The translated sentence is incorrect as it missed the key action \"polished up\" from the target. The output suggests that the person has the floor and the furniture, not that they polished it.", "rationale_3": "The output is a hallucination. The output does not accurately translate the input, as it omits the key action \"polished up\" from the original French sentence.", "rationale_4": "The output is a hallucination. The output does not accurately translate the input. The verb \"poli\" (polished) is completely omitted in the output, changing the meaning of the sentence."}, {"hyp": "I can't do it alone.", "ref": "either", "src": "Je ne peux le faire seule. Il vous faut m'aider.", "tgt": "I can't do it alone. You have to help me.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "predictions": ["Not Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 0.8, "timestamp": "2023-11-05T19:42:48Z", "rationale_0": "The output is incorrect and inaccurate because it only translated the first part of the input. It neglected the second sentence \"Il vous faut m'aider\" which translates to \"You have to help me.\" Therefore, the output is a hallucination.", "rationale_1": "The output is a hallucination. While the first sentence of the output correctly translates the first sentence of the input, it misses the second sentence entirely. The target translation includes \"You have to help me,\" which is not present in the output.", "rationale_2": "The output is a hallucination. While the first sentence in the output matches the first sentence in the target, the output omits the second sentence from the target, \"You have to help me.\" This makes the output incomplete and not an accurate translation of the full input.", "rationale_3": "The output is a hallucination. While the first sentence is correctly translated, the second sentence from the input (\"Il vous faut m'aider.\") is completely missing in the output. Thus, the output is not fully accurate.", "rationale_4": "The output is a hallucination. While it correctly translates the first sentence of the input, it completely omits the second sentence (\"Il vous faut m'aider\"), which translates to \"You have to help me.\" This means the output is missing crucial information from the input."}, {"hyp": "He lost what he received from his father.", "ref": "either", "src": "Il a perdu ce qu'il a re\u00e7u de son p\u00e8re.", "tgt": "He wasted that which he had received from his father.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "predictions": ["Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination", "Not Hallucination"], "predicted": "Not Hallucination", "predicted_p": 0.0, "timestamp": "2023-11-05T19:43:17Z", "rationale_0": "The output is not a hallucination. While the output and target translations do not match exactly, both convey the same general meaning. The difference is in the nuance of the words used - \"wasted\" implies carelessness or misuse, while \"lost\" could mean misplacement or loss through circumstances beyond control. It's a matter of interpretation and both can be inferred from the input.", "rationale_1": "The output is not a hallucination. It is a correct translation of the input, but it doesn't match exactly with the target. The verb \"perdu\" can be translated as both \"lost\" and \"wasted\", so the output translation is still correct and accurate, even though it's not the same as the target.", "rationale_2": "The output is not a hallucination. It is a correct and accurate translation of the input, although it uses the word \"lost\" instead of \"wasted\". Both translations convey the same general meaning, so the output is not off point or including extraneous information.", "rationale_3": "The output is not a hallucination. It is a correct and accurate translation of the input, although the verb \"perdu\" has been translated as \"lost\" instead of \"wasted\". However, both translations convey the same general meaning.", "rationale_4": "The output is not a hallucination. Although the output uses \"lost\" instead of \"wasted\" which is in the target, it still accurately translates the main idea of the sentence from the input. In this context, \"lost\" and \"wasted\" can be interpreted similarly."}, {"hyp": "We've discovered a lot of news.", "ref": "either", "src": "Nous avons d\u00e9couvert une grande nouveaut\u00e9.", "tgt": "We have discovered a great novelty.", "model": "", "task": "MT", "labels": ["Hallucination", "Not Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:43:43Z", "rationale_0": "The output is a hallucination. The correct translation of \"une grande nouveaut\u00e9\" is \"a great novelty,\" not \"a lot of news.\" The output therefore contains extraneous information that cannot be reasonably inferred from the input.", "rationale_1": "The output is a hallucination. The input talks about discovering a \"great novelty\" and not a \"lot of news\". The output is not accurately translating the original input.", "rationale_2": "The output is a hallucination. The input's direct translation is \"We have discovered a great novelty\" which implies they found something new and interesting. The output \"We've discovered a lot of news\" implies that they have found several new pieces of information or updates, which is not the same as the original input's meaning.", "rationale_3": "The output is a hallucination. The input text translates directly to \"We have discovered a great novelty,\" meaning a new or unique thing/experience. The output, \"We've discovered a lot of news,\" suggests multiple new pieces of information, which is not consistent with the original singular \"novelty\" in the input.", "rationale_4": "The output is a hallucination. The input is specifically referring to a singular \"great novelty,\" whereas the output incorrectly translates this to \"a lot of news.\" The two phrases carry different meanings, making the output inaccurate."}, {"hyp": "Why is everyone okay?", "ref": "either", "src": "Pourquoi est-ce que tout le monde rigole ?", "tgt": "Why is everyone laughing?", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:44:03Z", "rationale_0": "The output is a hallucination. The translation does not accurately reflect the original French sentence. The French sentence is asking why everyone is laughing, not if everyone is okay.", "rationale_1": "The output is a hallucination. The correct translation of \"rigole\" from French to English is \"laughing,\" not \"okay.\" Therefore, the output is not accurate to the input.", "rationale_2": "The output is a hallucination. The correct translation of \"rigole\" in French is \"laughing\", not \"okay\". Therefore, the output does not accurately translate the input.", "rationale_3": "The output is a hallucination. The translation is incorrect as \"rigole\" in French translates to \"laughing\" in English, not \"okay\". Therefore, the correct translation should be \"Why is everyone laughing?\" not \"Why is everyone okay?\"", "rationale_4": "The output is a hallucination. The input text translates to \"Why is everyone laughing?\", however, the output is \"Why is everyone okay?\". The translation does not align with the original meaning of the input."}, {"hyp": "No matter what you do to your guide.", "ref": "either", "src": "Chacun fait \u00e0 sa guise.", "tgt": "Each one does as he likes.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "predictions": ["Hallucination", "Hallucination", "Hallucination", "Hallucination", "Hallucination"], "predicted": "Hallucination", "predicted_p": 1.0, "timestamp": "2023-11-05T19:44:29Z", "rationale_0": "The output is a hallucination. The output translation does not accurately reflect the input. The correct translation should be \"Each one does as he likes\", but the output is completely different and does not relate to the original French sentence.", "rationale_1": "The output is a hallucination. The translated output does not align with the target translation and includes information (\u201cNo matter what you do\u201d) that wasn\u2019t present or implied in the original French input. The correct translation should be \"Each one does as he likes\", reflecting individual preference, not actions towards a guide.", "rationale_2": "The output is a hallucination. The translated output does not accurately reflect the input. The correct translation should be \"Each one does as he likes\" as indicated in the target but the output says, \"No matter what you do to your guide,\" which is off point and incorrect.", "rationale_3": "The output is a hallucination. The output does not accurately translate the input. The correct translation is \"Each one does as he likes\" and not \"No matter what you do to your guide.\" The output introduces the concept of a guide which is not present in the input.", "rationale_4": "The output is a hallucination. The output does not accurately translate the input. The input's correct translation is \"Each one does as he likes,\" not \"No matter what you do to your guide.\" Therefore, the output includes extraneous information that isn't inferred from the input."}]