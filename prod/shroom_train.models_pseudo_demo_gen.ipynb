{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, random, numpy as np\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from scipy.spatial.distance import cosine\n",
    "from shroom_classifier_v12 import ShroomClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-4-1106-preview\"\n",
    "\n",
    "TEMP = 1.2\n",
    "\n",
    "DATE = datetime.utcnow().date().isoformat()\n",
    "\n",
    "SAMPLE_SIZE = 64\n",
    "\n",
    "PSEUDO_DEMOS_PER_SELECTION = 5\n",
    "\n",
    "SELECTIONS = 5\n",
    "\n",
    "EMBEDDINGS_MODEL = OpenAIEmbeddings()\n",
    "\n",
    "CLASSIFIER = ShroomClassifier(model_name=MODEL, temperature=TEMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_negative_entropy(p, epsilon=1e-10):\n",
    "    # Adjust probabilities to avoid log(0)\n",
    "    p = np.clip(p, epsilon, 1 - epsilon)\n",
    "    return p * np.log(p) + (1 - p) * np.log(1 - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(v1, v2):\n",
    "    return 1 - cosine(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi(dp, classification):\n",
    "    serialization = f'{dp[\"hyp\"]} {dp[\"tgt\"]} {dp[\"src\"]} {dp[\"tgt\"]} {classification[\"label\"]}'\n",
    "    return EMBEDDINGS_MODEL.embed_query(serialization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection_metric(p, S, l=0.2):\n",
    "    return p['F_CLS'] - (l * max([ cos_sim(p[\"phi\"], s[\"phi\"]) for s in S ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pseudo_demos(datapoints):\n",
    "    pseudo_demos = []\n",
    "    for dp in tqdm(datapoints):  \n",
    "        classification = CLASSIFIER.classify(dp, examples=False)\n",
    "        pseudo_demos.append(\n",
    "            {\n",
    "                \"datapoint\": dp,\n",
    "                \"classification\": classification,\n",
    "                \"F_CLS\": binary_negative_entropy(classification[\"p(Hallucination)\"]),\n",
    "                \"phi\": phi(dp, classification) \n",
    "            }\n",
    "        )\n",
    "    return pseudo_demos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_pseudo_demos(pseudo_demos, K=3):\n",
    "    pool = pseudo_demos\n",
    "    selections = []\n",
    "    for k in range(K):\n",
    "        if len(pool) == 0:\n",
    "            break\n",
    "        if k == 0:\n",
    "            sk = max(pool, key=lambda x: x['F_CLS'])\n",
    "        else:\n",
    "            sk = max(pool, key=lambda x: selection_metric(x, selections))\n",
    "        selections.append(sk)\n",
    "        pool.remove(sk)\n",
    "    return selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = json.load(open('reference/train.model-agnostic.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [02:30<00:00,  2.36s/it]\n",
      "100%|██████████| 64/64 [02:20<00:00,  2.20s/it]\n",
      "100%|██████████| 64/64 [02:35<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [02:05<00:00,  1.97s/it]\n",
      "100%|██████████| 64/64 [02:06<00:00,  1.98s/it]\n",
      "100%|██████████| 64/64 [02:09<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [02:26<00:00,  2.28s/it]\n",
      "100%|██████████| 64/64 [02:04<00:00,  1.95s/it]\n",
      "100%|██████████| 64/64 [02:02<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 4 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [02:22<00:00,  2.22s/it]\n",
      "100%|██████████| 64/64 [03:58<00:00,  3.72s/it] \n",
      "100%|██████████| 64/64 [02:11<00:00,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [02:08<00:00,  2.01s/it]\n",
      "100%|██████████| 64/64 [02:03<00:00,  1.93s/it]\n",
      "100%|██████████| 64/64 [02:06<00:00,  1.98s/it]\n"
     ]
    }
   ],
   "source": [
    "examples = []\n",
    "for i in range(SELECTIONS):\n",
    "    print(\"run\", i+1, \"...\")\n",
    "    run = {}\n",
    "    for task in [\"DM\", \"PG\", \"MT\"]:\n",
    "        pds = generate_pseudo_demos(random.sample([ dp for dp in dataset if dp['task'] == task ], SAMPLE_SIZE))\n",
    "        pds_pos = [ pd for pd in pds if pd[\"classification\"][\"label\"] == \"Hallucination\" ]\n",
    "        pds_neg = [ pd for pd in pds if pd[\"classification\"][\"label\"] == \"Not Hallucination\" ]\n",
    "        run[task] = { \"Hallucination\": select_pseudo_demos(pds_pos, K=PSEUDO_DEMOS_PER_SELECTION), \"Not Hallucination\": select_pseudo_demos(pds_neg, K=PSEUDO_DEMOS_PER_SELECTION) }\n",
    "    examples.append(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(examples, open('examples.json', 'w+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x147ff9b90>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x1500de5d0>, model='text-embedding-ada-002', deployment='text-embedding-ada-002', openai_api_version='', openai_api_base=None, openai_api_type='', openai_proxy='', embedding_ctx_length=8191, openai_api_key='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', openai_organization=None, allowed_special=set(), disallowed_special='all', chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMBEDDINGS_MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conceptual-engineering-using-llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
